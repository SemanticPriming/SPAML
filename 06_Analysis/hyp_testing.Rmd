---
title: "Confirmatory Hypothesis Testing"
author: "Erin M. Buchanan"
date: "Last Update `r Sys.Date()`"
output:
  html_document:
    df_print: paged
    toc: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, size="scriptsize")
def.chunk.hook <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
```

## Libraries

```{r}
library(dplyr)
library(psych)
library(tidyr)
library(ggplot2)
library(rio)
set.seed(58902)
library(nlme)
library(MuMIn)
library(performance)
library(parameters)
```

## Import the Files

```{r import-data, message = F}
langs <- c("en", "pl", "sr", "ro", "tr", "pt", "br_pt", "")


original <- list.files("../05_Data_real/data_processing/output_data/priming_data",
                       pattern = ".csv",
                       full.names = TRUE,
                       recursive = TRUE)



answered <- original[grepl("answered", original)]
original <- original[!grepl("answered", original)]

original.data <- lapply(original, import)

```

## Hypothesis 1

```{r}
# run the analysis
hyp1 <- lm(avgZ_prime ~ 1, data = sim_data_same)

# print the results
summary(hyp1)
parameters(hyp1)
model_performance(hyp1)
```

Hypothesis information is presented in Table XX. Hypothesis 1 predicts semantic facilitation with reduced response latencies for related than unrelated words. Hypothesis 1 was analyzed by calculating an intercept-only regression model using the *z*-scored priming response latency as the dependent variable. 



The intercept and its 95% confidence interval will represent the grand mean of the priming effect across all languages. The priming response latency is calculated by taking the average of the unrelated pair z-scored response latency minus the related pair response latency within each item. Therefore, values that are positive and greater than zero (e.g., > 0.0001) indicate priming because the related pair had a faster response latency than the unrelated pair. We will determine support for Hypothesis 1 if the lower limit of the confidence interval is greater than zero (i.e., a directional comparison). This process will be repeated for average priming scores calculated without trials that were marked as 2.50 z-score outliers and 3.00 z-score outliers separately. The decision criteria will remain the same, and we will identify any differences in decisions based on outlier statistics (e.g., priming only occurs when X trials are removed). 

## Hypothesis 2

Hypothesis 2 explores the extent to which these semantic priming effects vary across languages. Therefore, we will calculate a random effects model using the nlme99 package in R wherein the random intercept of language will be added to the overall intercept only model for Hypothesis 1. We will report the standard deviation of the random effect, its 95% confidence interval, the AIC change between models, and the pseudo-R2 values for the effect size of this parameter100. Results will support significant heterogeneity when the AIC for the random effects model is two points or more less than the AIC for the intercept-only model56. This analysis will be repeated with the 2.50 z-score outliers and 3.00 z-score outliers excluded. We will include a forest plot of the priming effect and their 95% confidence intervals to visualize the potential heterogeneity in the priming results. Simulations of models within and without variability in the priming effects can be found at https://osf.io/fbhr8/.

```{r}
# run the model
hyp2 <- lme(avgZ_prime ~ 1, 
            data = sim_data_same, 
            method = "REML", 
            random = ~1|Language)

# model assumptions
performance::check_model(hyp2)

# print the results
summary(hyp2)
parameters(hyp2)
model_performance(hyp2)
intervals(hyp2)

# compare models
AIC(hyp1)
AIC(hyp2)

# effect size
r.squaredGLMM(hyp2)
```

```{r}
# example plot
ggplot(sim_data_same, aes(Language, avgZ_prime)) +
  stat_summary(fun.data = mean_cl_normal, 
               geom = "errorbar", 
               width = .2, 
               position = position_dodge(width = .2)) + 
  stat_summary(fun = mean,
               geom = "point", 
               position = position_dodge()) + 
  xlab("Language") + 
  ylab("Z Score Priming") +
  theme_classic() + 
  coord_flip() + 
  geom_hline(yintercept = 0)
```

