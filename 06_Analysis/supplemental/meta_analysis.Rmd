---
title: "Supplemental Meta Analysis Hypothesis Testing"
author: "Erin M. Buchanan"
date: "Last Update `r Sys.Date()`"
output: html_document
bibliography: ../references.bib
---

Related/unrelated trials were considered complete when *n* answered \>= 50 for minimum data collection. Often, we were able to get *n* correct \>= 50. When examining some of the “weird” words, it was clear that they had a low percent correct rate and would not reach correct rates at *n* \>= 50. In order to account for potential differences in correct sample sizes, we have analyzed an exploratory meta-analysis for the same two questions in the original pre-registration, using a random effects analysis to calculate the overall priming effect for everything and each language. We will use the same criteria as listed to determine the sensitivity of the original effects using weighted scores to account for differences in item sample sizes. Given that no differences in scoring accuracy was found, we will only examine this model for the original, more conservative, accuracy scoring to determine if the same conclusions would be found using a different analysis approach.

```{r setup, include=FALSE, echo = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = FALSE, size="scriptsize")
def.chunk.hook <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
```

```{r libraries, include=FALSE, echo = FALSE, message = FALSE, warning = FALSE}
## libraries
library(dplyr)
library(psych)
library(tidyr)
library(ggplot2)
library(rio)
set.seed(58902)
library(nlme)
library(MuMIn)
library(performance)
library(parameters)
library(ggridges)
library(papaja)
library(metafor)
```

```{r import-data, message = F}
## Import the Files
langs <- c("br_pt_combo", "cs", "da", "de", 
           "el", "en", "es", "fr", "hu", "it", "ja", 
           "ko", "pl", "pt_combo", 
           "ro", "ru", "sr", "tr", 
           "zh")

# original data ----
original <- list.files("../../05_Data/data_processing/output_data/priming_data",
                       pattern = "prime_summary.csv",
                       full.names = TRUE,
                       recursive = TRUE)

original <- original[grepl(paste0(langs, "_prime_summary.csv",
                                        collapse = "|"), original)]

langs.length <- c(rep(1000, 11), 1034,
                  rep(1000, 7))

original.data <- bind_rows(lapply(original, import)) %>% 
  mutate(Language = rep(langs, times = langs.length))

# original 2.5 ----
original2 <- list.files("../../05_Data/data_processing/output_data/priming_data",
                       pattern = "prime_summary_no2.5.csv",
                       full.names = TRUE,
                       recursive = TRUE)

original2 <- original2[grepl(paste0(langs, "_prime_summary_no2.5.csv",
                                        collapse = "|"), original2)]
original2.data <- bind_rows(lapply(original2, import)) %>% 
  mutate(Language = rep(langs, times = langs.length))

# original 3.0 ----
original3 <- list.files("../../05_Data/data_processing/output_data/priming_data",
                       pattern = "prime_summary_no3.0.csv",
                       full.names = TRUE,
                       recursive = TRUE)

original3 <- original3[grepl(paste0(langs, "_prime_summary_no3.0.csv",
                                        collapse = "|"), original3)]
original3.data <- bind_rows(lapply(original3, import)) %>% 
  mutate(Language = rep(langs, times = langs.length))
```

```{r import-data-answered, message = F}
langs <- c("br_pt_combo", "cs", "da", "de", 
           "el", "en", "es", "fr", "hu", "it", "ja", 
           "ko", "pl", "pt_combo", 
           "ro", "ru", "sr", "tr", 
           "zh")

langs.length <- c(rep(1000, 11), 1034,
                  rep(1000, 7))

# original.answered data ----
original.answered <- list.files("../../05_Data/data_processing/output_data/priming_data",
                       pattern = "answered_prime_summary.csv",
                       full.names = TRUE,
                       recursive = TRUE)

original.answered <- original.answered[grepl(paste0(langs, "_answered_prime_summary.csv",
                                        collapse = "|"), original.answered)]
original.answered.data <- bind_rows(lapply(original.answered, import)) %>% 
  mutate(Language = rep(langs, times = langs.length))

# original.answered 2.5 ----
original.answered2 <- list.files("../../05_Data/data_processing/output_data/priming_data",
                       pattern = "answered_prime_summary_no2.5.csv",
                       full.names = TRUE,
                       recursive = TRUE)

original.answered2 <- original.answered2[grepl(paste0(langs, "_answered_prime_summary_no2.5.csv",
                                        collapse = "|"), original.answered2)]
original.answered2.data <- bind_rows(lapply(original.answered2, import)) %>% 
  mutate(Language = rep(langs, times = langs.length))

# original.answered 3.0 ----
original.answered3 <- list.files("../../05_Data/data_processing/output_data/priming_data",
                       pattern = "answered_prime_summary_no3.0.csv",
                       full.names = TRUE,
                       recursive = TRUE)

original.answered3 <- original.answered3[grepl(paste0(langs, "_answered_prime_summary_no3.0.csv",
                                        collapse = "|"), original.answered3)]
original.answered3.data <- bind_rows(lapply(original.answered3, import)) %>% 
  mutate(Language = rep(langs, times = langs.length))
```

```{r data-factor, echo = FALSE}
original.data$Language <- 
  original2.data$Language <- 
  original3.data$Language <- 
  original.answered.data$Language <- 
  original.answered2.data$Language <- 
  original.answered3.data$Language <- 
  factor(original.data$Language, 
         levels = c(langs),
         labels =  c("Brazilian Portuguese", 
                     "Czech", "Danish", 
                     "German", "Greek", 
                     "English", "Spanish", 
                     "French", "Hungarian", 
                     "Italian", "Japanese", 
                     "Korean", "Polish", 
                     "Portuguese", "Romanian", 
                     "Russian", "Serbian", 
                     "Turkish", "Simplified Chinese"))

original.data$Language_type <- 
  original2.data$Language_type <- 
  original3.data$Language_type <- 
  original.answered.data$Language_type <- 
  original.answered2.data$Language_type <- 
  original.answered3.data$Language_type <- 
  ifelse(
    original.data$Language == "Greek" | 
      original.data$Language == "Japanese" | 
      original.data$Language == "Korean" | 
      original.data$Language == "Russian" | 
      original.data$Language == "Serbian" | 
      original.data$Language == "Simplified Chinese", "Non-Latin", 
    "Latin")
```

## Hypothesis 1

```{r hyp1-original, message = F, echo = F}
# calculate vi
original.data <- escalc(
  data = original.data %>% 
    filter(!is.na(avgZ_prime)),
  measure = "MD",
  n1i = target_correct_keep_unrelated,
  n2i = target_correct_keep_related, 
  m1i = avgZ_RT_unrelated,
  m2i = avgZ_RT_related, 
  sd1i = seZ_RT_unrelated * sqrt(target_correct_keep_unrelated), 
  sd2i = seZ_RT_unrelated * sqrt(target_correct_keep_related), 
)

# fit random-effects model
original.results <- rma(yi, vi, 
                        data = original.data, 
                        test="knha", method="DL")
# original.results
```

For this supplemental analysis, we used the `metafor` package [@viechtbauer2010] to calculate the "raw" mean difference between average *Z*-scores unrelated minus average *Z*-scores related separately for each item. The standard deviations of the average *Z*-scores and sample sizes for condition by item were used to calculate the variance of the effect size necessary for meta-analysis. A random-effects meta-analysis was analyzed on the `r nrow(original.data %>% filter(!is.na(avgZ_prime)))` items with a non-zero sample size in both related and unrelated conditions using the DerSimonian-Laird estimator [@dersimonian1986]. The results suggest that the overall effect size was `r print_num(original.results$beta[1], digits = 3)` 95% *CI* [`r print_num(original.results$ci.lb, digits = 3)`, `r print_num(original.results$ci.ub, digits = 3)`]. This results supports Hypothesis 1.

## Hypothesis 2

```{r hyp2-original, message = F, echo = F, eval = F, warning = FALSE}
# run the model
original.results.h2 <- rma.mv(yi, vi, 
                              model = ~ 1 | Language, 
                              data = original.data)

original.results.h2
save(original.results.h2, file = "rma_mv.RData")
getwd()

# Multivariate Meta-Analysis Model (k = 18999; method: REML)
# 
# Variance Components: none
# 
# Test for Heterogeneity:
# Q(df = 18998) = 62842.4774, p-val < .0001
# 
# Model Results:
# 
# estimate      se     zval    pval   ci.lb   ci.ub      
#   0.0647  0.0007  89.7717  <.0001  0.0633  0.0661  *** 
# 
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
```


```{r hyp2-load, message = F, echo = F, warning = FALSE}
load(file = "rma_mv.RData")
# Multivariate Meta-Analysis Model (k = 18999; method: REML)
# 
# Variance Components: none
# 
# Test for Heterogeneity:
# Q(df = 18998) = 62842.4774, p-val < .0001
# 
# Model Results:
# 
# estimate      se     zval    pval   ci.lb   ci.ub      
#   0.0647  0.0007  89.7717  <.0001  0.0633  0.0661  *** 
# 
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
```

For Hypothesis 2, we added a random intercept of language to the random effects model used in Hypothesis 1. The results suggest that the overall effect size was `r print_num(original.results.h2$beta[1], digits = 3)` 95% *CI* [`r print_num(original.results.h2$ci.lb, digits = 3)`, `r print_num(original.results.h2$ci.ub, digits = 3)`] after controlling for the random intercept of language. The test for heterogeneity was significant *Q*(*df* = 18998) = 62842.4774, *p* < .0001, thus, supporting hypothesis 2. 

## References
