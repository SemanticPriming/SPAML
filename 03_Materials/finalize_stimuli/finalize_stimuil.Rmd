---
title: "Finalize Stimuli"
author: "Erin M. Buchanan"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This document takes in the translations for each of the finished languages, updates the stimuli so they are consistent across languages, and creates the trials for each language. 

## Libraries

```{r}
library(rio)
library(stringi)
library(lsa)
library(dplyr)
# library(quanteda)
# library(sylly)
# library(tidytext)
# library(tidyr)
# library(stringr)
# library(stringdist)
```

Note: all models were downloaded from subs2vec github and stored on a separate drive, as they are very large. Also, this document is in the order that we added languages, not alphabetical like the other documents.

## en English

For English, we need to correct:
  
  - The fake trials that are not appropriate (fixed)
  - The unrelated trials in ensure a low cosine 
  
```{r eval = F}
# original words
en <- import("en/en_translate.csv")

# fix fake words ----
en_update <- import("en/en_translate_checked.xlsx")
cue_fix <- 
  bind_rows(
    (en_update %>% 
      filter(cue_vowel == "no") %>%
      select(en_cue, en_fake_cue)),
    (en_update %>% 
      filter(en_update$cue_pronounce == "no") %>% 
      select(en_cue, en_fake_cue)), 
    (en_update %>% 
       filter(cue_real == "yes") %>% 
       select(en_cue, en_fake_cue))
  ) %>% unique()

target_fix <- 
  bind_rows(
    (en_update %>% 
      filter(target_vowel == "no") %>%
      select(en_target, en_fake_target)),
    (en_update %>% 
      filter(en_update$target_pronounce == "no") %>% 
      select(en_target, en_fake_target)), 
    (en_update %>% 
       filter(target_real == "yes") %>% 
       select(en_target, en_fake_target))
  ) %>% unique()

# export(bind_rows(cue_fix, target_fix), "en/en_tofix.csv")
en_update <- import("en/en_tofix_fixed.csv")

cues <- en_update %>% filter(en_fake_cue != "")
for (i in 1:nrow(cues)){
  ru$en_fake_cue[ru$en_fake_cue == cues$en_fake_cue[i]
                 & ru$en_cue == cues$en_cue[i]] <- cues$fixed[i]
}

targets <- en_update %>% filter(en_fake_target != "")
for (i in 1:nrow(targets)){
  ru$en_fake_target[ru$en_fake_target == targets$en_fake_target[i]
                    & ru$en_target == targets$en_target[i]] <- targets$fixed[i]
}

# create possible trials ----
# en_trials <- en[ , c("en_cue", "en_target")]
# en_trials$type <- "related"
# en_trials$cue_type <- "word"
# en_trials$target_type <- "word"
# 
# en_trials <- rbind(en_trials,
#                    data.frame(en_cue = ru$en_cue, 
#                               en_target = ru$en_target[sample(1:1000, 
#                                                               1000)],
#                               type = "unrelated",
#                               cue_type = "word", 
#                               target_type = "word"), 
#                    data.frame(en_cue = ru$en_fake_cue, 
#                               en_target = ru$en_target[sample(1:1000, 
#                                                               1000)],
#                               type = "nonword",
#                               cue_type = "nonword", 
#                               target_type = "word"),
#                    data.frame(en_cue = ru$en_cue[sample(1:1000,
#                                                         1000)], 
#                               en_target = ru$en_fake_target,
#                               type = "nonword",
#                               cue_type = "word", 
#                               target_type = "nonword"),
#                    data.frame(en_cue = ru$en_fake_cue[sample(1:1000,
#                                                         1000)], 
#                               en_target = ru$en_fake_target[sample(1:1000,
#                                                         1000)],
#                               type = "nonword",
#                               cue_type = "nonword", 
#                               target_type = "nonword"))
# 
# # check dups run until 0
# sum(duplicated(en_trials[ , c("en_cue", "en_target")]))

# update with low cosines from random shuffle ----
# set up model
en_model <- read.table("/Volumes/SPAML Backup/subs_vec/en/subs.en.1e6.txt", quote="\"")
en_model <- na.omit(en_model)
en_model$V1 <- tolower(en_model$V1)
en_model <- en_model[!duplicated(en_model$V1), ]
rownames(en_model) <- en_model$V1
en_model <- en_model[ , -1]

en_trials$en_cosine <- NA

# get cosine
for (row in 1:nrow(en_trials)){
  
  if(en_trials$type[row] != "nonword") { 
    
    en_trials$en_cosine[row] <- cosine(as.matrix(t(en_model[
    c(en_trials$en_cue[row], en_trials$en_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
en_trials$ok <- TRUE
en_trials$ok[en_trials$type == "unrelated" & abs(en_trials$en_cosine) > .15] <- FALSE

good_trials <- en_trials %>% filter(ok == TRUE)
bad_trials <- en_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I evened out 
bad_trials$en_target <- sample(bad_trials$en_target, 
                               size = length(bad_trials$en_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$en_cosine[row] <- cosine(as.matrix(t(en_model[
    c(bad_trials$en_cue[row], bad_trials$en_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(en_cosine < .15)))
bad_trials <- bad_trials %>% filter(en_cosine >= .15)
# end section I ran multiple times 

whats_left <- cosine(as.matrix(t(en_model[c(
  bad_trials$en_target,
  unique(good_trials$en_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$en_target)){
  
  # find all words that could be paired with bad en_target
  # as updated en_cue
  potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$en_target[i]] < .15] 
  
  # find all pairs of good en_target that could
  # be paired with bad en_cue
  potential_switch <- good_trials %>% filter(en_cue %in% potential_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(en_model[c(
    bad_trials$en_cue[i],
    potential_switch$en_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$en_cue[i], bad_trials$en_target[i],
    potential_switch$en_cue[potential_switch$en_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_en_cue", "bad_en_target", 
                           "good_en_cue", "good_en_target")

good_trials_small <- good_trials %>% 
  filter(!(en_cue %in% switch_todo$good_en_cue & type == "unrelated"))

new_good_trials <- data.frame(
  en_cue = c(switch_todo$bad_en_cue, switch_todo$good_en_cue),
  en_target = c(switch_todo$good_en_target, switch_todo$bad_en_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  en_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$en_cosine[row] <- cosine(as.matrix(t(en_model[
    c(new_good_trials$en_cue[row], new_good_trials$en_target[row]) , ])))[2]
}

en_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(en_final[ , c("en_cue", "en_target")]))


tapply(en_final$en_cosine, en_final$type, mean, na.rm = T)
tapply(en_final$en_cosine, en_final$type, min, na.rm = T)
tapply(en_final$en_cosine, en_final$type, max, na.rm = T)

en_final$ok <- NULL

export(en_final, "en/en_trials_final.csv")
```

## ru Russian 

```{r eval = F}
# original words
ru <- import("ru/ru_translate.csv")

# fix real words ----
ru_update <- import("ru/ru_translated_AK.xlsx")

cues <- ru_update %>% filter(ru_cue_trans != "")
for (i in 1:nrow(cues)){
  ru$ru_cue[ru$ru_cue == cues$ru_cue[i] #original cue match
            & ru$en_cue == cues$en_cue[i]] <- #english match 
    cues$ru_cue_trans[i] #new cue 
}

targets <- ru_update %>% filter(ru_target_trans != "")
for (i in 1:nrow(targets)){
  ru$ru_target[ru$ru_target == targets$ru_target[i] #original target match
            & ru$en_target == targets$en_target[i]] <- #english match 
    targets$ru_target_trans[i] #new target 
}

# # fix fake words ----
# cues <- ru_update %>% filter(ru_fake_cue_trans != "")
# for (i in 1:nrow(cues)){
#   ru$ru_fake_cue[ru$ru_fake_cue == cues$ru_fake_cue[i] #original cue match
#             & ru$en_cue == cues$en_cue[i]] <- #english match 
#     cues$ru_fake_cue_trans[i] #new cue 
# }
# 
# targets <- ru_update %>% filter(ru_fake_target_trans != "")
# for (i in 1:nrow(targets)){
#   ru$ru_fake_target[ru$ru_fake_target == targets$ru_fake_target[i] #original target match
#             & ru$en_target == targets$en_target[i]] <- #english match 
#     targets$ru_fake_target_trans[i] #new target 
# }

ru$ru_fake_target <- ru_update$ru_fake_target_fix
ru$ru_fake_cue <- ru_update$ru_fake_cue_fix

sum(duplicated(ru$ru_cue))
sum(duplicated(ru$ru_target))
sum(duplicated(ru$ru_fake_cue))
sum(duplicated(ru$ru_fake_target))

# create possible trials ----
ru_trials <- ru[ , c("ru_cue", "ru_target")]
ru_trials$type <- "related"
ru_trials$cue_type <- "word"
ru_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
ru$en_cue <- tolower(ru$en_cue)
ru$en_target <- tolower(ru$en_target)
# match unrelated pairs as a start 
ru_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(ru_unrelated)){
  ru_unrelated$en_cue[i] <- ru$ru_cue[ru$en_cue == ru_unrelated$en_cue[i]]
  ru_unrelated$en_target[i] <- ru$ru_target[ru$en_target == ru_unrelated$en_target[i]]
}

ru_trials <- rbind(ru_trials,
                   ru_unrelated %>% select(-en_cosine) %>% 
                     rename("ru_cue" = "en_cue", 
                            "ru_target" = "en_target"), 
                   data.frame(ru_cue = ru$ru_fake_cue,
                              ru_target = ru$ru_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(ru_cue = ru$ru_cue[sample(1:1000,
                                                        1000)],
                              ru_target = ru$ru_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(ru_cue = ru$ru_fake_cue[sample(1:1000,
                                                        1000)],
                              ru_target = ru$ru_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(ru_trials[ , c("ru_cue", "ru_target")]))

# update with low cosines from random shuffle ----
# set up model
ru_model <- read.table("/Volumes/SPAML Backup/subs_vec/ru/subs.ru.1e6.txt", quote="\"")
ru_model <- na.omit(ru_model)
ru_model$V1 <- tolower(ru_model$V1)
ru_model <- ru_model[!duplicated(ru_model$V1), ]
rownames(ru_model) <- ru_model$V1
ru_model <- ru_model[ , -1]

ru_trials$ru_cosine <- NA

# get cosine
for (row in 1:nrow(ru_trials)){
  
  if(ru_trials$type[row] != "nonword") { 
    
    ru_trials$ru_cosine[row] <- cosine(as.matrix(t(ru_model[
    c(ru_trials$ru_cue[row], ru_trials$ru_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
ru_trials$ok <- TRUE
ru_trials$ok[ru_trials$type == "unrelated" & abs(ru_trials$ru_cosine) > .15] <- FALSE

good_trials <- ru_trials %>% filter(ok == TRUE)
bad_trials <- ru_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$ru_target <- sample(bad_trials$ru_target, 
                               size = length(bad_trials$ru_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$ru_cosine[row] <- cosine(as.matrix(t(ru_model[
    c(bad_trials$ru_cue[row], bad_trials$ru_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(ru_cosine < .15)))
bad_trials <- bad_trials %>% filter(ru_cosine >= .15)
nrow(bad_trials)
# rud section I ran multiple times 

whats_left <- cosine(as.matrix(t(ru_model[c(
  bad_trials$ru_target,
  unique(good_trials$ru_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$ru_target)){
  
  # find all words that could be paired with bad ru_target
  # as updated ru_cue
  potrutial_cues <- rownames(whats_left)[whats_left[ , bad_trials$ru_target[i]] < .15] 
  
  # find all pairs of good ru_target that could
  # be paired with bad ru_cue
  potrutial_switch <- good_trials %>% filter(ru_cue %in% potrutial_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(ru_model[c(
    bad_trials$ru_cue[i],
    potrutial_switch$ru_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$ru_cue[i], bad_trials$ru_target[i],
    potrutial_switch$ru_cue[potrutial_switch$ru_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_ru_cue", "bad_ru_target", 
                           "good_ru_cue", "good_ru_target")

good_trials_small <- good_trials %>% 
  filter(!(ru_cue %in% switch_todo$good_ru_cue & type == "unrelated"))

new_good_trials <- data.frame(
  ru_cue = c(switch_todo$bad_ru_cue, switch_todo$good_ru_cue),
  ru_target = c(switch_todo$good_ru_target, switch_todo$bad_ru_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  ru_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$ru_cosine[row] <- cosine(as.matrix(t(ru_model[
    c(new_good_trials$ru_cue[row], new_good_trials$ru_target[row]) , ])))[2]
}

ru_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(ru_final[ , c("ru_cue", "ru_target")]))


tapply(ru_final$ru_cosine, ru_final$type, mean, na.rm = T)
tapply(ru_final$ru_cosine, ru_final$type, min, na.rm = T)
tapply(ru_final$ru_cosine, ru_final$type, max, na.rm = T)

ru_final$ok <- NULL

export(ru_final, "ru/ru_trials_final.csv")
```

## tr Turkish

```{r eval = F}
# original words
tr <- import("tr/tr_translate.csv")

# fix real words ----
# tr_update <- import("tr/tr_translated_Aslan.xlsx") second person added to this file 
tr_update <- import("tr/tr_translated_Elif.xlsx")

cues <- tr_update %>% filter(tr_cue_update != "")
for (i in 1:nrow(cues)){
  tr$tr_cue[tr$tr_cue == cues$tr_cue[i] #original cue match
            & tr$en_cue == cues$en_cue[i]] <- #english match 
    cues$tr_cue_update[i] #new cue 
}

targets <- tr_update %>% filter(tr_target_update != "")
for (i in 1:nrow(targets)){
  tr$tr_target[tr$tr_target == targets$tr_target[i] #original target match
            & tr$en_target == targets$en_target[i]] <- #english match 
    targets$tr_target_update[i] #new target 
}

# find matches and edit
tr %>% filter(tr_cue == tr_target)

# fix fake words ----
cues <- tr_update %>% filter(tr_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  tr$tr_fake_cue[tr$tr_fake_cue == cues$tr_fake_cue[i] #original cue match
            & tr$en_cue == cues$en_cue[i]] <- #english match 
    cues$tr_fake_cue_trans[i] #new cue 
}

targets <- tr_update %>% filter(tr_fake_target_trans != "")
for (i in 1:nrow(targets)){
  tr$tr_fake_target[tr$tr_fake_target == targets$tr_fake_target[i] #original target match
            & tr$en_target == targets$en_target[i]] <- #english match 
    targets$tr_fake_target_trans[i] #new target 
}

sum(duplicated(tr$tr_cue))
sum(duplicated(tr$tr_target))
sum(duplicated(tr$tr_fake_cue))
sum(duplicated(tr$tr_fake_target))

# create possible trials ----
tr_trials <- tr[ , c("tr_cue", "tr_target")]
tr_trials$type <- "related"
tr_trials$cue_type <- "word"
tr_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
tr$en_cue <- tolower(tr$en_cue)
tr$en_target <- tolower(tr$en_target)
# match unrelated pairs as a start 
tr_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(tr_unrelated)){
  tr_unrelated$en_cue[i] <- tr$tr_cue[tr$en_cue == tr_unrelated$en_cue[i]]
  tr_unrelated$en_target[i] <- tr$tr_target[tr$en_target == tr_unrelated$en_target[i]]
}

tr_trials <- rbind(tr_trials,
                   tr_unrelated %>% select(-en_cosine) %>% 
                     rename("tr_cue" = "en_cue", 
                            "tr_target" = "en_target"), 
                   data.frame(tr_cue = tr$tr_fake_cue,
                              tr_target = tr$tr_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(tr_cue = tr$tr_cue[sample(1:1000,
                                                        1000)],
                              tr_target = tr$tr_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(tr_cue = tr$tr_fake_cue[sample(1:1000,
                                                        1000)],
                              tr_target = tr$tr_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(tr_trials[ , c("tr_cue", "tr_target")]))

# update with low cosines from random shuffle ----
# set up model
tr_model <- read.table("/Volumes/SPAML Backup/subs_vec/tr/subs.tr.1e6.txt", quote="\"")
tr_model <- na.omit(tr_model)
tr_model$V1 <- tolower(tr_model$V1)
tr_model <- tr_model[!duplicated(tr_model$V1), ]
rownames(tr_model) <- tr_model$V1
tr_model <- tr_model[ , -1]

tr_trials$tr_cosine <- NA

# get cosine
for (row in 1:nrow(tr_trials)){
  
  if(tr_trials$type[row] != "nonword") { 
    
    tr_trials$tr_cosine[row] <- cosine(as.matrix(t(tr_model[
    c(tr_trials$tr_cue[row], tr_trials$tr_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
tr_trials$ok <- TRUE
tr_trials$ok[tr_trials$type == "unrelated" & abs(tr_trials$tr_cosine) > .15] <- FALSE

good_trials <- tr_trials %>% filter(ok == TRUE)
bad_trials <- tr_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$tr_target <- sample(bad_trials$tr_target, 
                               size = length(bad_trials$tr_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$tr_cosine[row] <- cosine(as.matrix(t(tr_model[
    c(bad_trials$tr_cue[row], bad_trials$tr_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(tr_cosine < .15)))
bad_trials <- bad_trials %>% filter(tr_cosine >= .15)
nrow(bad_trials)
# end section I ran multiple times 

whats_left <- cosine(as.matrix(t(tr_model[c(
  bad_trials$tr_target,
  unique(good_trials$tr_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$tr_target)){
  
  # find all words that could be paired with bad tr_target
  # as updated tr_cue
  potrutial_cues <- rownames(whats_left)[whats_left[ , bad_trials$tr_target[i]] < .15] 
  
  # find all pairs of good tr_target that could
  # be paired with bad tr_cue
  potrutial_switch <- good_trials %>% filter(tr_cue %in% potrutial_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(tr_model[c(
    bad_trials$tr_cue[i],
    potrutial_switch$tr_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$tr_cue[i], bad_trials$tr_target[i],
    potrutial_switch$tr_cue[potrutial_switch$tr_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_tr_cue", "bad_tr_target", 
                           "good_tr_cue", "good_tr_target")

good_trials_small <- good_trials %>% 
  filter(!(tr_cue %in% switch_todo$good_tr_cue & type == "unrelated"))

new_good_trials <- data.frame(
  tr_cue = c(switch_todo$bad_tr_cue, switch_todo$good_tr_cue),
  tr_target = c(switch_todo$good_tr_target, switch_todo$bad_tr_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  tr_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$tr_cosine[row] <- cosine(as.matrix(t(tr_model[
    c(new_good_trials$tr_cue[row], new_good_trials$tr_target[row]) , ])))[2]
}

tr_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(tr_final[ , c("tr_cue", "tr_target")]))


tapply(tr_final$tr_cosine, tr_final$type, mean, na.rm = T)
tapply(tr_final$tr_cosine, tr_final$type, min, na.rm = T)
tapply(tr_final$tr_cosine, tr_final$type, max, na.rm = T)

tr_final$ok <- NULL

export(tr_final, "tr/tr_trials_final.csv")
```

## ko Korean

```{r eval = F}
# original words
# don't use the original trials because there are lot of weird typos
# that were clearly fixed in the translated sheet
ko <- import("ko/ko_translated.xlsx")
ko_temp <- import("ko/ko_translate.csv")
ko <- ko %>% select(colnames(ko_temp))

# fix real words ----
ko_update <- import("ko/ko_translated.xlsx")

cues <- ko_update %>% filter(ko_cue_trans != "")
for (i in 1:nrow(cues)){
  ko$ko_cue[ko$ko_cue == cues$ko_cue[i] #original cue match
            & ko$en_cue == cues$en_cue[i]] <- #english match 
    cues$ko_cue_trans[i] #new cue 
}

targets <- ko_update %>% filter(ko_target_trans != "")
for (i in 1:nrow(targets)){
  ko$ko_target[ko$ko_target == targets$ko_target[i] #original target match
            & ko$en_target == targets$en_target[i]] <- #english match 
    targets$ko_target_trans[i] #new target 
}

# find matches and edit
ko %>% filter(ko_cue == ko_target)

# fix fake words ----
cues <- ko_update %>% filter(ko_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  ko$ko_fake_cue[ko$ko_fake_cue == cues$ko_fake_cue[i] #original cue match
            & ko$en_cue == cues$en_cue[i]] <- #english match 
    cues$ko_fake_cue_trans[i] #new cue 
}

targets <- ko_update %>% filter(ko_fake_target_trans != "")
for (i in 1:nrow(targets)){
  ko$ko_fake_target[ko$ko_fake_target == targets$ko_fake_target[i] #original target match
            & ko$en_target == targets$en_target[i]] <- #english match 
    targets$ko_fake_target_trans[i] #new target 
}

sum(duplicated(ko$ko_cue))
sum(duplicated(ko$ko_target))
sum(duplicated(ko$ko_fake_cue))
sum(duplicated(ko$ko_fake_target))

# create possible trials ----
ko_trials <- ko[ , c("ko_cue", "ko_target")]
ko_trials$type <- "related"
ko_trials$cue_type <- "word"
ko_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
ko$en_cue <- tolower(ko$en_cue)
ko$en_target <- tolower(ko$en_target)
# match unrelated pairs as a start 
ko_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(ko_unrelated)){
  ko_unrelated$en_cue[i] <- ko$ko_cue[ko$en_cue == ko_unrelated$en_cue[i]]
  ko_unrelated$en_target[i] <- ko$ko_target[ko$en_target == ko_unrelated$en_target[i]]
}

ko_trials <- rbind(ko_trials,
                   ko_unrelated %>% select(-en_cosine) %>% 
                     rename("ko_cue" = "en_cue", 
                            "ko_target" = "en_target"), 
                   data.frame(ko_cue = ko$ko_fake_cue,
                              ko_target = ko$ko_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(ko_cue = ko$ko_cue[sample(1:1000,
                                                        1000)],
                              ko_target = ko$ko_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(ko_cue = ko$ko_fake_cue[sample(1:1000,
                                                        1000)],
                              ko_target = ko$ko_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(ko_trials[ , c("ko_cue", "ko_target")]))

# update with low cosines from random shuffle ----
# set up model
ko_model <- read.table("/Volumes/SPAML Backup/subs_vec/ko/subs.ko.1e6.txt", quote="\"")
ko_model <- na.omit(ko_model)
ko_model$V1 <- tolower(ko_model$V1)
ko_model <- ko_model[!duplicated(ko_model$V1), ]
rownames(ko_model) <- ko_model$V1
ko_model <- ko_model[ , -1]

ko_trials$ko_cosine <- NA

# get cosine
for (row in 1:nrow(ko_trials)){
  
  if(ko_trials$type[row] != "nonword") { 
    
    ko_trials$ko_cosine[row] <- cosine(as.matrix(t(ko_model[
    c(ko_trials$ko_cue[row], ko_trials$ko_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
# if they are NA, they are zero 
ko_trials$ko_cosine[is.na(ko_trials$ko_cosine) & ko_trials$type == "unrelated"] <- 0
ko_trials$ok <- TRUE
ko_trials$ok[ko_trials$type == "unrelated" & abs(ko_trials$ko_cosine) > .15] <- FALSE

good_trials <- ko_trials %>% filter(ok == TRUE)
bad_trials <- ko_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$ko_target <- sample(bad_trials$ko_target, 
                               size = length(bad_trials$ko_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$ko_cosine[row] <- cosine(as.matrix(t(ko_model[
    c(bad_trials$ko_cue[row], bad_trials$ko_target[row]) , ])))[2]
}

# deal with zeros 
bad_trials$ko_cosine[is.na(bad_trials$ko_cosine)] <- 0
bad_trials$ko_cosine[bad_trials$ko_target == "땡땡"] <- 0
bad_trials$ko_cosine[bad_trials$ko_target == "버리다"] <- 0

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(ko_cosine < .15))) # update to 20
bad_trials <- bad_trials %>% filter(ko_cosine >= .15)
nrow(bad_trials)

whats_left <- cosine(as.matrix(t(ko_model[c(
  bad_trials$ko_target,
  unique(good_trials$ko_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$ko_target)){
  
  # find all words that could be paired with bad ko_target
  potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$ko_target[i]] < .20] 
  
  # find all pairs of good ko_target that could
  # be paired with bad ko_cue
  potential_switch <- good_trials %>% filter(ko_cue %in% potential_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(ko_model[c(
    bad_trials$ko_cue[i],
    potential_switch$ko_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$ko_cue[i], bad_trials$ko_target[i],
    potential_switch$ko_cue[potential_switch$ko_target == new_target][1],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_ko_cue", "bad_ko_target", 
                           "good_ko_cue", "good_ko_target")

good_trials_small <- good_trials %>% 
  filter(!(ko_cue %in% switch_todo$good_ko_cue & type == "unrelated")) 

new_good_trials <- data.frame(
  ko_cue = c(switch_todo$bad_ko_cue, switch_todo$good_ko_cue),
  ko_target = c(switch_todo$good_ko_target, switch_todo$bad_ko_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  ko_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$ko_cosine[row] <- cosine(as.matrix(t(ko_model[
    c(new_good_trials$ko_cue[row], new_good_trials$ko_target[row]) , ])))[2]
}

# creates too many so sample 
ko_final <- bind_rows(good_trials_small, new_good_trials[sample(1:nrow(new_good_trials), 5000-nrow(good_trials_small), replace = F), ])
sum(duplicated(ko_final[ , c("ko_cue", "ko_target")]))

tapply(ko_final$ko_cosine, ko_final$type, mean, na.rm = T)
tapply(ko_final$ko_cosine, ko_final$type, min, na.rm = T)
tapply(ko_final$ko_cosine, ko_final$type, max, na.rm = T)

ko_final$ok <- NULL

export(ko_final, "ko/ko_trials_final.csv")
```

## cs Czech

```{r eval = F}
# original words
# make sure to use the translated sheet so we don't have issues 
# that were clearly fixed in the translated sheet
cs <- import("cs/cs_update2.xlsx")
cs_temp <- import("cs/cs_translate.csv")
cs <- cs %>% select(colnames(cs_temp))

# fix real words ----
cs_update <- import("cs/cs_update2.xlsx")

cues <- cs_update %>% filter(cs_cue_final != "")
for (i in 1:nrow(cues)){
  cs$cs_cue[cs$cs_cue == cues$cs_cue[i] #original cue match
            & cs$en_cue == cues$en_cue[i]] <- #english match 
    cues$cs_cue_final[i] #new cue 
}

targets <- cs_update %>% filter(cs_target_final != "")
for (i in 1:nrow(targets)){
  cs$cs_target[cs$cs_target == targets$cs_target[i] #original target match
            & cs$en_target == targets$en_target[i]] <- #english match 
    targets$cs_target_final[i] #new target 
}

# find matches and edit
cs %>% filter(cs_cue == cs_target)

# fix fake words ----
cues <- cs_update %>% filter(cs_fake_cue_final != "")
for (i in 1:nrow(cues)){
  cs$cs_fake_cue[cs$cs_fake_cue == cues$cs_fake_cue[i] #original cue match
            & cs$en_cue == cues$en_cue[i]] <- #english match 
    cues$cs_fake_cue_final[i] #new cue 
}

targets <- cs_update %>% filter(cs_fake_target_final != "")
for (i in 1:nrow(targets)){
  cs$cs_fake_target[cs$cs_fake_target == targets$cs_fake_target[i] #original target match
            & cs$en_target == targets$en_target[i]] <- #english match 
    targets$cs_fake_target_final[i] #new target 
}

cues <- cs_update %>% filter(cs_fake_cue_final2 != "")
for (i in 1:nrow(cues)){
  cs$cs_fake_cue[cs$cs_fake_cue == cues$cs_fake_cue[i] #original cue match
            & cs$en_cue == cues$en_cue[i]] <- #english match 
    cues$cs_fake_cue_final2[i] #new cue 
}

targets <- cs_update %>% filter(cs_fake_target_final2 != "")
for (i in 1:nrow(targets)){
  cs$cs_fake_target[cs$cs_fake_target == targets$cs_fake_target[i] #original target match
            & cs$en_target == targets$en_target[i]] <- #english match 
    targets$cs_fake_target_final2[i] #new target 
}


sum(duplicated(cs$cs_cue))
sum(duplicated(cs$cs_target))
sum(duplicated(cs$cs_fake_cue))
sum(duplicated(cs$cs_fake_target))

# create possible trials ----
cs_trials <- cs[ , c("cs_cue", "cs_target")]
cs_trials$type <- "related"
cs_trials$cue_type <- "word"
cs_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
cs$en_cue <- tolower(cs$en_cue)
cs$en_target <- tolower(cs$en_target)
# match unrelated pairs as a start 
cs_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(cs_unrelated)){
  cs_unrelated$en_cue[i] <- cs$cs_cue[cs$en_cue == cs_unrelated$en_cue[i]]
  cs_unrelated$en_target[i] <- cs$cs_target[cs$en_target == cs_unrelated$en_target[i]]
}

cs_trials <- rbind(cs_trials,
                   cs_unrelated %>% select(-en_cosine) %>% 
                     rename("cs_cue" = "en_cue", 
                            "cs_target" = "en_target"), 
                   data.frame(cs_cue = cs$cs_fake_cue,
                              cs_target = cs$cs_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(cs_cue = cs$cs_cue[sample(1:1000,
                                                        1000)],
                              cs_target = cs$cs_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(cs_cue = cs$cs_fake_cue[sample(1:1000,
                                                        1000)],
                              cs_target = cs$cs_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(cs_trials[ , c("cs_cue", "cs_target")]))

# update with low cosines from random shuffle ----
# set up model
cs_model <- read.table("/Volumes/SPAML Backup/subs_vec/cs/subs.cs.1e6.txt", quote="\"")
cs_model <- na.omit(cs_model)
cs_model$V1 <- tolower(cs_model$V1)
cs_model <- cs_model[!duplicated(cs_model$V1), ]
rownames(cs_model) <- cs_model$V1
cs_model <- cs_model[ , -1]

cs_trials$cs_cosine <- NA

# get cosine
for (row in 1:nrow(cs_trials)){
  
  if(cs_trials$type[row] != "nonword") { 
    
    cs_trials$cs_cosine[row] <- cosine(as.matrix(t(cs_model[
    c(cs_trials$cs_cue[row], cs_trials$cs_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
# if they are NA, they are zero 
cs_trials$cs_cosine[is.na(cs_trials$cs_cosine) & cs_trials$type == "unrelated"] <- 0
cs_trials$ok <- TRUE
cs_trials$ok[cs_trials$type == "unrelated" & abs(cs_trials$cs_cosine) > .15] <- FALSE

good_trials <- cs_trials %>% filter(ok == TRUE)
bad_trials <- cs_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$cs_target <- sample(bad_trials$cs_target, 
                               size = length(bad_trials$cs_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$cs_cosine[row] <- cosine(as.matrix(t(cs_model[
    c(bad_trials$cs_cue[row], bad_trials$cs_target[row]) , ])))[2]
}

# deal with zeros 
bad_trials$cs_cosine[is.na(bad_trials$cs_cosine)] <- 0

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(cs_cosine < .15))) # update to 20
bad_trials <- bad_trials %>% filter(cs_cosine >= .15)
nrow(bad_trials)

whats_left <- cosine(as.matrix(t(cs_model[c(
  bad_trials$cs_target,
  unique(good_trials$cs_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$cs_target)){
  
  # find all words that could be paired with bad cs_target
  potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$cs_target[i]] < .20] 
  
  # find all pairs of good cs_target that could
  # be paired with bad cs_cue
  potential_switch <- good_trials %>% filter(cs_cue %in% potential_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(cs_model[c(
    bad_trials$cs_cue[i],
    potential_switch$cs_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$cs_cue[i], bad_trials$cs_target[i],
    potential_switch$cs_cue[potential_switch$cs_target == new_target][1],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_cs_cue", "bad_cs_target", 
                           "good_cs_cue", "good_cs_target")

good_trials_small <- good_trials %>% 
  filter(!(cs_cue %in% switch_todo$good_cs_cue & type == "unrelated")) 

new_good_trials <- data.frame(
  cs_cue = c(switch_todo$bad_cs_cue, switch_todo$good_cs_cue),
  cs_target = c(switch_todo$good_cs_target, switch_todo$bad_cs_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  cs_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$cs_cosine[row] <- cosine(as.matrix(t(cs_model[
    c(new_good_trials$cs_cue[row], new_good_trials$cs_target[row]) , ])))[2]
}

# creates too many so sample 
cs_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(cs_final[ , c("cs_cue", "cs_target")]))

tapply(cs_final$cs_cosine, cs_final$type, mean, na.rm = T)
tapply(cs_final$cs_cosine, cs_final$type, min, na.rm = T)
tapply(cs_final$cs_cosine, cs_final$type, max, na.rm = T)

cs_final$ok <- NULL

export(cs_final, "cs/cs_trials_final.csv")
```

## ja Japanese

```{r eval = F}
# original words the japanese team did this for me
ja <- import("ja/ja_translated_final.xlsx")
colnames(ja) <- gsub("_final", "", colnames(ja))

ja %>% filter(ja_cue == ja_target)

sum(duplicated(ja$ja_cue))
sum(duplicated(ja$ja_target))
sum(duplicated(ja$ja_fake_cue))
sum(duplicated(ja$ja_fake_target))

# create possible trials ----
ja_trials <- ja[ , c("ja_cue", "ja_target")]
ja_trials$type <- "related"
ja_trials$cue_type <- "word"
ja_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
ja$en_cue <- tolower(ja$en_cue)
ja$en_target <- tolower(ja$en_target)
# match unrelated pairs as a start 
ja_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(ja_unrelated)){
  ja_unrelated$en_cue[i] <- ja$ja_cue[ja$en_cue == ja_unrelated$en_cue[i]]
  ja_unrelated$en_target[i] <- ja$ja_target[ja$en_target == ja_unrelated$en_target[i]]
}

ja_trials <- rbind(ja_trials,
                   ja_unrelated %>% select(-en_cosine) %>% 
                     rename("ja_cue" = "en_cue", 
                            "ja_target" = "en_target"), 
                   data.frame(ja_cue = ja$ja_fake_cue,
                              ja_target = ja$ja_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(ja_cue = ja$ja_cue[sample(1:1000,
                                                        1000)],
                              ja_target = ja$ja_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(ja_cue = ja$ja_fake_cue[sample(1:1000,
                                                        1000)],
                              ja_target = ja$ja_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(ja_trials[ , c("ja_cue", "ja_target")]))

# update with low cosines from random shuffle ----
# set up model
ja_model <- import("/Volumes/SPAML Backup/subs_vec/ja/ja_300_5_sg_wxd.csv")
ja_model <- na.omit(ja_model)
ja_model$V1 <- tolower(ja_model$V1)
ja_model <- ja_model[-1 , ]
ja_model <- ja_model[!duplicated(ja_model$V1), ]
rownames(ja_model) <- ja_model$V1
ja_model <- ja_model[ , -1]

ja_trials$ja_cosine <- NA

# get cosine
for (row in 1:nrow(ja_trials)){
  
  if(ja_trials$type[row] != "nonword") { 
    
    if (ja_trials$ja_cue[row] %in% rownames(ja_model) & 
        ja_trials$ja_target[row] %in% rownames(ja_model)){
    ja_trials$ja_cosine[row] <- cosine(as.matrix(t(ja_model[
    c(ja_trials$ja_cue[row], ja_trials$ja_target[row]) , ])))[2]
    } else { 
      ja_trials$ja_cosine[row] <- 0 
    }
    
  }
  
}

# update trials that have cosines too big 
ja_trials$ok <- TRUE
ja_trials$ok[ja_trials$type == "unrelated" & abs(ja_trials$ja_cosine) > .15] <- FALSE

good_trials <- ja_trials %>% filter(ok == TRUE)
bad_trials <- ja_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$ja_target <- sample(bad_trials$ja_target, 
                               size = length(bad_trials$ja_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
  
    if (bad_trials$ja_cue[row] %in% rownames(ja_model) & 
        bad_trials$ja_target[row] %in% rownames(ja_model)){
    bad_trials$ja_cosine[row] <- cosine(as.matrix(t(ja_model[
    c(bad_trials$ja_cue[row], bad_trials$ja_target[row]) , ])))[2]
    } else { 
      bad_trials$ja_cosine[row] <- 0 
    }
}

# deal with zeros 
bad_trials$ja_cosine[is.na(bad_trials$ja_cosine)] <- 0

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(ja_cosine < .50))) # update to 20
bad_trials <- bad_trials %>% filter(ja_cosine >= .50)
nrow(bad_trials)

whats_left <- cosine(as.matrix(t(ja_model[c(
  bad_trials$ja_target,
  unique(good_trials$ja_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

# just deal with the wild JA ones 
ja_final <- bind_rows(good_trials, bad_trials)
sum(duplicated(ja_final[ , c("ja_cue", "ja_target")]))

tapply(ja_final$ja_cosine, ja_final$type, mean, na.rm = T)
tapply(ja_final$ja_cosine, ja_final$type, min, na.rm = T)
tapply(ja_final$ja_cosine, ja_final$type, max, na.rm = T)

ja_final$ok <- NULL

export(ja_final, "ja/ja_trials_final.csv")
```

