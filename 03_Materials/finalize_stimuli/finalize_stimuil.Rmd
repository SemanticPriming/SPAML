---
title: "Finalize Stimuli"
author: "Erin M. Buchanan"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This document takes in the translations for each of the finished languages, updates the stimuli so they are consistent across languages, and creates the trials for each language. 

## Libraries

```{r}
library(rio)
library(stringi)
library(lsa)
library(dplyr)
# library(quanteda)
# library(sylly)
# library(tidytext)
# library(tidyr)
# library(stringr)
# library(stringdist)
```

Note: all models were downloaded from subs2vec github and stored on a separate drive, as they are very large. Also, this document is in the order that we added languages, not alphabetical like the other documents.

## en English

For English, we need to correct:
  
  - The fake trials that are not appropriate (fixed)
  - The unrelated trials in ensure a low cosine 
  
```{r eval = F}
# original words
en <- import("en/en_translate.csv")

# fix fake words ----
en_update <- import("en/en_translated_final.xlsx")
cue_fix <- 
  bind_rows(
    (en_update %>% 
      filter(cue_vowel == "no") %>%
      select(en_cue, en_fake_cue)),
    (en_update %>% 
      filter(en_update$cue_pronounce == "no") %>% 
      select(en_cue, en_fake_cue)), 
    (en_update %>% 
       filter(cue_real == "yes") %>% 
       select(en_cue, en_fake_cue))
  ) %>% unique()

target_fix <- 
  bind_rows(
    (en_update %>% 
      filter(target_vowel == "no") %>%
      select(en_target, en_fake_target)),
    (en_update %>% 
      filter(en_update$target_pronounce == "no") %>% 
      select(en_target, en_fake_target)), 
    (en_update %>% 
       filter(target_real == "yes") %>% 
       select(en_target, en_fake_target))
  ) %>% unique()

# export(bind_rows(cue_fix, target_fix), "en/en_tofix.csv")
en_update <- import("en/en_tofix_fixed.csv")

cues <- en_update %>% filter(en_fake_cue != "")
for (i in 1:nrow(cues)){
  en$en_fake_cue[en$en_fake_cue == cues$en_fake_cue[i]
                 & en$en_cue == cues$en_cue[i]] <- cues$fixed[i]
}

targets <- en_update %>% filter(en_fake_target != "")
for (i in 1:nrow(targets)){
  en$en_fake_target[en$en_fake_target == targets$en_fake_target[i]
                    & en$en_target == targets$en_target[i]] <- targets$fixed[i]
}

sum(duplicated(en$en_cue))
sum(duplicated(en$en_target))
sum(duplicated(en$en_fake_cue))
sum(duplicated(en$en_fake_target))
sum(en$en_cue == en$en_target)

export(en, "../matched_stimuli/en_matched.csv", row.names = F)

# create possible trials ----
en_trials <- en[ , c("en_cue", "en_target")]
en_trials$type <- "related"
en_trials$cue_type <- "word"
en_trials$target_type <- "word"

en_trials <- rbind(en_trials,
                   data.frame(en_cue = ru$en_cue,
                              en_target = ru$en_target[sample(1:1000,
                                                              1000)],
                              type = "unrelated",
                              cue_type = "word",
                              target_type = "word"),
                   data.frame(en_cue = ru$en_fake_cue,
                              en_target = ru$en_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(en_cue = ru$en_cue[sample(1:1000,
                                                        1000)],
                              en_target = ru$en_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(en_cue = ru$en_fake_cue[sample(1:1000,
                                                        1000)],
                              en_target = ru$en_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(en_trials[ , c("en_cue", "en_target")]))

# update with low cosines from random shuffle ----
# set up model
en_model <- read.table("/Volumes/SPAML Backup/subs_vec/en/subs.en.1e6.txt", quote="\"")
en_model <- na.omit(en_model)
en_model$V1 <- tolower(en_model$V1)
en_model <- en_model[!duplicated(en_model$V1), ]
rownames(en_model) <- en_model$V1
en_model <- en_model[ , -1]

en_trials$en_cosine <- NA

# get cosine
for (row in 1:nrow(en_trials)){
  
  if(en_trials$type[row] != "nonword") { 
    
    en_trials$en_cosine[row] <- cosine(as.matrix(t(en_model[
    c(en_trials$en_cue[row], en_trials$en_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
en_trials$ok <- TRUE
en_trials$ok[en_trials$type == "unrelated" & abs(en_trials$en_cosine) > .15] <- FALSE

good_trials <- en_trials %>% filter(ok == TRUE)
bad_trials <- en_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I evened out 
bad_trials$en_target <- sample(bad_trials$en_target, 
                               size = length(bad_trials$en_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$en_cosine[row] <- cosine(as.matrix(t(en_model[
    c(bad_trials$en_cue[row], bad_trials$en_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(en_cosine < .15)))
bad_trials <- bad_trials %>% filter(en_cosine >= .15)
# end section I ran multiple times 

whats_left <- cosine(as.matrix(t(en_model[c(
  bad_trials$en_target,
  unique(good_trials$en_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$en_target)){
  
  # find all words that could be paired with bad en_target
  # as updated en_cue
  potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$en_target[i]] < .15] 
  
  # find all pairs of good en_target that could
  # be paired with bad en_cue
  potential_switch <- good_trials %>% filter(en_cue %in% potential_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(en_model[c(
    bad_trials$en_cue[i],
    potential_switch$en_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$en_cue[i], bad_trials$en_target[i],
    potential_switch$en_cue[potential_switch$en_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_en_cue", "bad_en_target", 
                           "good_en_cue", "good_en_target")

good_trials_small <- good_trials %>% 
  filter(!(en_cue %in% switch_todo$good_en_cue & type == "unrelated"))

new_good_trials <- data.frame(
  en_cue = c(switch_todo$bad_en_cue, switch_todo$good_en_cue),
  en_target = c(switch_todo$good_en_target, switch_todo$bad_en_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  en_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$en_cosine[row] <- cosine(as.matrix(t(en_model[
    c(new_good_trials$en_cue[row], new_good_trials$en_target[row]) , ])))[2]
}

en_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(en_final[ , c("en_cue", "en_target")]))


tapply(en_final$en_cosine, en_final$type, mean, na.rm = T)
tapply(en_final$en_cosine, en_final$type, min, na.rm = T)
tapply(en_final$en_cosine, en_final$type, max, na.rm = T)

en_final$ok <- NULL

export(en_final, "en/en_trials_final.csv")
```

## ru Russian 

```{r eval = F}
# original words
ru <- import("ru/ru_translate.csv")

# fix real words ----
ru_update <- import("ru/ru_translated_final.xlsx")

cues <- ru_update %>% filter(ru_cue_trans != "")
for (i in 1:nrow(cues)){
  ru$ru_cue[ru$ru_cue == cues$ru_cue[i] #original cue match
            & ru$en_cue == cues$en_cue[i]] <- #english match 
    cues$ru_cue_trans[i] #new cue 
}

targets <- ru_update %>% filter(ru_target_trans != "")
for (i in 1:nrow(targets)){
  ru$ru_target[ru$ru_target == targets$ru_target[i] #original target match
            & ru$en_target == targets$en_target[i]] <- #english match 
    targets$ru_target_trans[i] #new target 
}

# # fix fake words ----
# cues <- ru_update %>% filter(ru_fake_cue_trans != "")
# for (i in 1:nrow(cues)){
#   ru$ru_fake_cue[ru$ru_fake_cue == cues$ru_fake_cue[i] #original cue match
#             & ru$en_cue == cues$en_cue[i]] <- #english match 
#     cues$ru_fake_cue_trans[i] #new cue 
# }
# 
# targets <- ru_update %>% filter(ru_fake_target_trans != "")
# for (i in 1:nrow(targets)){
#   ru$ru_fake_target[ru$ru_fake_target == targets$ru_fake_target[i] #original target match
#             & ru$en_target == targets$en_target[i]] <- #english match 
#     targets$ru_fake_target_trans[i] #new target 
# }

ru$ru_fake_target <- ru_update$ru_fake_target_fix
ru$ru_fake_cue <- ru_update$ru_fake_cue_fix

sum(duplicated(ru$ru_cue))
sum(duplicated(ru$ru_target))
sum(duplicated(ru$ru_fake_cue))
sum(duplicated(ru$ru_fake_target))
sum(ru$ru_cue == ru$ru_target)

export(ru, "../matched_stimuli/ru_matched.csv", row.names = F)

# create possible trials ----
ru_trials <- ru[ , c("ru_cue", "ru_target")]
ru_trials$type <- "related"
ru_trials$cue_type <- "word"
ru_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
ru$en_cue <- tolower(ru$en_cue)
ru$en_target <- tolower(ru$en_target)
# match unrelated pairs as a start 
ru_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(ru_unrelated)){
  ru_unrelated$en_cue[i] <- ru$ru_cue[ru$en_cue == ru_unrelated$en_cue[i]]
  ru_unrelated$en_target[i] <- ru$ru_target[ru$en_target == ru_unrelated$en_target[i]]
}

ru_trials <- rbind(ru_trials,
                   ru_unrelated %>% select(-en_cosine) %>% 
                     rename("ru_cue" = "en_cue", 
                            "ru_target" = "en_target"), 
                   data.frame(ru_cue = ru$ru_fake_cue,
                              ru_target = ru$ru_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(ru_cue = ru$ru_cue[sample(1:1000,
                                                        1000)],
                              ru_target = ru$ru_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(ru_cue = ru$ru_fake_cue[sample(1:1000,
                                                        1000)],
                              ru_target = ru$ru_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(ru_trials[ , c("ru_cue", "ru_target")]))

# update with low cosines from random shuffle ----
# set up model
ru_model <- read.table("/Volumes/SPAML Backup/subs_vec/ru/subs.ru.1e6.txt", quote="\"")
ru_model <- na.omit(ru_model)
ru_model$V1 <- tolower(ru_model$V1)
ru_model <- ru_model[!duplicated(ru_model$V1), ]
rownames(ru_model) <- ru_model$V1
ru_model <- ru_model[ , -1]

ru_trials$ru_cosine <- NA

# get cosine
for (row in 1:nrow(ru_trials)){
  
  if(ru_trials$type[row] != "nonword") { 
    
    ru_trials$ru_cosine[row] <- cosine(as.matrix(t(ru_model[
    c(ru_trials$ru_cue[row], ru_trials$ru_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
ru_trials$ok <- TRUE
ru_trials$ok[ru_trials$type == "unrelated" & abs(ru_trials$ru_cosine) > .15] <- FALSE

good_trials <- ru_trials %>% filter(ok == TRUE)
bad_trials <- ru_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$ru_target <- sample(bad_trials$ru_target, 
                               size = length(bad_trials$ru_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$ru_cosine[row] <- cosine(as.matrix(t(ru_model[
    c(bad_trials$ru_cue[row], bad_trials$ru_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(ru_cosine < .15)))
bad_trials <- bad_trials %>% filter(ru_cosine >= .15)
nrow(bad_trials)
# rud section I ran multiple times 

whats_left <- cosine(as.matrix(t(ru_model[c(
  bad_trials$ru_target,
  unique(good_trials$ru_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$ru_target)){
  
  # find all words that could be paired with bad ru_target
  # as updated ru_cue
  potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$ru_target[i]] < .15] 
  
  # find all pairs of good ru_target that could
  # be paired with bad ru_cue
  potential_switch <- good_trials %>% filter(ru_cue %in% potential_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(ru_model[c(
    bad_trials$ru_cue[i],
    potential_switch$ru_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$ru_cue[i], bad_trials$ru_target[i],
    potential_switch$ru_cue[potential_switch$ru_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_ru_cue", "bad_ru_target", 
                           "good_ru_cue", "good_ru_target")

good_trials_small <- good_trials %>% 
  filter(!(ru_cue %in% switch_todo$good_ru_cue & type == "unrelated"))

new_good_trials <- data.frame(
  ru_cue = c(switch_todo$bad_ru_cue, switch_todo$good_ru_cue),
  ru_target = c(switch_todo$good_ru_target, switch_todo$bad_ru_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  ru_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$ru_cosine[row] <- cosine(as.matrix(t(ru_model[
    c(new_good_trials$ru_cue[row], new_good_trials$ru_target[row]) , ])))[2]
}

ru_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(ru_final[ , c("ru_cue", "ru_target")]))


tapply(ru_final$ru_cosine, ru_final$type, mean, na.rm = T)
tapply(ru_final$ru_cosine, ru_final$type, min, na.rm = T)
tapply(ru_final$ru_cosine, ru_final$type, max, na.rm = T)

ru_final$ok <- NULL

export(ru_final, "ru/ru_trials_final.csv")
```

## tr Turkish

```{r eval = F}
# original words
tr <- import("tr/tr_translate.csv")

# fix real words ----
tr_update <- import("tr/tr_translated_final.xlsx")

cues <- tr_update %>% filter(tr_cue_update != "")
for (i in 1:nrow(cues)){
  tr$tr_cue[tr$tr_cue == cues$tr_cue[i] #original cue match
            & tr$en_cue == cues$en_cue[i]] <- #english match 
    cues$tr_cue_update[i] #new cue 
}

targets <- tr_update %>% filter(tr_target_update != "")
for (i in 1:nrow(targets)){
  tr$tr_target[tr$tr_target == targets$tr_target[i] #original target match
            & tr$en_target == targets$en_target[i]] <- #english match 
    targets$tr_target_update[i] #new target 
}

# find matches and edit
tr %>% filter(tr_cue == tr_target)

# fix fake words ----
cues <- tr_update %>% filter(tr_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  tr$tr_fake_cue[tr$tr_fake_cue == cues$tr_fake_cue[i] #original cue match
            & tr$en_cue == cues$en_cue[i]] <- #english match 
    cues$tr_fake_cue_trans[i] #new cue 
}

targets <- tr_update %>% filter(tr_fake_target_trans != "")
for (i in 1:nrow(targets)){
  tr$tr_fake_target[tr$tr_fake_target == targets$tr_fake_target[i] #original target match
            & tr$en_target == targets$en_target[i]] <- #english match 
    targets$tr_fake_target_trans[i] #new target 
}

sum(duplicated(tr$tr_cue))
sum(duplicated(tr$tr_target))
sum(duplicated(tr$tr_fake_cue))
sum(duplicated(tr$tr_fake_target))
sum(tr$tr_cue == tr$tr_target)

export(tr, "../matched_stimuli/tr_matched.csv", row.names = F)

# create possible trials ----
tr_trials <- tr[ , c("tr_cue", "tr_target")]
tr_trials$type <- "related"
tr_trials$cue_type <- "word"
tr_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
tr$en_cue <- tolower(tr$en_cue)
tr$en_target <- tolower(tr$en_target)
# match unrelated pairs as a start 
tr_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(tr_unrelated)){
  tr_unrelated$en_cue[i] <- tr$tr_cue[tr$en_cue == tr_unrelated$en_cue[i]]
  tr_unrelated$en_target[i] <- tr$tr_target[tr$en_target == tr_unrelated$en_target[i]]
}

tr_trials <- rbind(tr_trials,
                   tr_unrelated %>% select(-en_cosine) %>% 
                     rename("tr_cue" = "en_cue", 
                            "tr_target" = "en_target"), 
                   data.frame(tr_cue = tr$tr_fake_cue,
                              tr_target = tr$tr_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(tr_cue = tr$tr_cue[sample(1:1000,
                                                        1000)],
                              tr_target = tr$tr_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(tr_cue = tr$tr_fake_cue[sample(1:1000,
                                                        1000)],
                              tr_target = tr$tr_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(tr_trials[ , c("tr_cue", "tr_target")]))

# update with low cosines from random shuffle ----
# set up model
tr_model <- read.table("/Volumes/SPAML Backup/subs_vec/tr/subs.tr.1e6.txt", quote="\"")
tr_model <- na.omit(tr_model)
tr_model$V1 <- tolower(tr_model$V1)
tr_model <- tr_model[!duplicated(tr_model$V1), ]
rownames(tr_model) <- tr_model$V1
tr_model <- tr_model[ , -1]

tr_trials$tr_cosine <- NA

# get cosine
for (row in 1:nrow(tr_trials)){
  
  if(tr_trials$type[row] != "nonword") { 
    
    tr_trials$tr_cosine[row] <- cosine(as.matrix(t(tr_model[
    c(tr_trials$tr_cue[row], tr_trials$tr_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
tr_trials$ok <- TRUE
tr_trials$ok[tr_trials$type == "unrelated" & abs(tr_trials$tr_cosine) > .15] <- FALSE

good_trials <- tr_trials %>% filter(ok == TRUE)
bad_trials <- tr_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$tr_target <- sample(bad_trials$tr_target, 
                               size = length(bad_trials$tr_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$tr_cosine[row] <- cosine(as.matrix(t(tr_model[
    c(bad_trials$tr_cue[row], bad_trials$tr_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(tr_cosine < .15)))
bad_trials <- bad_trials %>% filter(tr_cosine >= .15)
nrow(bad_trials)
# end section I ran multiple times 

whats_left <- cosine(as.matrix(t(tr_model[c(
  bad_trials$tr_target,
  unique(good_trials$tr_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$tr_target)){
  
  # find all words that could be paired with bad tr_target
  # as updated tr_cue
  potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$tr_target[i]] < .15] 
  
  # find all pairs of good tr_target that could
  # be paired with bad tr_cue
  potential_switch <- good_trials %>% filter(tr_cue %in% potential_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(tr_model[c(
    bad_trials$tr_cue[i],
    potential_switch$tr_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$tr_cue[i], bad_trials$tr_target[i],
    potential_switch$tr_cue[potential_switch$tr_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_tr_cue", "bad_tr_target", 
                           "good_tr_cue", "good_tr_target")

good_trials_small <- good_trials %>% 
  filter(!(tr_cue %in% switch_todo$good_tr_cue & type == "unrelated"))

new_good_trials <- data.frame(
  tr_cue = c(switch_todo$bad_tr_cue, switch_todo$good_tr_cue),
  tr_target = c(switch_todo$good_tr_target, switch_todo$bad_tr_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  tr_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$tr_cosine[row] <- cosine(as.matrix(t(tr_model[
    c(new_good_trials$tr_cue[row], new_good_trials$tr_target[row]) , ])))[2]
}

tr_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(tr_final[ , c("tr_cue", "tr_target")]))


tapply(tr_final$tr_cosine, tr_final$type, mean, na.rm = T)
tapply(tr_final$tr_cosine, tr_final$type, min, na.rm = T)
tapply(tr_final$tr_cosine, tr_final$type, max, na.rm = T)

tr_final$ok <- NULL

export(tr_final, "tr/tr_trials_final.csv")
```

## ko Korean

```{r eval = F}
# original words
# don't use the original trials because there are lot of weird typos
# that were clearly fixed in the translated sheet
ko <- import("ko/ko_translated_final.xlsx")
ko_temp <- import("ko/ko_translate.csv")
ko <- ko %>% select(colnames(ko_temp))

# fix real words ----
ko_update <- import("ko/ko_translated_final.xlsx")

cues <- ko_update %>% filter(ko_cue_trans != "")
for (i in 1:nrow(cues)){
  ko$ko_cue[ko$ko_cue == cues$ko_cue[i] #original cue match
            & ko$en_cue == cues$en_cue[i]] <- #english match 
    cues$ko_cue_trans[i] #new cue 
}

targets <- ko_update %>% filter(ko_target_trans != "")
for (i in 1:nrow(targets)){
  ko$ko_target[ko$ko_target == targets$ko_target[i] #original target match
            & ko$en_target == targets$en_target[i]] <- #english match 
    targets$ko_target_trans[i] #new target 
}

# find matches and edit
ko %>% filter(ko_cue == ko_target)

# fix fake words ----
cues <- ko_update %>% filter(ko_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  ko$ko_fake_cue[ko$ko_fake_cue == cues$ko_fake_cue[i] #original cue match
            & ko$en_cue == cues$en_cue[i]] <- #english match 
    cues$ko_fake_cue_trans[i] #new cue 
}

targets <- ko_update %>% filter(ko_fake_target_trans != "")
for (i in 1:nrow(targets)){
  ko$ko_fake_target[ko$ko_fake_target == targets$ko_fake_target[i] #original target match
            & ko$en_target == targets$en_target[i]] <- #english match 
    targets$ko_fake_target_trans[i] #new target 
}

sum(duplicated(ko$ko_cue))
sum(duplicated(ko$ko_target))
sum(duplicated(ko$ko_fake_cue))
sum(duplicated(ko$ko_fake_target))
sum(ko$ko_cue == ko$ko_target)

export(ko, "../matched_stimuli/ko_matched.csv", row.names = F)

# create possible trials ----
ko_trials <- ko[ , c("ko_cue", "ko_target")]
ko_trials$type <- "related"
ko_trials$cue_type <- "word"
ko_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
ko$en_cue <- tolower(ko$en_cue)
ko$en_target <- tolower(ko$en_target)
# match unrelated pairs as a start 
ko_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(ko_unrelated)){
  ko_unrelated$en_cue[i] <- ko$ko_cue[ko$en_cue == ko_unrelated$en_cue[i]]
  ko_unrelated$en_target[i] <- ko$ko_target[ko$en_target == ko_unrelated$en_target[i]]
}

ko_trials <- rbind(ko_trials,
                   ko_unrelated %>% select(-en_cosine) %>% 
                     rename("ko_cue" = "en_cue", 
                            "ko_target" = "en_target"), 
                   data.frame(ko_cue = ko$ko_fake_cue,
                              ko_target = ko$ko_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(ko_cue = ko$ko_cue[sample(1:1000,
                                                        1000)],
                              ko_target = ko$ko_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(ko_cue = ko$ko_fake_cue[sample(1:1000,
                                                        1000)],
                              ko_target = ko$ko_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(ko_trials[ , c("ko_cue", "ko_target")]))

# update with low cosines from random shuffle ----
# set up model
ko_model <- read.table("/Volumes/SPAML Backup/subs_vec/ko/subs.ko.1e6.txt", quote="\"")
ko_model <- na.omit(ko_model)
ko_model$V1 <- tolower(ko_model$V1)
ko_model <- ko_model[!duplicated(ko_model$V1), ]
rownames(ko_model) <- ko_model$V1
ko_model <- ko_model[ , -1]

ko_trials$ko_cosine <- NA

# get cosine
for (row in 1:nrow(ko_trials)){
  
  if(ko_trials$type[row] != "nonword") { 
    
    ko_trials$ko_cosine[row] <- cosine(as.matrix(t(ko_model[
    c(ko_trials$ko_cue[row], ko_trials$ko_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
# if they are NA, they are zero 
ko_trials$ko_cosine[is.na(ko_trials$ko_cosine) & ko_trials$type == "unrelated"] <- 0
ko_trials$ok <- TRUE
ko_trials$ok[ko_trials$type == "unrelated" & abs(ko_trials$ko_cosine) > .15] <- FALSE

good_trials <- ko_trials %>% filter(ok == TRUE)
bad_trials <- ko_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$ko_target <- sample(bad_trials$ko_target, 
                               size = length(bad_trials$ko_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$ko_cosine[row] <- cosine(as.matrix(t(ko_model[
    c(bad_trials$ko_cue[row], bad_trials$ko_target[row]) , ])))[2]
}

# deal with zeros 
bad_trials$ko_cosine[is.na(bad_trials$ko_cosine)] <- 0
bad_trials$ko_cosine[bad_trials$ko_target == "땡땡"] <- 0
bad_trials$ko_cosine[bad_trials$ko_target == "버리다"] <- 0

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(ko_cosine < .15))) # update to 20
bad_trials <- bad_trials %>% filter(ko_cosine >= .15)
nrow(bad_trials)

whats_left <- cosine(as.matrix(t(ko_model[c(
  bad_trials$ko_target,
  unique(good_trials$ko_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$ko_target)){
  
  # find all words that could be paired with bad ko_target
  potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$ko_target[i]] < .20] 
  
  # find all pairs of good ko_target that could
  # be paired with bad ko_cue
  potential_switch <- good_trials %>% filter(ko_cue %in% potential_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(ko_model[c(
    bad_trials$ko_cue[i],
    potential_switch$ko_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$ko_cue[i], bad_trials$ko_target[i],
    potential_switch$ko_cue[potential_switch$ko_target == new_target][1],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_ko_cue", "bad_ko_target", 
                           "good_ko_cue", "good_ko_target")

good_trials_small <- good_trials %>% 
  filter(!(ko_cue %in% switch_todo$good_ko_cue & type == "unrelated")) 

new_good_trials <- data.frame(
  ko_cue = c(switch_todo$bad_ko_cue, switch_todo$good_ko_cue),
  ko_target = c(switch_todo$good_ko_target, switch_todo$bad_ko_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  ko_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$ko_cosine[row] <- cosine(as.matrix(t(ko_model[
    c(new_good_trials$ko_cue[row], new_good_trials$ko_target[row]) , ])))[2]
}

# creates too many so sample 
ko_final <- bind_rows(good_trials_small, new_good_trials[sample(1:nrow(new_good_trials), 5000-nrow(good_trials_small), replace = F), ])
sum(duplicated(ko_final[ , c("ko_cue", "ko_target")]))

tapply(ko_final$ko_cosine, ko_final$type, mean, na.rm = T)
tapply(ko_final$ko_cosine, ko_final$type, min, na.rm = T)
tapply(ko_final$ko_cosine, ko_final$type, max, na.rm = T)

ko_final$ok <- NULL

export(ko_final, "ko/ko_trials_final.csv")
```

## cs Czech

```{r eval = F}
# original words
# make sure to use the translated sheet so we don't have issues 
# that were clearly fixed in the translated sheet
cs <- import("cs/cs_translated_final.xlsx")
cs_temp <- import("cs/cs_translate.csv")
cs <- cs %>% select(colnames(cs_temp))

# fix real words ----
cs_update <- import("cs/cs_translated_final.xlsx")

cues <- cs_update %>% filter(cs_cue_final != "")
for (i in 1:nrow(cues)){
  cs$cs_cue[cs$cs_cue == cues$cs_cue[i] #original cue match
            & cs$en_cue == cues$en_cue[i]] <- #english match 
    cues$cs_cue_final[i] #new cue 
}

targets <- cs_update %>% filter(cs_target_final != "")
for (i in 1:nrow(targets)){
  cs$cs_target[cs$cs_target == targets$cs_target[i] #original target match
            & cs$en_target == targets$en_target[i]] <- #english match 
    targets$cs_target_final[i] #new target 
}

# find matches and edit
cs %>% filter(cs_cue == cs_target)

# fix fake words ----
cues <- cs_update %>% filter(cs_fake_cue_final != "")
for (i in 1:nrow(cues)){
  cs$cs_fake_cue[cs$cs_fake_cue == cues$cs_fake_cue[i] #original cue match
            & cs$en_cue == cues$en_cue[i]] <- #english match 
    cues$cs_fake_cue_final[i] #new cue 
}

targets <- cs_update %>% filter(cs_fake_target_final != "")
for (i in 1:nrow(targets)){
  cs$cs_fake_target[cs$cs_fake_target == targets$cs_fake_target[i] #original target match
            & cs$en_target == targets$en_target[i]] <- #english match 
    targets$cs_fake_target_final[i] #new target 
}

cues <- cs_update %>% filter(cs_fake_cue_final2 != "")
for (i in 1:nrow(cues)){
  cs$cs_fake_cue[cs$cs_fake_cue == cues$cs_fake_cue[i] #original cue match
            & cs$en_cue == cues$en_cue[i]] <- #english match 
    cues$cs_fake_cue_final2[i] #new cue 
}

targets <- cs_update %>% filter(cs_fake_target_final2 != "")
for (i in 1:nrow(targets)){
  cs$cs_fake_target[cs$cs_fake_target == targets$cs_fake_target[i] #original target match
            & cs$en_target == targets$en_target[i]] <- #english match 
    targets$cs_fake_target_final2[i] #new target 
}


sum(duplicated(cs$cs_cue))
sum(duplicated(cs$cs_target))
sum(duplicated(cs$cs_fake_cue))
sum(duplicated(cs$cs_fake_target))
sum(cs$cs_cue == cs$cs_target)

export(cs, "../matched_stimuli/cs_matched.csv", row.names = F)

# create possible trials ----
cs_trials <- cs[ , c("cs_cue", "cs_target")]
cs_trials$type <- "related"
cs_trials$cue_type <- "word"
cs_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
cs$en_cue <- tolower(cs$en_cue)
cs$en_target <- tolower(cs$en_target)
# match unrelated pairs as a start 
cs_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(cs_unrelated)){
  cs_unrelated$en_cue[i] <- cs$cs_cue[cs$en_cue == cs_unrelated$en_cue[i]]
  cs_unrelated$en_target[i] <- cs$cs_target[cs$en_target == cs_unrelated$en_target[i]]
}

cs_trials <- rbind(cs_trials,
                   cs_unrelated %>% select(-en_cosine) %>% 
                     rename("cs_cue" = "en_cue", 
                            "cs_target" = "en_target"), 
                   data.frame(cs_cue = cs$cs_fake_cue,
                              cs_target = cs$cs_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(cs_cue = cs$cs_cue[sample(1:1000,
                                                        1000)],
                              cs_target = cs$cs_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(cs_cue = cs$cs_fake_cue[sample(1:1000,
                                                        1000)],
                              cs_target = cs$cs_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(cs_trials[ , c("cs_cue", "cs_target")]))

# update with low cosines from random shuffle ----
# set up model
cs_model <- read.table("/Volumes/SPAML Backup/subs_vec/cs/subs.cs.1e6.txt", quote="\"")
cs_model <- na.omit(cs_model)
cs_model$V1 <- tolower(cs_model$V1)
cs_model <- cs_model[!duplicated(cs_model$V1), ]
rownames(cs_model) <- cs_model$V1
cs_model <- cs_model[ , -1]

cs_trials$cs_cosine <- NA

# get cosine
for (row in 1:nrow(cs_trials)){
  
  if(cs_trials$type[row] != "nonword") { 
    
    cs_trials$cs_cosine[row] <- cosine(as.matrix(t(cs_model[
    c(cs_trials$cs_cue[row], cs_trials$cs_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
# if they are NA, they are zero 
cs_trials$cs_cosine[is.na(cs_trials$cs_cosine) & cs_trials$type == "unrelated"] <- 0
cs_trials$ok <- TRUE
cs_trials$ok[cs_trials$type == "unrelated" & abs(cs_trials$cs_cosine) > .15] <- FALSE

good_trials <- cs_trials %>% filter(ok == TRUE)
bad_trials <- cs_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$cs_target <- sample(bad_trials$cs_target, 
                               size = length(bad_trials$cs_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$cs_cosine[row] <- cosine(as.matrix(t(cs_model[
    c(bad_trials$cs_cue[row], bad_trials$cs_target[row]) , ])))[2]
}

# deal with zeros 
bad_trials$cs_cosine[is.na(bad_trials$cs_cosine)] <- 0

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(cs_cosine < .15))) # update to 20
bad_trials <- bad_trials %>% filter(cs_cosine >= .15)
nrow(bad_trials)

whats_left <- cosine(as.matrix(t(cs_model[c(
  bad_trials$cs_target,
  unique(good_trials$cs_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$cs_target)){
  
  # find all words that could be paired with bad cs_target
  potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$cs_target[i]] < .20] 
  
  # find all pairs of good cs_target that could
  # be paired with bad cs_cue
  potential_switch <- good_trials %>% filter(cs_cue %in% potential_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(cs_model[c(
    bad_trials$cs_cue[i],
    potential_switch$cs_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$cs_cue[i], bad_trials$cs_target[i],
    potential_switch$cs_cue[potential_switch$cs_target == new_target][1],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_cs_cue", "bad_cs_target", 
                           "good_cs_cue", "good_cs_target")

good_trials_small <- good_trials %>% 
  filter(!(cs_cue %in% switch_todo$good_cs_cue & type == "unrelated")) 

new_good_trials <- data.frame(
  cs_cue = c(switch_todo$bad_cs_cue, switch_todo$good_cs_cue),
  cs_target = c(switch_todo$good_cs_target, switch_todo$bad_cs_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  cs_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$cs_cosine[row] <- cosine(as.matrix(t(cs_model[
    c(new_good_trials$cs_cue[row], new_good_trials$cs_target[row]) , ])))[2]
}

# creates too many so sample 
cs_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(cs_final[ , c("cs_cue", "cs_target")]))

tapply(cs_final$cs_cosine, cs_final$type, mean, na.rm = T)
tapply(cs_final$cs_cosine, cs_final$type, min, na.rm = T)
tapply(cs_final$cs_cosine, cs_final$type, max, na.rm = T)

cs_final$ok <- NULL

export(cs_final, "cs/cs_trials_final.csv")
```

## ja Japanese

```{r eval = F}
# original words the japanese team did this for me
ja <- import("ja/ja_translated_final.xlsx")
colnames(ja) <- gsub("_final", "", colnames(ja))

ja %>% filter(ja_cue == ja_target)

sum(duplicated(ja$ja_cue))
sum(duplicated(ja$ja_target))
sum(duplicated(ja$ja_fake_cue))
sum(duplicated(ja$ja_fake_target))
sum(ja$ja_cue == ja$ja_target)

export(ja, "../matched_stimuli/ja_matched.csv", row.names = F)

# create possible trials ----
ja_trials <- ja[ , c("ja_cue", "ja_target")]
ja_trials$type <- "related"
ja_trials$cue_type <- "word"
ja_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
ja$en_cue <- tolower(ja$en_cue)
ja$en_target <- tolower(ja$en_target)
# match unrelated pairs as a start 
ja_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(ja_unrelated)){
  ja_unrelated$en_cue[i] <- ja$ja_cue[ja$en_cue == ja_unrelated$en_cue[i]]
  ja_unrelated$en_target[i] <- ja$ja_target[ja$en_target == ja_unrelated$en_target[i]]
}

ja_trials <- rbind(ja_trials,
                   ja_unrelated %>% select(-en_cosine) %>% 
                     rename("ja_cue" = "en_cue", 
                            "ja_target" = "en_target"), 
                   data.frame(ja_cue = ja$ja_fake_cue,
                              ja_target = ja$ja_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(ja_cue = ja$ja_cue[sample(1:1000,
                                                        1000)],
                              ja_target = ja$ja_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(ja_cue = ja$ja_fake_cue[sample(1:1000,
                                                        1000)],
                              ja_target = ja$ja_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(ja_trials[ , c("ja_cue", "ja_target")]))

# update with low cosines from random shuffle ----
# set up model
ja_model <- import("/Volumes/SPAML Backup/subs_vec/ja/ja_300_5_sg_wxd.csv")
ja_model <- na.omit(ja_model)
ja_model$V1 <- tolower(ja_model$V1)
ja_model <- ja_model[-1 , ]
ja_model <- ja_model[!duplicated(ja_model$V1), ]
rownames(ja_model) <- ja_model$V1
ja_model <- ja_model[ , -1]

ja_trials$ja_cosine <- NA

# get cosine
for (row in 1:nrow(ja_trials)){
  
  if(ja_trials$type[row] != "nonword") { 
    
    if (ja_trials$ja_cue[row] %in% rownames(ja_model) & 
        ja_trials$ja_target[row] %in% rownames(ja_model)){
    ja_trials$ja_cosine[row] <- cosine(as.matrix(t(ja_model[
    c(ja_trials$ja_cue[row], ja_trials$ja_target[row]) , ])))[2]
    } else { 
      ja_trials$ja_cosine[row] <- 0 
    }
    
  }
  
}

# update trials that have cosines too big 
ja_trials$ok <- TRUE
ja_trials$ok[ja_trials$type == "unrelated" & abs(ja_trials$ja_cosine) > .15] <- FALSE

good_trials <- ja_trials %>% filter(ok == TRUE)
bad_trials <- ja_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$ja_target <- sample(bad_trials$ja_target, 
                               size = length(bad_trials$ja_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
  
    if (bad_trials$ja_cue[row] %in% rownames(ja_model) & 
        bad_trials$ja_target[row] %in% rownames(ja_model)){
    bad_trials$ja_cosine[row] <- cosine(as.matrix(t(ja_model[
    c(bad_trials$ja_cue[row], bad_trials$ja_target[row]) , ])))[2]
    } else { 
      bad_trials$ja_cosine[row] <- 0 
    }
}

# deal with zeros 
bad_trials$ja_cosine[is.na(bad_trials$ja_cosine)] <- 0

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(ja_cosine < .50))) # update to 20
bad_trials <- bad_trials %>% filter(ja_cosine >= .50)
nrow(bad_trials)

whats_left <- cosine(as.matrix(t(ja_model[c(
  bad_trials$ja_target,
  unique(good_trials$ja_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

# just deal with the wild JA ones 
ja_final <- bind_rows(good_trials, bad_trials)
sum(duplicated(ja_final[ , c("ja_cue", "ja_target")]))

tapply(ja_final$ja_cosine, ja_final$type, mean, na.rm = T)
tapply(ja_final$ja_cosine, ja_final$type, min, na.rm = T)
tapply(ja_final$ja_cosine, ja_final$type, max, na.rm = T)

ja_final$ok <- NULL

export(ja_final, "ja/ja_trials_final.csv")
```

## da Danish

```{r eval = F}
# original words
da <- import("da/da_translate.csv")

# fix real words ----
da_update <- import("da/da_translated_final.xlsx")

cues <- da_update %>% filter(da_cue_trans != "")
for (i in 1:nrow(cues)){
  da$da_cue[da$da_cue == cues$da_cue[i] #original cue match
            & da$en_cue == cues$en_cue[i]] <- #english match 
    cues$da_cue_trans[i] #new cue 
}

targets <- da_update %>% filter(da_target_trans != "")
for (i in 1:nrow(targets)){
  da$da_target[da$da_target == targets$da_target[i] #original target match
            & da$en_target == targets$en_target[i]] <- #english match 
    targets$da_target_trans[i] #new target 
}

# fix fake words ----
# cues <- da_update %>% filter(da_fake_cue_trans != "")
# for (i in 1:nrow(cues)){
#   da$da_fake_cue[da$da_fake_cue == cues$da_fake_cue[i] #original cue match
#             & da$en_cue == cues$en_cue[i]] <- #english match
#     cues$da_fake_cue_trans[i] #new cue
# }
# 
# targets <- da_update %>% filter(da_fake_target_trans != "")
# for (i in 1:nrow(targets)){
#   da$da_fake_target[da$da_fake_target == targets$da_fake_target[i] #original target match
#             & da$en_target == targets$en_target[i]] <- #english match
#     targets$da_fake_target_trans[i] #new target
# }
da$da_fake_target <- da_update$da_fake_target_final
da$da_fake_cue <- da_update$da_fake_cue_final

sum(duplicated(da$da_cue))
sum(duplicated(da$da_target))
sum(duplicated(da$da_fake_cue))
sum(duplicated(da$da_fake_target))

nrow(da %>% filter(da_cue == da_target))

export(da, "../matched_stimuli/da_matched.csv", row.names = F)

# create possible trials ----
da_trials <- da[ , c("da_cue", "da_target")]
da_trials$type <- "related"
da_trials$cue_type <- "word"
da_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
da$en_cue <- tolower(da$en_cue)
da$en_target <- tolower(da$en_target)
# match unrelated pairs as a start 
da_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(da_unrelated)){
  da_unrelated$en_cue[i] <- da$da_cue[da$en_cue == da_unrelated$en_cue[i]]
  da_unrelated$en_target[i] <- da$da_target[da$en_target == da_unrelated$en_target[i]]
}

da_trials <- rbind(da_trials,
                   da_unrelated %>% select(-en_cosine) %>% 
                     rename("da_cue" = "en_cue", 
                            "da_target" = "en_target"), 
                   data.frame(da_cue = da$da_fake_cue,
                              da_target = da$da_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(da_cue = da$da_cue[sample(1:1000,
                                                        1000)],
                              da_target = da$da_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(da_cue = da$da_fake_cue[sample(1:1000,
                                                        1000)],
                              da_target = da$da_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(da_trials[ , c("da_cue", "da_target")]))

# update with low cosines from random shuffle ----
# set up model
da_model <- read.table("/Volumes/SPAML Backup/subs_vec/da/subs.da.1e6.txt", quote="\"")
da_model <- na.omit(da_model)
da_model$V1 <- tolower(da_model$V1)
da_model <- da_model[!duplicated(da_model$V1), ]
rownames(da_model) <- da_model$V1
da_model <- da_model[ , -1]

da_trials$da_cosine <- NA

# get cosine
for (row in 1:nrow(da_trials)){
  
  if(da_trials$type[row] != "nonword") { 
    
    da_trials$da_cosine[row] <- cosine(as.matrix(t(da_model[
    c(da_trials$da_cue[row], da_trials$da_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
da_trials$ok <- TRUE
da_trials$ok[da_trials$type == "unrelated" & abs(da_trials$da_cosine) > .15] <- FALSE

good_trials <- da_trials %>% filter(ok == TRUE)
bad_trials <- da_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$da_target <- sample(bad_trials$da_target, 
                               size = length(bad_trials$da_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$da_cosine[row] <- cosine(as.matrix(t(da_model[
    c(bad_trials$da_cue[row], bad_trials$da_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(da_cosine < .15)))
bad_trials <- bad_trials %>% filter(da_cosine >= .15)
nrow(bad_trials)
# ran section I ran multiple times 

whats_left <- cosine(as.matrix(t(da_model[c(
  bad_trials$da_target,
  unique(good_trials$da_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$da_target)){
  
  # find all words that could be paired with bad da_target
  # as updated da_cue
  potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$da_target[i]] < .15] 
  
  # find all pairs of good da_target that could
  # be paired with bad da_cue
  potential_switch <- good_trials %>% filter(da_cue %in% potential_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(da_model[c(
    bad_trials$da_cue[i],
    potential_switch$da_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$da_cue[i], bad_trials$da_target[i],
    potential_switch$da_cue[potential_switch$da_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_da_cue", "bad_da_target", 
                           "good_da_cue", "good_da_target")

good_trials_small <- good_trials %>% 
  filter(!(da_cue %in% switch_todo$good_da_cue & type == "unrelated"))

new_good_trials <- data.frame(
  da_cue = c(switch_todo$bad_da_cue, switch_todo$good_da_cue),
  da_target = c(switch_todo$good_da_target, switch_todo$bad_da_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  da_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$da_cosine[row] <- cosine(as.matrix(t(da_model[
    c(new_good_trials$da_cue[row], new_good_trials$da_target[row]) , ])))[2]
}

da_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(da_final[ , c("da_cue", "da_target")]))

# check cosines
tapply(da_final$da_cosine, da_final$type, mean, na.rm = T)
tapply(da_final$da_cosine, da_final$type, min, na.rm = T)
tapply(da_final$da_cosine, da_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- da_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(da_target) %>% 
  filter(n != 2)

weird_trials <- da_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(da_target %in% target_table$da_target)

# check for NA
sum(is.na(da_final$da_cue))
sum(is.na(da_final$da_target))
sum(grepl("^NA", da_final$da_cue))
sum(grepl("^NA", da_final$da_target))

# check rows
nrow(da_final)
table(da_final$type, da_final$cue_type, da_final$target_type)

da_final$ok <- NULL

export(da_final, "da/da_trials_final.csv")
```

## de German

```{r eval = F}
# original words
de <- import("de/de_translate.csv")
de$en_cue <- gsub("digusting", "disgusting", de$en_cue)

# fix real words ----
de_update <- import("de/de_translated_final.xlsx") %>% 
  mutate(across(everything(), tolower))

# fix cue words ----
# cues <- de_update %>% filter(de_cue_trans != "")
# for (i in 1:nrow(cues)){
#   de$de_cue[de$de_cue == cues$de_cue[i] #original cue match
#             & de$en_cue == cues$en_cue[i]] <- #english match 
#     cues$de_cue_trans[i] #new cue 
# }
# 
# 
# targets <- de_update %>% filter(de_target_trans != "")
# for (i in 1:nrow(targets)){
#   de$de_target[de$de_target == targets$de_target[i] #original target match
#             & de$en_target == targets$en_target[i]] <- #english match 
#     targets$de_target_trans[i] #new target 
# }
de$de_cue <- de_update$de_cue_trans_final
de$de_target <- de_update$de_target_trans_final

# fix fake words ----
# cues <- de_update %>% filter(de_fake_cue_trans != "")
# for (i in 1:nrow(cues)){
#   de$de_fake_cue[de$de_fake_cue == cues$de_fake_cue[i] #original cue match
#             & de$en_cue == cues$en_cue[i]] <- #english match
#     cues$de_fake_cue_trans[i] #new cue
# }
# 
# targets <- de_update %>% filter(de_fake_target_trans != "")
# for (i in 1:nrow(targets)){
#   de$de_fake_target[de$de_fake_target == targets$de_fake_target[i] #original target match
#             & de$en_target == targets$en_target[i]] <- #english match
#     targets$de_fake_target_trans[i] #new target
# }
de$de_fake_cue <- de_update$de_fake_cue_trans_final
de$de_fake_target <- de_update$de_fake_target_trans_final

sum(duplicated(de$de_cue))
sum(duplicated(de$de_target))
sum(duplicated(de$de_fake_cue))
sum(duplicated(de$de_fake_target))

nrow(de %>% filter(de_cue == de_target))

export(de, "../matched_stimuli/de_matched.csv", row.names = F)

# create possible trials ----
de_trials <- de[ , c("de_cue", "de_target")]
de_trials$type <- "related"
de_trials$cue_type <- "word"
de_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
de$en_cue <- tolower(de$en_cue)
de$en_target <- tolower(de$en_target)
# match unrelated pairs as a start 
de_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(de_unrelated)){
  de_unrelated$en_cue[i] <- de$de_cue[de$en_cue == de_unrelated$en_cue[i]]
  de_unrelated$en_target[i] <- de$de_target[de$en_target == de_unrelated$en_target[i]]
}

de_trials <- rbind(de_trials,
                   de_unrelated %>% select(-en_cosine) %>% 
                     rename("de_cue" = "en_cue", 
                            "de_target" = "en_target"), 
                   data.frame(de_cue = de$de_fake_cue,
                              de_target = de$de_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(de_cue = de$de_cue[sample(1:1000,
                                                        1000)],
                              de_target = de$de_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(de_cue = de$de_fake_cue[sample(1:1000,
                                                        1000)],
                              de_target = de$de_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(de_trials[ , c("de_cue", "de_target")]))

# update with low cosines from random shuffle ----
# set up model
de_model <- read.table("/Volumes/SPAML Backup/subs_vec/de/subs.de.1e6.txt", quote="\"")
de_model <- na.omit(de_model)
de_model$V1 <- tolower(de_model$V1)
de_model <- de_model[!duplicated(de_model$V1), ]
rownames(de_model) <- de_model$V1
de_model <- de_model[ , -1]

de_trials$de_cosine <- NA

# get cosine
for (row in 1:nrow(de_trials)){
  
  if(de_trials$type[row] != "nonword") { 
    
    de_trials$de_cosine[row] <- cosine(as.matrix(t(de_model[
    c(de_trials$de_cue[row], de_trials$de_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
de_trials$ok <- TRUE
de_trials$ok[de_trials$type == "unrelated" & abs(de_trials$de_cosine) > .15] <- FALSE

good_trials <- de_trials %>% filter(ok == TRUE)
bad_trials <- de_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$de_target <- sample(bad_trials$de_target, 
                               size = length(bad_trials$de_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$de_cosine[row] <- cosine(as.matrix(t(de_model[
    c(bad_trials$de_cue[row], bad_trials$de_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(de_cosine < .15)))
bad_trials <- bad_trials %>% filter(de_cosine >= .15)
nrow(bad_trials)
# ran section I ran multiple times 

whats_left <- cosine(as.matrix(t(de_model[c(
  bad_trials$de_target,
  unique(good_trials$de_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$de_target)){
  
  # find all words that could be paired with bad de_target
  # as updated de_cue
  potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$de_target[i]] < .15] 
  
  # find all pairs of good de_target that could
  # be paired with bad de_cue
  potential_switch <- good_trials %>% filter(de_cue %in% potential_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(de_model[c(
    bad_trials$de_cue[i],
    potential_switch$de_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$de_cue[i], bad_trials$de_target[i],
    potential_switch$de_cue[potential_switch$de_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_de_cue", "bad_de_target", 
                           "good_de_cue", "good_de_target")

good_trials_small <- good_trials %>% 
  filter(!(de_cue %in% switch_todo$good_de_cue & type == "unrelated"))

new_good_trials <- data.frame(
  de_cue = c(switch_todo$bad_de_cue, switch_todo$good_de_cue),
  de_target = c(switch_todo$good_de_target, switch_todo$bad_de_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  de_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$de_cosine[row] <- cosine(as.matrix(t(de_model[
    c(new_good_trials$de_cue[row], new_good_trials$de_target[row]) , ])))[2]
}

de_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(de_final[ , c("de_cue", "de_target")]))

# check cosines
tapply(de_final$de_cosine, de_final$type, mean, na.rm = T)
tapply(de_final$de_cosine, de_final$type, min, na.rm = T)
tapply(de_final$de_cosine, de_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- de_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(de_target) %>% 
  filter(n != 2)

weird_trials <- de_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(de_target %in% target_table$de_target)

# check for NA
sum(is.na(de_final$de_cue))
sum(is.na(de_final$de_target))
sum(grepl("^NA", de_final$de_cue))
sum(grepl("^NA", de_final$de_target))

# check rows
nrow(de_final)
table(de_final$type, de_final$cue_type, de_final$target_type)

de_final$ok <- NULL

export(de_final, "de/de_trials_final.csv")
```

## ar Arabic

```{r eval = F}
# original words
ar <- import("ar/ar_translate.csv")
ar$en_cue <- gsub("digusting", "disgusting", ar$en_cue)

# fix real words ----
ar_update <- import("ar/ar_translated_final.xlsx") %>% 
  mutate(across(everything(), tolower))

# # fix cue words ----
# cues <- ar_update %>% filter(ar_cue_trans != "")
# for (i in 1:nrow(cues)){
#   ar$ar_cue[ar$ar_cue == cues$ar_cue[i] #original cue match
#             & ar$en_cue == cues$en_cue[i]] <- #english match
#     cues$ar_cue_trans[i] #new cue
# }

ar$ar_cue <- ar_update$ar_cue_final

# targets <- ar_update %>% filter(ar_target_trans != "")
# for (i in 1:nrow(targets)){
#   ar$ar_target[ar$ar_target == targets$ar_target[i] #original target match
#             & ar$en_target == targets$en_target[i]] <- #english match
#     targets$ar_target_trans[i] #new target
# }

ar$ar_target <- ar_update$ar_target_final

# fix fake words ----
cues <- ar_update %>% filter(ar_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  ar$ar_fake_cue[ar$ar_fake_cue == cues$ar_fake_cue[i] #original cue match
            & ar$en_cue == cues$en_cue[i]] <- #english match
    cues$ar_fake_cue_trans[i] #new cue
}

targets <- ar_update %>% filter(ar_fake_target_trans != "")
for (i in 1:nrow(targets)){
  ar$ar_fake_target[ar$ar_fake_target == targets$ar_fake_target[i] #original target match
            & ar$en_target == targets$en_target[i]] <- #english match
    targets$ar_fake_target_trans[i] #new target
}

sum(duplicated(ar$ar_cue))
sum(duplicated(ar$ar_target))
sum(duplicated(ar$ar_fake_cue))
sum(duplicated(ar$ar_fake_target))

nrow(ar %>% filter(ar_cue == ar_target))

export(ar, "../matched_stimuli/ar_matched.csv", row.names = F)

# create possible trials ----
ar_trials <- ar[ , c("ar_cue", "ar_target")]
ar_trials$type <- "related"
ar_trials$cue_type <- "word"
ar_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
ar$en_cue <- tolower(ar$en_cue)
ar$en_target <- tolower(ar$en_target)
# match unrelated pairs as a start 
ar_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(ar_unrelated)){
  ar_unrelated$en_cue[i] <- ar$ar_cue[ar$en_cue == ar_unrelated$en_cue[i]]
  ar_unrelated$en_target[i] <- ar$ar_target[ar$en_target == ar_unrelated$en_target[i]]
}

ar_trials <- rbind(ar_trials,
                   ar_unrelated %>% select(-en_cosine) %>% 
                     rename("ar_cue" = "en_cue", 
                            "ar_target" = "en_target"), 
                   data.frame(ar_cue = ar$ar_fake_cue,
                              ar_target = ar$ar_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(ar_cue = ar$ar_cue[sample(1:1000,
                                                        1000)],
                              ar_target = ar$ar_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(ar_cue = ar$ar_fake_cue[sample(1:1000,
                                                        1000)],
                              ar_target = ar$ar_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(ar_trials[ , c("ar_cue", "ar_target")]))

# update with low cosines from random shuffle ----
# set up model
ar_model <- read.table("/Volumes/SPAML Backup/subs_vec/ar/subs.ar.1e6.txt", quote="\"")
ar_model <- na.omit(ar_model)
ar_model$V1 <- tolower(ar_model$V1)
ar_model <- ar_model[!duplicated(ar_model$V1), ]
rownames(ar_model) <- ar_model$V1
ar_model <- ar_model[ , -1]

ar_trials$ar_cosine <- NA

# get cosine
for (row in 1:nrow(ar_trials)){
  
  if(ar_trials$type[row] != "nonword") { 
    
    ar_trials$ar_cosine[row] <- cosine(as.matrix(t(ar_model[
    c(ar_trials$ar_cue[row], ar_trials$ar_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
ar_trials$ok <- TRUE
ar_trials$ok[ar_trials$type == "unrelated" & abs(ar_trials$ar_cosine) > .15] <- FALSE

good_trials <- ar_trials %>% filter(ok == TRUE)
bad_trials <- ar_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$ar_target <- sample(bad_trials$ar_target, 
                               size = length(bad_trials$ar_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$ar_cosine[row] <- cosine(as.matrix(t(ar_model[
    c(bad_trials$ar_cue[row], bad_trials$ar_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(ar_cosine < .15)))
bad_trials <- bad_trials %>% filter(ar_cosine >= .15)
nrow(bad_trials)
# this section I ran multiple times 

whats_left <- cosine(as.matrix(t(ar_model[c(
  bad_trials$ar_target,
  unique(good_trials$ar_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$ar_target)){
  
  # find all words that could be paired with bad ar_target
  # as updated ar_cue
  potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$ar_target[i]] < .15] 
  
  # find all pairs of good ar_target that could
  # be paired with bad ar_cue
  potential_switch <- good_trials %>% filter(ar_cue %in% potential_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(ar_model[c(
    bad_trials$ar_cue[i],
    potential_switch$ar_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$ar_cue[i], bad_trials$ar_target[i],
    potential_switch$ar_cue[potential_switch$ar_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_ar_cue", "bad_ar_target", 
                           "good_ar_cue", "good_ar_target")

good_trials_small <- good_trials %>% 
  filter(!(ar_cue %in% switch_todo$good_ar_cue & type == "unrelated"))

new_good_trials <- data.frame(
  ar_cue = c(switch_todo$bad_ar_cue, switch_todo$good_ar_cue),
  ar_target = c(switch_todo$good_ar_target, switch_todo$bad_ar_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  ar_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$ar_cosine[row] <- cosine(as.matrix(t(ar_model[
    c(new_good_trials$ar_cue[row], new_good_trials$ar_target[row]) , ])))[2]
}

ar_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(ar_final[ , c("ar_cue", "ar_target")]))

# check cosines
tapply(ar_final$ar_cosine, ar_final$type, mean, na.rm = T)
tapply(ar_final$ar_cosine, ar_final$type, min, na.rm = T)
tapply(ar_final$ar_cosine, ar_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- ar_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(ar_target) %>% 
  filter(n != 2)

weird_trials <- ar_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(ar_target %in% target_table$ar_target)

# check for NA
sum(is.na(ar_final$ar_cue))
sum(is.na(ar_final$ar_target))
sum(grepl("^NA", ar_final$ar_cue))
sum(grepl("^NA", ar_final$ar_target))

# check rows
nrow(ar_final)
table(ar_final$type, ar_final$cue_type, ar_final$target_type)

ar_final$ok <- NULL

export(ar_final, "ar/ar_trials_final.csv")
```

## fa Farsi

```{r eval = F}
# original words
fa <- import("fa/fa_translate.csv")
fa$en_cue <- gsub("digusting", "disgusting", fa$en_cue)

# fix real words ----
fa_update <- import("fa/fa_translated_final.xlsx") %>% 
  mutate(across(everything(), tolower))

# fix cue words ----
cues <- fa_update %>% filter(fa_cue_trans != "")
for (i in 1:nrow(cues)){
  fa$fa_cue[fa$fa_cue == cues$fa_cue[i] #original cue match
            & fa$en_cue == cues$en_cue[i]] <- #english match
    cues$fa_cue_trans[i] #new cue
}

targets <- fa_update %>% filter(fa_target_trans != "")
for (i in 1:nrow(targets)){
  fa$fa_target[fa$fa_target == targets$fa_target[i] #original target match
            & fa$en_target == targets$en_target[i]] <- #english match
    targets$fa_target_trans[i] #new target
}

# fix fake words ----
cues <- fa_update %>% filter(fa_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  fa$fa_fake_cue[fa$fa_fake_cue == cues$fa_fake_cue[i] #original cue match
            & fa$en_cue == cues$en_cue[i]] <- #english match
    cues$fa_fake_cue_trans[i] #new cue
}

targets <- fa_update %>% filter(fa_fake_target_trans != "")
for (i in 1:nrow(targets)){
  fa$fa_fake_target[fa$fa_fake_target == targets$fa_fake_target[i] #original target match
            & fa$en_target == targets$en_target[i]] <- #english match
    targets$fa_fake_target_trans[i] #new target
}

sum(duplicated(fa$fa_cue))
sum(duplicated(fa$fa_target))
sum(duplicated(fa$fa_fake_cue))
sum(duplicated(fa$fa_fake_target))

nrow(fa %>% filter(fa_cue == fa_target))

export(fa, "../matched_stimuli/fa_matched.csv", row.names = F)

# create possible trials ----
fa_trials <- fa[ , c("fa_cue", "fa_target")]
fa_trials$type <- "related"
fa_trials$cue_type <- "word"
fa_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
fa$en_cue <- tolower(fa$en_cue)
fa$en_target <- tolower(fa$en_target)
# match unrelated pairs as a start 
fa_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(fa_unrelated)){
  fa_unrelated$en_cue[i] <- fa$fa_cue[fa$en_cue == fa_unrelated$en_cue[i]]
  fa_unrelated$en_target[i] <- fa$fa_target[fa$en_target == fa_unrelated$en_target[i]]
}

fa_trials <- rbind(fa_trials,
                   fa_unrelated %>% select(-en_cosine) %>% 
                     rename("fa_cue" = "en_cue", 
                            "fa_target" = "en_target"), 
                   data.frame(fa_cue = fa$fa_fake_cue,
                              fa_target = fa$fa_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(fa_cue = fa$fa_cue[sample(1:1000,
                                                        1000)],
                              fa_target = fa$fa_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(fa_cue = fa$fa_fake_cue[sample(1:1000,
                                                        1000)],
                              fa_target = fa$fa_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(fa_trials[ , c("fa_cue", "fa_target")]))

# update with low cosines from random shuffle ----
# set up model
fa_model <- read.table("/Volumes/SPAML Backup/subs_vec/fa/subs.fa.1e6.txt", quote="\"")
fa_model <- na.omit(fa_model)
fa_model$V1 <- tolower(fa_model$V1)
fa_model <- fa_model[!duplicated(fa_model$V1), ]
rownames(fa_model) <- fa_model$V1
fa_model <- fa_model[ , -1]

fa_trials$fa_cosine <- NA

# get cosine
for (row in 1:nrow(fa_trials)){
  
  if(fa_trials$type[row] != "nonword") { 
    
    fa_trials$fa_cosine[row] <- cosine(as.matrix(t(fa_model[
    c(fa_trials$fa_cue[row], fa_trials$fa_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
fa_trials$ok <- TRUE
fa_trials$ok[fa_trials$type == "unrelated" & abs(fa_trials$fa_cosine) > .15] <- FALSE

good_trials <- fa_trials %>% filter(ok == TRUE)
bad_trials <- fa_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$fa_target <- sample(bad_trials$fa_target, 
                               size = length(bad_trials$fa_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$fa_cosine[row] <- cosine(as.matrix(t(fa_model[
    c(bad_trials$fa_cue[row], bad_trials$fa_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(fa_cosine < .15)))
bad_trials <- bad_trials %>% filter(fa_cosine >= .15)
nrow(bad_trials)
# ran section I ran multiple times 

whats_left <- cosine(as.matrix(t(fa_model[c(
  bad_trials$fa_target,
  unique(good_trials$fa_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$fa_target)){
  
  # find all words that could be paired with bad fa_target
  # as updated fa_cue
  potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$fa_target[i]] < .15] 
  
  # find all pairs of good fa_target that could
  # be paired with bad fa_cue
  potential_switch <- good_trials %>% filter(fa_cue %in% potential_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(fa_model[c(
    bad_trials$fa_cue[i],
    potential_switch$fa_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$fa_cue[i], bad_trials$fa_target[i],
    potential_switch$fa_cue[potential_switch$fa_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_fa_cue", "bad_fa_target", 
                           "good_fa_cue", "good_fa_target")

good_trials_small <- good_trials %>% 
  filter(!(fa_cue %in% switch_todo$good_fa_cue & type == "unrelated"))

new_good_trials <- data.frame(
  fa_cue = c(switch_todo$bad_fa_cue, switch_todo$good_fa_cue),
  fa_target = c(switch_todo$good_fa_target, switch_todo$bad_fa_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  fa_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$fa_cosine[row] <- cosine(as.matrix(t(fa_model[
    c(new_good_trials$fa_cue[row], new_good_trials$fa_target[row]) , ])))[2]
}

fa_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(fa_final[ , c("fa_cue", "fa_target")]))

# check cosines
tapply(fa_final$fa_cosine, fa_final$type, mean, na.rm = T)
tapply(fa_final$fa_cosine, fa_final$type, min, na.rm = T)
tapply(fa_final$fa_cosine, fa_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- fa_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(fa_target) %>% 
  filter(n != 2)

weird_trials <- fa_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(fa_target %in% target_table$fa_target)

# deal with mismatches
fa_final$fa_target[fa_final$fa_cue == "هوشیار" & fa_final$fa_target == "امضاء"] = "رئیس پلیس"
fa_final$fa_target[fa_final$fa_cue == "پایین" & fa_final$fa_target == "بتمن"] = "ماهواره"

# check that everyone has a mate
target_table <- fa_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(fa_target) %>% 
  filter(n != 2)

weird_trials <- fa_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(fa_target %in% target_table$fa_target)

# delete extras
fa_final <- fa_final %>% 
  filter(!(fa_cue == "عملیاتی" & fa_target == "بغل")) %>% 
  filter(!(fa_cue == "بررسی" & fa_target == "متاهل"))

# check for NA
sum(is.na(fa_final$fa_cue))
sum(is.na(fa_final$fa_target))
sum(grepl("^NA", fa_final$fa_cue))
sum(grepl("^NA", fa_final$fa_target))

# check rows
nrow(fa_final)
table(fa_final$type, fa_final$cue_type, fa_final$target_type)

fa_final$ok <- NULL

export(fa_final, "fa/fa_trials_final.csv")
```

## fi Finnish

```{r eval = F}
# original words
fi <- import("fi/fi_translate.csv")
fi$en_cue <- gsub("digusting", "disgusting", fi$en_cue)

# fix real words ----
fi_update <- import("fi/fi_translated_final.xlsx") %>% 
  mutate(across(everything(), tolower))

# fix cue words ----
cues <- fi_update %>% filter(fi_cue_trans != "")
for (i in 1:nrow(cues)){
  fi$fi_cue[fi$fi_cue == cues$fi_cue[i] #original cue match
            & fi$en_cue == cues$en_cue[i]] <- #english match
    cues$fi_cue_trans[i] #new cue
}

targets <- fi_update %>% filter(fi_target_trans != "")
for (i in 1:nrow(targets)){
  fi$fi_target[fi$fi_target == targets$fi_target[i] #original target match
            & fi$en_target == targets$en_target[i]] <- #english match
    targets$fi_target_trans[i] #new target
}

# fix fake words ----
cues <- fi_update %>% filter(fi_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  fi$fi_fake_cue[fi$fi_fake_cue == cues$fi_fake_cue[i] #original cue match
            & fi$en_cue == cues$en_cue[i]] <- #english match
    cues$fi_fake_cue_trans[i] #new cue
}

targets <- fi_update %>% filter(fi_fake_target_trans != "")
for (i in 1:nrow(targets)){
  fi$fi_fake_target[fi$fi_fake_target == targets$fi_fake_target[i] #original target match
            & fi$en_target == targets$en_target[i]] <- #english match
    targets$fi_fake_target_trans[i] #new target
}

sum(duplicated(fi$fi_cue))
sum(duplicated(fi$fi_target))
sum(duplicated(fi$fi_fake_cue))
sum(duplicated(fi$fi_fake_target))

nrow(fi %>% filter(fi_cue == fi_target))

export(fi, "../matched_stimuli/fi_matched.csv", row.names = F)

# create possible trials ----
fi_trials <- fi[ , c("fi_cue", "fi_target")]
fi_trials$type <- "related"
fi_trials$cue_type <- "word"
fi_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
fi$en_cue <- tolower(fi$en_cue)
fi$en_target <- tolower(fi$en_target)
# match unrelated pairs as a start 
fi_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(fi_unrelated)){
  fi_unrelated$en_cue[i] <- fi$fi_cue[fi$en_cue == fi_unrelated$en_cue[i]]
  fi_unrelated$en_target[i] <- fi$fi_target[fi$en_target == fi_unrelated$en_target[i]]
}

fi_trials <- rbind(fi_trials,
                   fi_unrelated %>% select(-en_cosine) %>% 
                     rename("fi_cue" = "en_cue", 
                            "fi_target" = "en_target"), 
                   data.frame(fi_cue = fi$fi_fake_cue,
                              fi_target = fi$fi_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(fi_cue = fi$fi_cue[sample(1:1000,
                                                        1000)],
                              fi_target = fi$fi_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(fi_cue = fi$fi_fake_cue[sample(1:1000,
                                                        1000)],
                              fi_target = fi$fi_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(fi_trials[ , c("fi_cue", "fi_target")]))

# update with low cosines from random shuffle ----
# set up model
fi_model <- read.table("/Volumes/SPAML Backup/subs_vec/fi/subs.fi.1e6.txt", quote="\"")
fi_model <- na.omit(fi_model)
fi_model$V1 <- tolower(fi_model$V1)
fi_model <- fi_model[!duplicated(fi_model$V1), ]
rownames(fi_model) <- fi_model$V1
fi_model <- fi_model[ , -1]

fi_trials$fi_cosine <- NA

# get cosine
for (row in 1:nrow(fi_trials)){
  
  if(fi_trials$type[row] != "nonword") { 
    
    fi_trials$fi_cosine[row] <- cosine(as.matrix(t(fi_model[
    c(fi_trials$fi_cue[row], fi_trials$fi_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
fi_trials$ok <- TRUE
fi_trials$ok[fi_trials$type == "unrelated" & abs(fi_trials$fi_cosine) > .15] <- FALSE

good_trials <- fi_trials %>% filter(ok == TRUE)
bad_trials <- fi_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$fi_target <- sample(bad_trials$fi_target, 
                               size = length(bad_trials$fi_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$fi_cosine[row] <- cosine(as.matrix(t(fi_model[
    c(bad_trials$fi_cue[row], bad_trials$fi_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(fi_cosine < .15)))
bad_trials <- bad_trials %>% filter(fi_cosine >= .15)
nrow(bad_trials)
# this section I ran multiple times 

whats_left <- cosine(as.matrix(t(fi_model[c(
  bad_trials$fi_target,
  unique(good_trials$fi_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$fi_target)){
  
  # find all words that could be paired with bad fi_target
  # as updated fi_cue
  potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$fi_target[i]] < .15] 
  
  # find all pairs of good fi_target that could
  # be paired with bad fi_cue
  potential_switch <- good_trials %>% filter(fi_cue %in% potential_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(fi_model[c(
    bad_trials$fi_cue[i],
    potential_switch$fi_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$fi_cue[i], bad_trials$fi_target[i],
    potential_switch$fi_cue[potential_switch$fi_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_fi_cue", "bad_fi_target", 
                           "good_fi_cue", "good_fi_target")

good_trials_small <- good_trials %>% 
  filter(!(fi_cue %in% switch_todo$good_fi_cue & type == "unrelated"))

new_good_trials <- data.frame(
  fi_cue = c(switch_todo$bad_fi_cue, switch_todo$good_fi_cue),
  fi_target = c(switch_todo$good_fi_target, switch_todo$bad_fi_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  fi_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$fi_cosine[row] <- cosine(as.matrix(t(fi_model[
    c(new_good_trials$fi_cue[row], new_good_trials$fi_target[row]) , ])))[2]
}

fi_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(fi_final[ , c("fi_cue", "fi_target")]))

# check cosines
tapply(fi_final$fi_cosine, fi_final$type, mean, na.rm = T)
tapply(fi_final$fi_cosine, fi_final$type, min, na.rm = T)
tapply(fi_final$fi_cosine, fi_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- fi_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(fi_target) %>% 
  filter(n != 2)

weird_trials <- fi_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(fi_target %in% target_table$fi_target)

# check for NA
sum(is.na(fi_final$fi_cue))
sum(is.na(fi_final$fi_target))
sum(grepl("^NA", fi_final$fi_cue))
sum(grepl("^NA", fi_final$fi_target))

# check rows
nrow(fi_final)
table(fi_final$type, fi_final$cue_type, fi_final$target_type)

fi_final$ok <- NULL

export(fi_final, "fi/fi_trials_final.csv")
```

## fr French 

```{r eval = F}
# they formatted it nicely  ----
fr <- import("fr/fr_translated_final.xlsx") %>% 
  mutate(across(everything(), tolower))
fr$en_cue <- gsub("digusting", "disgusting", fr$en_cue)

sum(duplicated(fr$fr_cue))
sum(duplicated(fr$fr_target))
sum(duplicated(fr$fr_fake_cue))
sum(duplicated(fr$fr_fake_target))

nrow(fr %>% filter(fr_cue == fr_target))

export(fr, "../matched_stimuli/fr_matched.csv", row.names = F)

# create possible trials ----
fr_trials <- fr[ , c("fr_cue", "fr_target")]
fr_trials$type <- "related"
fr_trials$cue_type <- "word"
fr_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
fr$en_cue <- tolower(fr$en_cue)
fr$en_target <- tolower(fr$en_target)
# match unrelated pairs as a start 
fr_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(fr_unrelated)){
  fr_unrelated$en_cue[i] <- fr$fr_cue[fr$en_cue == fr_unrelated$en_cue[i]]
  fr_unrelated$en_target[i] <- fr$fr_target[fr$en_target == fr_unrelated$en_target[i]]
}

fr_trials <- rbind(fr_trials,
                   fr_unrelated %>% select(-en_cosine) %>% 
                     rename("fr_cue" = "en_cue", 
                            "fr_target" = "en_target"), 
                   data.frame(fr_cue = fr$fr_fake_cue,
                              fr_target = fr$fr_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(fr_cue = fr$fr_cue[sample(1:1000,
                                                        1000)],
                              fr_target = fr$fr_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(fr_cue = fr$fr_fake_cue[sample(1:1000,
                                                        1000)],
                              fr_target = fr$fr_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(fr_trials[ , c("fr_cue", "fr_target")]))

# update with low cosines from random shuffle ----
# set up model
fr_model <- read.table("/Volumes/SPAML Backup/subs_vec/fr/subs.fr.1e6.txt", quote="\"")
fr_model <- na.omit(fr_model)
fr_model$V1 <- tolower(fr_model$V1)
fr_model <- fr_model[!duplicated(fr_model$V1), ]
rownames(fr_model) <- fr_model$V1
fr_model <- fr_model[ , -1]

fr_trials$fr_cosine <- NA

# get cosine
for (row in 1:nrow(fr_trials)){
  
  if(fr_trials$type[row] != "nonword") { 
    
    fr_trials$fr_cosine[row] <- cosine(as.matrix(t(fr_model[
    c(fr_trials$fr_cue[row], fr_trials$fr_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
fr_trials$ok <- TRUE
fr_trials$ok[fr_trials$type == "unrelated" & abs(fr_trials$fr_cosine) > .15] <- FALSE

good_trials <- fr_trials %>% filter(ok == TRUE)
bad_trials <- fr_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$fr_target <- sample(bad_trials$fr_target, 
                               size = length(bad_trials$fr_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$fr_cosine[row] <- cosine(as.matrix(t(fr_model[
    c(bad_trials$fr_cue[row], bad_trials$fr_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(fr_cosine < .15)))
bad_trials <- bad_trials %>% filter(fr_cosine >= .15)
nrow(bad_trials)
# this section I ran multiple times 

whats_left <- cosine(as.matrix(t(fr_model[c(
  bad_trials$fr_target,
  unique(good_trials$fr_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$fr_target)){
  
  # find all words that could be paired with bad fr_target
  # as updated fr_cue
  potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$fr_target[i]] < .15] 
  
  # find all pairs of good fr_target that could
  # be paired with bad fr_cue
  potential_switch <- good_trials %>% filter(fr_cue %in% potential_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(fr_model[c(
    bad_trials$fr_cue[i],
    potential_switch$fr_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$fr_cue[i], bad_trials$fr_target[i],
    potential_switch$fr_cue[potential_switch$fr_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_fr_cue", "bad_fr_target", 
                           "good_fr_cue", "good_fr_target")

good_trials_small <- good_trials %>% 
  filter(!(fr_cue %in% switch_todo$good_fr_cue & type == "unrelated"))

new_good_trials <- data.frame(
  fr_cue = c(switch_todo$bad_fr_cue, switch_todo$good_fr_cue),
  fr_target = c(switch_todo$good_fr_target, switch_todo$bad_fr_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  fr_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$fr_cosine[row] <- cosine(as.matrix(t(fr_model[
    c(new_good_trials$fr_cue[row], new_good_trials$fr_target[row]) , ])))[2]
}

fr_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(fr_final[ , c("fr_cue", "fr_target")]))

# check cosines
tapply(fr_final$fr_cosine, fr_final$type, mean, na.rm = T)
tapply(fr_final$fr_cosine, fr_final$type, min, na.rm = T)
tapply(fr_final$fr_cosine, fr_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- fr_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(fr_target) %>% 
  filter(n != 2)

weird_trials <- fr_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(fr_target %in% target_table$fr_target)

# check for NA
sum(is.na(fr_final$fr_cue))
sum(is.na(fr_final$fr_target))
sum(grepl("^NA", fr_final$fr_cue))
sum(grepl("^NA", fr_final$fr_target))

# check rows
nrow(fr_final)
table(fr_final$type, fr_final$cue_type, fr_final$target_type)

fr_final$ok <- NULL

export(fr_final, "fr/fr_trials_final.csv")
```

## el Greek

```{r eval = F}
# original words
el <- import("el/el_translate.csv")
el$en_cue <- gsub("digusting", "disgusting", el$en_cue)

# fix real words ----
el_update <- import("el/el_translated_final.xlsx") %>% 
  mutate(across(everything(), tolower))

# fix cue words ----
cues <- el_update %>% filter(el_cue_trans != "")
for (i in 1:nrow(cues)){
  el$el_cue[el$el_cue == cues$el_cue[i] #original cue match
            & el$en_cue == cues$en_cue[i]] <- #english match
    cues$el_cue_trans[i] #new cue
}

targets <- el_update %>% filter(el_target_trans != "")
for (i in 1:nrow(targets)){
  el$el_target[el$el_target == targets$el_target[i] #original target match
            & el$en_target == targets$en_target[i]] <- #english match
    targets$el_target_trans[i] #new target
}

# fix fake words ----
cues <- el_update %>% filter(el_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  el$el_fake_cue[el$el_fake_cue == cues$el_fake_cue[i] #original cue match
            & el$en_cue == cues$en_cue[i]] <- #english match
    cues$el_fake_cue_trans[i] #new cue
}

targets <- el_update %>% filter(el_fake_target_trans != "")
for (i in 1:nrow(targets)){
  el$el_fake_target[el$el_fake_target == targets$el_fake_target[i] #original target match
            & el$en_target == targets$en_target[i]] <- #english match
    targets$el_fake_target_trans[i] #new target
}

sum(duplicated(el$el_cue))
sum(duplicated(el$el_target))
sum(duplicated(el$el_fake_cue))
sum(duplicated(el$el_fake_target))

nrow(el %>% filter(el_cue == el_target))

export(el, "../matched_stimuli/el_matched.csv", row.names = F)

# create possible trials ----
el_trials <- el[ , c("el_cue", "el_target")]
el_trials$type <- "related"
el_trials$cue_type <- "word"
el_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
el$en_cue <- tolower(el$en_cue)
el$en_target <- tolower(el$en_target)
# match unrelated pairs as a start 
el_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(el_unrelated)){
  el_unrelated$en_cue[i] <- el$el_cue[el$en_cue == el_unrelated$en_cue[i]]
  el_unrelated$en_target[i] <- el$el_target[el$en_target == el_unrelated$en_target[i]]
}

el_trials <- rbind(el_trials,
                   el_unrelated %>% select(-en_cosine) %>% 
                     rename("el_cue" = "en_cue", 
                            "el_target" = "en_target"), 
                   data.frame(el_cue = el$el_fake_cue,
                              el_target = el$el_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(el_cue = el$el_cue[sample(1:1000,
                                                        1000)],
                              el_target = el$el_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(el_cue = el$el_fake_cue[sample(1:1000,
                                                        1000)],
                              el_target = el$el_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(el_trials[ , c("el_cue", "el_target")]))

# update with low cosines from random shuffle ----
# set up model
el_model <- read.table("/Volumes/SPAML Backup/subs_vec/el/subs.el.1e6.txt", quote="\"")
el_model <- na.omit(el_model)
el_model$V1 <- tolower(el_model$V1)
el_model <- el_model[!duplicated(el_model$V1), ]
rownames(el_model) <- el_model$V1
el_model <- el_model[ , -1]

el_trials$el_cosine <- NA

# get cosine
for (row in 1:nrow(el_trials)){
  
  if(el_trials$type[row] != "nonword") { 
    
    el_trials$el_cosine[row] <- cosine(as.matrix(t(el_model[
    c(el_trials$el_cue[row], el_trials$el_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
el_trials$ok <- TRUE
el_trials$ok[el_trials$type == "unrelated" & abs(el_trials$el_cosine) > .15] <- FALSE

good_trials <- el_trials %>% filter(ok == TRUE)
bad_trials <- el_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$el_target <- sample(bad_trials$el_target, 
                               size = length(bad_trials$el_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$el_cosine[row] <- cosine(as.matrix(t(el_model[
    c(bad_trials$el_cue[row], bad_trials$el_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(el_cosine < .15)))
bad_trials <- bad_trials %>% filter(el_cosine >= .15)
nrow(bad_trials)
# ran section I ran multiple times 

whats_left <- cosine(as.matrix(t(el_model[c(
  bad_trials$el_target,
  unique(good_trials$el_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$el_target)){
  
  # find all words that could be paired with bad el_target
  # as updated el_cue
  potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$el_target[i]] < .15] 
  
  # find all pairs of good el_target that could
  # be paired with bad el_cue
  potential_switch <- good_trials %>% filter(el_cue %in% potential_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(el_model[c(
    bad_trials$el_cue[i],
    potential_switch$el_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$el_cue[i], bad_trials$el_target[i],
    potential_switch$el_cue[potential_switch$el_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_el_cue", "bad_el_target", 
                           "good_el_cue", "good_el_target")

good_trials_small <- good_trials %>% 
  filter(!(el_cue %in% switch_todo$good_el_cue & type == "unrelated"))

new_good_trials <- data.frame(
  el_cue = c(switch_todo$bad_el_cue, switch_todo$good_el_cue),
  el_target = c(switch_todo$good_el_target, switch_todo$bad_el_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  el_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$el_cosine[row] <- cosine(as.matrix(t(el_model[
    c(new_good_trials$el_cue[row], new_good_trials$el_target[row]) , ])))[2]
}

el_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(el_final[ , c("el_cue", "el_target")]))

# check cosines
tapply(el_final$el_cosine, el_final$type, mean, na.rm = T)
tapply(el_final$el_cosine, el_final$type, min, na.rm = T)
tapply(el_final$el_cosine, el_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- el_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(el_target) %>% 
  filter(n != 2)

weird_trials <- el_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(el_target %in% target_table$el_target)

# check for NA
sum(is.na(el_final$el_cue))
sum(is.na(el_final$el_target))
sum(grepl("^NA", el_final$el_cue))
sum(grepl("^NA", el_final$el_target))

# check rows
nrow(el_final)
table(el_final$type, el_final$cue_type, el_final$target_type)

el_final$ok <- NULL

export(el_final, "el/el_trials_final.csv")
```

## he Hebrew

```{r eval = F}
# original words
he <- import("he/he_translate.csv")
he$en_cue <- gsub("digusting", "disgusting", he$en_cue)

# fix real words ----
he_update <- import("he/he_translated_final.xlsx") %>% 
  mutate(across(everything(), tolower))

he_update$he_fake_cue <- he_update$he_fake_cue_update
he_update$he_fake_target <- he_update$he_fake_target_update

# fix cue words ----
# cues <- he_update %>% filter(he_cue_trans != "")
# for (i in 1:nrow(cues)){
#   he$he_cue[he$he_cue == cues$he_cue[i] #original cue match
#             & he$en_cue == cues$en_cue[i]] <- #english match
#     cues$he_cue_trans[i] #new cue
# }
# 
# targets <- he_update %>% filter(he_target_trans != "")
# for (i in 1:nrow(targets)){
#   he$he_target[he$he_target == targets$he_target[i] #original target match
#             & he$en_target == targets$en_target[i]] <- #english match
#     targets$he_target_trans[i] #new target
# }
# 
# # fix fake words ----
# he$he_fake_target <- he_update$he_fake_target_final
# he$he_fake_cue <- he_update$he_fake_cue_final

he <- he_update %>% 
  select(-he_fake_cue_update, -he_fake_target_update)

sum(duplicated(he$he_cue))
sum(duplicated(he$he_target))
sum(duplicated(he$he_fake_cue))
sum(duplicated(he$he_fake_target))

nrow(he %>% filter(he_cue == he_target))

export(he, "../matched_stimuli/he_matched.csv", row.names = F)

# create possible trials ----
he_trials <- he[ , c("he_cue", "he_target")]
he_trials$type <- "related"
he_trials$cue_type <- "word"
he_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
he$en_cue <- tolower(he$en_cue)
he$en_target <- tolower(he$en_target)
# match unrelated pairs as a start 
he_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(he_unrelated)){
  he_unrelated$en_cue[i] <- he$he_cue[he$en_cue == he_unrelated$en_cue[i]]
  he_unrelated$en_target[i] <- he$he_target[he$en_target == he_unrelated$en_target[i]]
}

he_trials <- rbind(he_trials,
                   he_unrelated %>% select(-en_cosine) %>% 
                     rename("he_cue" = "en_cue", 
                            "he_target" = "en_target"), 
                   data.frame(he_cue = he$he_fake_cue,
                              he_target = he$he_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(he_cue = he$he_cue[sample(1:1000,
                                                        1000)],
                              he_target = he$he_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(he_cue = he$he_fake_cue[sample(1:1000,
                                                        1000)],
                              he_target = he$he_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(he_trials[ , c("he_cue", "he_target")]))

# update with low cosines from random shuffle ----
# set up model
he_model <- read.table("/Volumes/SPAML Backup/subs_vec/he/subs.he.1e6.txt", quote="\"")
he_model <- na.omit(he_model)
he_model$V1 <- tolower(he_model$V1)
he_model <- he_model[!duplicated(he_model$V1), ]
rownames(he_model) <- he_model$V1
he_model <- he_model[ , -1]

he_trials$he_cosine <- NA

# get cosine
for (row in 1:nrow(he_trials)){
  
  if(he_trials$type[row] != "nonword") { 
    
    he_trials$he_cosine[row] <- cosine(as.matrix(t(he_model[
    c(he_trials$he_cue[row], he_trials$he_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
he_trials$ok <- TRUE
he_trials$ok[he_trials$type == "unrelated" & abs(he_trials$he_cosine) > .15] <- FALSE

good_trials <- he_trials %>% filter(ok == TRUE)
bad_trials <- he_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$he_target <- sample(bad_trials$he_target, 
                               size = length(bad_trials$he_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$he_cosine[row] <- cosine(as.matrix(t(he_model[
    c(bad_trials$he_cue[row], bad_trials$he_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(he_cosine < .15)))
bad_trials <- bad_trials %>% filter(he_cosine >= .15)
nrow(bad_trials)
# this section I ran multiple times 

whats_left <- cosine(as.matrix(t(he_model[c(
  bad_trials$he_target,
  unique(good_trials$he_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$he_target)){
  
  # find all words that could be paired with bad he_target
  # as updated he_cue
  potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$he_target[i]] < .15] 
  
  # find all pairs of good he_target that could
  # be paired with bad he_cue
  potential_switch <- good_trials %>% filter(he_cue %in% potential_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(he_model[c(
    bad_trials$he_cue[i],
    potential_switch$he_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$he_cue[i], bad_trials$he_target[i],
    potential_switch$he_cue[potential_switch$he_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_he_cue", "bad_he_target", 
                           "good_he_cue", "good_he_target")

good_trials_small <- good_trials %>% 
  filter(!(he_cue %in% switch_todo$good_he_cue & type == "unrelated"))

new_good_trials <- data.frame(
  he_cue = c(switch_todo$bad_he_cue, switch_todo$good_he_cue),
  he_target = c(switch_todo$good_he_target, switch_todo$bad_he_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  he_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$he_cosine[row] <- cosine(as.matrix(t(he_model[
    c(new_good_trials$he_cue[row], new_good_trials$he_target[row]) , ])))[2]
}

he_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(he_final[ , c("he_cue", "he_target")]))

# check cosines
tapply(he_final$he_cosine, he_final$type, mean, na.rm = T)
tapply(he_final$he_cosine, he_final$type, min, na.rm = T)
tapply(he_final$he_cosine, he_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- he_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(he_target) %>% 
  filter(n != 2)

weird_trials <- he_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(he_target %in% target_table$he_target)

# check for NA
sum(is.na(he_final$he_cue))
sum(is.na(he_final$he_target))
sum(grepl("^NA", he_final$he_cue))
sum(grepl("^NA", he_final$he_target))

# check rows
nrow(he_final)
table(he_final$type, he_final$cue_type, he_final$target_type)

he_final$ok <- NULL

export(he_final, "he/he_trials_final.csv")
```

## hu Hungarian

```{r eval = F}
# original words
hu <- import("hu/hu_translate.csv")
hu$en_cue <- gsub("digusting", "disgusting", hu$en_cue)

# fix real words ----
hu_update <- import("hu/hu_translated_final.xlsx") %>% 
  mutate(across(everything(), tolower))

# fix cue words ----
cues <- hu_update %>% filter(hu_cue_trans != "")
for (i in 1:nrow(cues)){
  hu$hu_cue[hu$hu_cue == cues$hu_cue[i] #original cue match
            & hu$en_cue == cues$en_cue[i]] <- #english match
    cues$hu_cue_trans[i] #new cue
}

targets <- hu_update %>% filter(hu_target_trans != "")
for (i in 1:nrow(targets)){
  hu$hu_target[hu$hu_target == targets$hu_target[i] #original target match
            & hu$en_target == targets$en_target[i]] <- #english match
    targets$hu_target_trans[i] #new target
}

# fix fake words ----
cues <- hu_update %>% filter(hu_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  hu$hu_fake_cue[hu$hu_fake_cue == cues$hu_fake_cue[i] #original cue match
            & hu$en_cue == cues$en_cue[i]] <- #english match
    cues$hu_fake_cue_trans[i] #new cue
}

targets <- hu_update %>% filter(hu_fake_target_trans != "")
for (i in 1:nrow(targets)){
  hu$hu_fake_target[hu$hu_fake_target == targets$hu_fake_target[i] #original target match
            & hu$en_target == targets$en_target[i]] <- #english match
    targets$hu_fake_target_trans[i] #new target
}

sum(duplicated(hu$hu_cue))
sum(duplicated(hu$hu_target))
sum(duplicated(hu$hu_fake_cue))
sum(duplicated(hu$hu_fake_target))

nrow(hu %>% filter(hu_cue == hu_target))

export(hu, "../matched_stimuli/hu_matched.csv", row.names = F)

# create possible trials ----
hu_trials <- hu[ , c("hu_cue", "hu_target")]
hu_trials$type <- "related"
hu_trials$cue_type <- "word"
hu_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
hu$en_cue <- tolower(hu$en_cue)
hu$en_target <- tolower(hu$en_target)
# match unrelated pairs as a start 
hu_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(hu_unrelated)){
  hu_unrelated$en_cue[i] <- hu$hu_cue[hu$en_cue == hu_unrelated$en_cue[i]]
  hu_unrelated$en_target[i] <- hu$hu_target[hu$en_target == hu_unrelated$en_target[i]]
}

hu_trials <- rbind(hu_trials,
                   hu_unrelated %>% select(-en_cosine) %>% 
                     rename("hu_cue" = "en_cue", 
                            "hu_target" = "en_target"), 
                   data.frame(hu_cue = hu$hu_fake_cue,
                              hu_target = hu$hu_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(hu_cue = hu$hu_cue[sample(1:1000,
                                                        1000)],
                              hu_target = hu$hu_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(hu_cue = hu$hu_fake_cue[sample(1:1000,
                                                        1000)],
                              hu_target = hu$hu_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(hu_trials[ , c("hu_cue", "hu_target")]))

# update with low cosines from random shuffle ----
# set up model
hu_model <- read.table("/Volumes/SPAML Backup/subs_vec/hu/subs.hu.1e6.txt", quote="\"")
hu_model <- na.omit(hu_model)
hu_model$V1 <- tolower(hu_model$V1)
hu_model <- hu_model[!duplicated(hu_model$V1), ]
rownames(hu_model) <- hu_model$V1
hu_model <- hu_model[ , -1]

hu_trials$hu_cosine <- NA

# get cosine
for (row in 1:nrow(hu_trials)){
  
  if(hu_trials$type[row] != "nonword") { 
    
    hu_trials$hu_cosine[row] <- cosine(as.matrix(t(hu_model[
    c(hu_trials$hu_cue[row], hu_trials$hu_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
hu_trials$ok <- TRUE
hu_trials$ok[hu_trials$type == "unrelated" & abs(hu_trials$hu_cosine) > .15] <- FALSE

good_trials <- hu_trials %>% filter(ok == TRUE)
bad_trials <- hu_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$hu_target <- sample(bad_trials$hu_target, 
                               size = length(bad_trials$hu_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$hu_cosine[row] <- cosine(as.matrix(t(hu_model[
    c(bad_trials$hu_cue[row], bad_trials$hu_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(hu_cosine < .15)))
bad_trials <- bad_trials %>% filter(hu_cosine >= .15)
nrow(bad_trials)
# ran section I ran multiple times 

whats_left <- cosine(as.matrix(t(hu_model[c(
  bad_trials$hu_target,
  unique(good_trials$hu_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$hu_target)){
  
  # find all words that could be paired with bad hu_target
  # as updated hu_cue
  potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$hu_target[i]] < .15] 
  
  # find all pairs of good hu_target that could
  # be paired with bad hu_cue
  potential_switch <- good_trials %>% filter(hu_cue %in% potential_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(hu_model[c(
    bad_trials$hu_cue[i],
    potential_switch$hu_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$hu_cue[i], bad_trials$hu_target[i],
    potential_switch$hu_cue[potential_switch$hu_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_hu_cue", "bad_hu_target", 
                           "good_hu_cue", "good_hu_target")

good_trials_small <- good_trials %>% 
  filter(!(hu_cue %in% switch_todo$good_hu_cue & type == "unrelated"))

new_good_trials <- data.frame(
  hu_cue = c(switch_todo$bad_hu_cue, switch_todo$good_hu_cue),
  hu_target = c(switch_todo$good_hu_target, switch_todo$bad_hu_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  hu_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$hu_cosine[row] <- cosine(as.matrix(t(hu_model[
    c(new_good_trials$hu_cue[row], new_good_trials$hu_target[row]) , ])))[2]
}

hu_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(hu_final[ , c("hu_cue", "hu_target")]))

# check cosines
tapply(hu_final$hu_cosine, hu_final$type, mean, na.rm = T)
tapply(hu_final$hu_cosine, hu_final$type, min, na.rm = T)
tapply(hu_final$hu_cosine, hu_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- hu_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(hu_target) %>% 
  filter(n != 2)

weird_trials <- hu_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(hu_target %in% target_table$hu_target)

# check for NA
sum(is.na(hu_final$hu_cue))
sum(is.na(hu_final$hu_target))
sum(grepl("^NA", hu_final$hu_cue))
sum(grepl("^NA", hu_final$hu_target))

# check rows
nrow(hu_final)
table(hu_final$type, hu_final$cue_type, hu_final$target_type)

hu_final$ok <- NULL

export(hu_final, "hu/hu_trials_final.csv")
```

## zh Simplified Chinese

```{r eval = F}
# fix real words ----
zh_update <- import("zh/simplified/zh_translated_final.xlsx") %>% 
  mutate(across(everything(), tolower))

zh <- zh_update %>% 
  select(zh_cue_Melinna, zh_target_Melinna, 
         en_cue, en_target, 
         zh_fake_cue_trans, zh_fake_target_trans) %>% 
  rename(zh_cue = zh_cue_Melinna, 
         zh_target = zh_target_Melinna, 
         zh_fake_cue = zh_fake_cue_trans, 
         zh_fake_target = zh_fake_target_trans)

sum(duplicated(zh$zh_cue))
sum(duplicated(zh$zh_target))
sum(duplicated(zh$zh_fake_cue))
sum(duplicated(zh$zh_fake_target))

nrow(zh %>% filter(zh_cue == zh_target)) # after so much trouble, two is ok 

export(zh, "../matched_stimuli/zh_simple_matched.csv", row.names = F)

# create possible trials ----
zh_trials <- zh[ , c("zh_cue", "zh_target")]
zh_trials$type <- "related"
zh_trials$cue_type <- "word"
zh_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
zh$en_cue <- tolower(zh$en_cue)
zh$en_target <- tolower(zh$en_target)
# match unrelated pairs as a start 
zh_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(zh_unrelated)){
  zh_unrelated$en_cue[i] <- zh$zh_cue[zh$en_cue == zh_unrelated$en_cue[i]]
  zh_unrelated$en_target[i] <- zh$zh_target[zh$en_target == zh_unrelated$en_target[i]]
}

zh_trials <- rbind(zh_trials,
                   zh_unrelated %>% select(-en_cosine) %>% 
                     rename("zh_cue" = "en_cue", 
                            "zh_target" = "en_target"), 
                   data.frame(zh_cue = zh$zh_fake_cue,
                              zh_target = zh$zh_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(zh_cue = zh$zh_cue[sample(1:1000,
                                                        1000)],
                              zh_target = zh$zh_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(zh_cue = zh$zh_fake_cue[sample(1:1000,
                                                        1000)],
                              zh_target = zh$zh_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(zh_trials[ , c("zh_cue", "zh_target")]))

# update with low cosines from random shuffle ----
# set up model
zh_model <- read.csv("/Volumes/SPAML Backup/subs_vec/zh_cn/zh_300_5_sg_wxd.csv", quote="\"")
zh_model <- na.omit(zh_model)
zh_model$word <- tolower(zh_model$word)
zh_model <- zh_model[!duplicated(zh_model$word), ]
rownames(zh_model) <- zh_model$word
zh_model <- zh_model[ , -1]

zh_trials$zh_cosine <- NA

# get cosine
for (row in 1:nrow(zh_trials)){
  
  if(zh_trials$type[row] != "nonword") { 
    
    zh_trials$zh_cosine[row] <- cosine(as.matrix(t(zh_model[
    c(zh_trials$zh_cue[row], zh_trials$zh_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
zh_trials$ok <- TRUE
zh_trials$ok[zh_trials$type == "unrelated" & abs(zh_trials$zh_cosine) > .15] <- FALSE

good_trials <- zh_trials %>% filter(ok == TRUE)
bad_trials <- zh_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$zh_target <- sample(bad_trials$zh_target, 
                               size = length(bad_trials$zh_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$zh_cosine[row] <- cosine(as.matrix(t(zh_model[
    c(bad_trials$zh_cue[row], bad_trials$zh_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(zh_cosine < .15)))
bad_trials <- bad_trials %>% filter(zh_cosine >= .15)
nrow(bad_trials)
# this section I ran multiple times 

# whats_left <- cosine(as.matrix(t(zh_model[c(
#   bad_trials$zh_target,
#   unique(good_trials$zh_cue[good_trials$type == "unrelated"])) , ])))
# whats_left <- as.data.frame(whats_left)
# 
# switch_todo <- matrix(NA, nrow = nrow(bad_trials),
#                       ncol = 4)
# # find suggestions that the switch is ok 
# for (i in 1:length(bad_trials$zh_target)){
#   
#   # find all words that could be paired with bad zh_target
#   # as updated zh_cue
#   potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$zh_target[i]] < .15] 
#   
#   # find all pairs of good zh_target that could
#   # be paired with bad zh_cue
#   potential_switch <- good_trials %>% filter(zh_cue %in% potential_cues) %>% filter(type == "unrelated")
#   
#   # find switchables 
#   switches <- cosine(as.matrix(t(zh_model[c(
#     bad_trials$zh_cue[i],
#     potential_switch$zh_target), 
#   ])))
#   
#   new_target <- names(which.min(switches[1, ]))
#   
#   switch_todo[i , ] <- c(bad_trials$zh_cue[i], bad_trials$zh_target[i],
#     potential_switch$zh_cue[potential_switch$zh_target == new_target],
#     new_target)
# 
# }
# 
# switch_todo <- as.data.frame(switch_todo)
# colnames(switch_todo) <- c("bad_zh_cue", "bad_zh_target", 
#                            "good_zh_cue", "good_zh_target")
# 
# good_trials_small <- good_trials %>% 
#   filter(!(zh_cue %in% switch_todo$good_zh_cue & type == "unrelated"))
# 
# new_good_trials <- data.frame(
#   zh_cue = c(switch_todo$bad_zh_cue, switch_todo$good_zh_cue),
#   zh_target = c(switch_todo$good_zh_target, switch_todo$bad_zh_target),
#   type = rep("unrelated", nrow(switch_todo)*2),
#   cue_type = rep("word", nrow(switch_todo)*2),
#   target_type = rep("word", nrow(switch_todo)*2),
#   zh_cosine = rep(NA, nrow(switch_todo)*2),
#   ok = rep(FALSE, nrow(switch_todo)*2)
# )
# 
# for (row in 1:nrow(new_good_trials)){
#     new_good_trials$zh_cosine[row] <- cosine(as.matrix(t(zh_model[
#     c(new_good_trials$zh_cue[row], new_good_trials$zh_target[row]) , ])))[2]
# }

zh_final <- bind_rows(good_trials, bad_trials)
sum(duplicated(zh_final[ , c("zh_cue", "zh_target")]))

# check cosines
tapply(zh_final$zh_cosine, zh_final$type, mean, na.rm = T)
tapply(zh_final$zh_cosine, zh_final$type, min, na.rm = T)
tapply(zh_final$zh_cosine, zh_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- zh_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(zh_target) %>% 
  filter(n != 2)

weird_trials <- zh_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(zh_target %in% target_table$zh_target)

# check for NA
sum(is.na(zh_final$zh_cue))
sum(is.na(zh_final$zh_target))
sum(grepl("^NA", zh_final$zh_cue))
sum(grepl("^NA", zh_final$zh_target))

# check rows
nrow(zh_final)
table(zh_final$type, zh_final$cue_type, zh_final$target_type)

zh_final$ok <- NULL

export(zh_final, "zh/zh_trials_final.csv")
```

## zh_hk Traditional Chinese

```{r eval = F}
# fix real words ----
zh_hk_update <- import("zh/traditional/zh_hk_translated_final.xlsx") %>% 
  mutate(across(everything(), tolower))

zh_hk <- zh_hk_update %>% 
  select(zh_hk_cue, zh_hk_target, 
         zh_hk_fake_cue, zh_hk_fake_target, 
         en_cue, en_target) 

sum(duplicated(zh_hk$zh_hk_cue))
sum(duplicated(zh_hk$zh_hk_target))
sum(duplicated(zh_hk$zh_hk_fake_cue))
sum(duplicated(zh_hk$zh_hk_fake_target))

nrow(zh_hk %>% filter(zh_hk_cue == zh_hk_target))

export(zh_hk, "../matched_stimuli/zh_hk_matched.csv", row.names = F)

# create possible trials ----
zh_hk_trials <- zh_hk[ , c("zh_hk_cue", "zh_hk_target")]
zh_hk_trials$type <- "related"
zh_hk_trials$cue_type <- "word"
zh_hk_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
zh_hk$en_cue <- tolower(zh_hk$en_cue)
zh_hk$en_target <- tolower(zh_hk$en_target)
# match unrelated pairs as a start 
zh_hk_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(zh_hk_unrelated)){
  zh_hk_unrelated$en_cue[i] <- zh_hk$zh_hk_cue[zh_hk$en_cue == zh_hk_unrelated$en_cue[i]]
  zh_hk_unrelated$en_target[i] <- zh_hk$zh_hk_target[zh_hk$en_target == zh_hk_unrelated$en_target[i]]
}

zh_hk_trials <- rbind(zh_hk_trials,
                   zh_hk_unrelated %>% select(-en_cosine) %>% 
                     rename("zh_hk_cue" = "en_cue", 
                            "zh_hk_target" = "en_target"), 
                   data.frame(zh_hk_cue = zh_hk$zh_hk_fake_cue,
                              zh_hk_target = zh_hk$zh_hk_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(zh_hk_cue = zh_hk$zh_hk_cue[sample(1:1000,
                                                        1000)],
                              zh_hk_target = zh_hk$zh_hk_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(zh_hk_cue = zh_hk$zh_hk_fake_cue[sample(1:1000,
                                                        1000)],
                              zh_hk_target = zh_hk$zh_hk_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(zh_hk_trials[ , c("zh_hk_cue", "zh_hk_target")]))

# update with low cosines from random shuffle ----
# set up model
zh_hk_model <- read.csv("/Volumes/SPAML Backup/subs_vec/zh_tw/tw_300_5_sg_wxd.csv")
zh_hk_model <- na.omit(zh_hk_model)
zh_hk_model$word <- tolower(zh_hk_model$word)
zh_hk_model <- zh_hk_model[!duplicated(zh_hk_model$word), ]
rownames(zh_hk_model) <- zh_hk_model$word
zh_hk_model <- zh_hk_model[ , -1]

zh_hk_trials$zh_hk_cosine <- NA

# get cosine
for (row in 1:nrow(zh_hk_trials)){
  
  if(zh_hk_trials$type[row] != "nonword") { 
    
    zh_hk_trials$zh_hk_cosine[row] <- cosine(as.matrix(t(zh_hk_model[
    c(zh_hk_trials$zh_hk_cue[row], zh_hk_trials$zh_hk_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
zh_hk_trials$ok <- TRUE
zh_hk_trials$ok[zh_hk_trials$type == "unrelated" & abs(zh_hk_trials$zh_hk_cosine) > .15] <- FALSE

good_trials <- zh_hk_trials %>% filter(ok == TRUE)
bad_trials <- zh_hk_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$zh_hk_target <- sample(bad_trials$zh_hk_target, 
                               size = length(bad_trials$zh_hk_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$zh_hk_cosine[row] <- cosine(as.matrix(t(zh_hk_model[
    c(bad_trials$zh_hk_cue[row], bad_trials$zh_hk_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(zh_hk_cosine < .15)))
bad_trials <- bad_trials %>% filter(zh_hk_cosine >= .15)
nrow(bad_trials)
# this section I ran multiple times 

zh_hk_final <- bind_rows(good_trials, bad_trials)
sum(duplicated(zh_hk_final[ , c("zh_hk_cue", "zh_hk_target")]))

# check cosines
tapply(zh_hk_final$zh_hk_cosine, zh_hk_final$type, mean, na.rm = T)
tapply(zh_hk_final$zh_hk_cosine, zh_hk_final$type, min, na.rm = T)
tapply(zh_hk_final$zh_hk_cosine, zh_hk_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- zh_hk_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(zh_hk_target) %>% 
  filter(n != 2)

weird_trials <- zh_hk_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(zh_hk_target %in% target_table$zh_hk_target)

# check for NA
sum(is.na(zh_hk_final$zh_hk_cue))
sum(is.na(zh_hk_final$zh_hk_target))
sum(grepl("^NA", zh_hk_final$zh_hk_cue))
sum(grepl("^NA", zh_hk_final$zh_hk_target))

# check rows
nrow(zh_hk_final)
table(zh_hk_final$type, zh_hk_final$cue_type, zh_hk_final$target_type)

zh_hk_final$ok <- NULL

export(zh_hk_final, "zh/traditional/zh_hk_trials_final.csv")
```

## pt Portuguese 

```{r eval = F}
# original words
pt <- import("pt/pt_translate.csv")
pt$en_cue <- gsub("digusting", "disgusting", pt$en_cue)

# fix real words ----
pt_update <- import("pt/pt_translated_final.xlsx") %>% 
  mutate(across(everything(), tolower))

# fix cue words ----
cues <- pt_update %>% filter(pt_cue_trans != "")
for (i in 1:nrow(cues)){
  pt$pt_cue[pt$pt_cue == cues$pt_cue[i] #original cue match
            & pt$en_cue == cues$en_cue[i]] <- #english match
    cues$pt_cue_trans[i] #new cue
}

targets <- pt_update %>% filter(pt_target_trans != "")
for (i in 1:nrow(targets)){
  pt$pt_target[pt$pt_target == targets$pt_target[i] #original target match
            & pt$en_target == targets$en_target[i]] <- #english match
    targets$pt_target_trans[i] #new target
}

# fix fake words ----
cues <- pt_update %>% filter(pt_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  pt$pt_fake_cue[pt$pt_fake_cue == cues$pt_fake_cue[i] #original cue match
            & pt$en_cue == cues$en_cue[i]] <- #english match
    cues$pt_fake_cue_trans[i] #new cue
}

targets <- pt_update %>% filter(pt_fake_target_trans != "")
for (i in 1:nrow(targets)){
  pt$pt_fake_target[pt$pt_fake_target == targets$pt_fake_target[i] #original target match
            & pt$en_target == targets$en_target[i]] <- #english match
    targets$pt_fake_target_trans[i] #new target
}

sum(duplicated(pt$pt_cue))
sum(duplicated(pt$pt_target))
sum(duplicated(pt$pt_fake_cue))
sum(duplicated(pt$pt_fake_target))

nrow(pt %>% filter(pt_cue == pt_target))

export(pt, "../matched_stimuli/pt_matched.csv", row.names = F)

# create possible trials ----
pt_trials <- pt[ , c("pt_cue", "pt_target")]
pt_trials$type <- "related"
pt_trials$cue_type <- "word"
pt_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
pt$en_cue <- tolower(pt$en_cue)
pt$en_target <- tolower(pt$en_target)
# match unrelated pairs as a start 
pt_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(pt_unrelated)){
  pt_unrelated$en_cue[i] <- pt$pt_cue[pt$en_cue == pt_unrelated$en_cue[i]]
  pt_unrelated$en_target[i] <- pt$pt_target[pt$en_target == pt_unrelated$en_target[i]]
}

pt_trials <- rbind(pt_trials,
                   pt_unrelated %>% select(-en_cosine) %>% 
                     rename("pt_cue" = "en_cue", 
                            "pt_target" = "en_target"), 
                   data.frame(pt_cue = pt$pt_fake_cue,
                              pt_target = pt$pt_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(pt_cue = pt$pt_cue[sample(1:1000,
                                                        1000)],
                              pt_target = pt$pt_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(pt_cue = pt$pt_fake_cue[sample(1:1000,
                                                        1000)],
                              pt_target = pt$pt_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(pt_trials[ , c("pt_cue", "pt_target")]))

# update with low cosines from random shuffle ----
# set up model
pt_model <- read.table("/Volumes/SPAML Backup/subs_vec/pt/subs.pt.1e6.txt", quote="\"")
pt_model <- na.omit(pt_model)
pt_model$V1 <- tolower(pt_model$V1)
pt_model <- pt_model[!duplicated(pt_model$V1), ]
rownames(pt_model) <- pt_model$V1
pt_model <- pt_model[ , -1]

pt_trials$pt_cosine <- NA

# get cosine
for (row in 1:nrow(pt_trials)){
  
  if(pt_trials$type[row] != "nonword") { 
    
    pt_trials$pt_cosine[row] <- cosine(as.matrix(t(pt_model[
    c(pt_trials$pt_cue[row], pt_trials$pt_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
pt_trials$ok <- TRUE
pt_trials$ok[pt_trials$type == "unrelated" & abs(pt_trials$pt_cosine) > .15] <- FALSE

good_trials <- pt_trials %>% filter(ok == TRUE)
bad_trials <- pt_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$pt_target <- sample(bad_trials$pt_target, 
                               size = length(bad_trials$pt_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$pt_cosine[row] <- cosine(as.matrix(t(pt_model[
    c(bad_trials$pt_cue[row], bad_trials$pt_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(pt_cosine < .15)))
bad_trials <- bad_trials %>% filter(pt_cosine >= .15)
nrow(bad_trials)
# ran section I ran multiple times 

whats_left <- cosine(as.matrix(t(pt_model[c(
  bad_trials$pt_target,
  unique(good_trials$pt_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$pt_target)){
  
  # find all words that could be paired with bad pt_target
  # as updated pt_cue
  potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$pt_target[i]] < .15] 
  
  # find all pairs of good pt_target that could
  # be paired with bad pt_cue
  potential_switch <- good_trials %>% filter(pt_cue %in% potential_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(pt_model[c(
    bad_trials$pt_cue[i],
    potential_switch$pt_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$pt_cue[i], bad_trials$pt_target[i],
    potential_switch$pt_cue[potential_switch$pt_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_pt_cue", "bad_pt_target", 
                           "good_pt_cue", "good_pt_target")

good_trials_small <- good_trials %>% 
  filter(!(pt_cue %in% switch_todo$good_pt_cue & type == "unrelated"))

new_good_trials <- data.frame(
  pt_cue = c(switch_todo$bad_pt_cue, switch_todo$good_pt_cue),
  pt_target = c(switch_todo$good_pt_target, switch_todo$bad_pt_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  pt_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$pt_cosine[row] <- cosine(as.matrix(t(pt_model[
    c(new_good_trials$pt_cue[row], new_good_trials$pt_target[row]) , ])))[2]
}

pt_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(pt_final[ , c("pt_cue", "pt_target")]))

# check cosines
tapply(pt_final$pt_cosine, pt_final$type, mean, na.rm = T)
tapply(pt_final$pt_cosine, pt_final$type, min, na.rm = T)
tapply(pt_final$pt_cosine, pt_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- pt_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(pt_target) %>% 
  filter(n != 2)

weird_trials <- pt_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(pt_target %in% target_table$pt_target)

# check for NA
sum(is.na(pt_final$pt_cue))
sum(is.na(pt_final$pt_target))
sum(grepl("^NA", pt_final$pt_cue))
sum(grepl("^NA", pt_final$pt_target))

# check rows
nrow(pt_final)
table(pt_final$type, pt_final$cue_type, pt_final$target_type)

pt_final$ok <- NULL

export(pt_final, "pt/pt_trials_final.csv")
```

## pt_br Brazilian Portuguese

```{r eval = F}
# original words
pt_br <- import("pt/pt_translate.csv")
pt_br$en_cue <- gsub("digusting", "disgusting", pt_br$en_cue)

# fix real words ----
pt_br_update <- import("pt/pt_br/pt_br_translated_final.xlsx") %>% 
  mutate(across(everything(), tolower))

# fix cue words ----
cues <- pt_br_update %>% filter(pt_cue_trans != "")
for (i in 1:nrow(cues)){
  pt_br$pt_cue[pt_br$pt_cue == cues$pt_cue[i] #original cue match
            & pt_br$en_cue == cues$en_cue[i]] <- #english match
    cues$pt_cue_trans[i] #new cue
}

targets <- pt_br_update %>% filter(pt_target_trans != "")
for (i in 1:nrow(targets)){
  pt_br$pt_target[pt_br$pt_target == targets$pt_target[i] #original target match
            & pt_br$en_target == targets$en_target[i]] <- #english match
    targets$pt_target_trans[i] #new target
}

# fix fake words ----
cues <- pt_br_update %>% filter(pt_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  pt_br$pt_fake_cue[pt_br$pt_fake_cue == cues$pt_fake_cue[i] #original cue match
            & pt_br$en_cue == cues$en_cue[i]] <- #english match
    cues$pt_fake_cue_trans[i] #new cue
}

targets <- pt_br_update %>% filter(pt_fake_target_trans != "")
for (i in 1:nrow(targets)){
  pt_br$pt_fake_target[pt_br$pt_fake_target == targets$pt_fake_target[i] #original target match
            & pt_br$en_target == targets$en_target[i]] <- #english match
    targets$pt_fake_target_trans[i] #new target
}

sum(duplicated(pt_br$pt_cue))
sum(duplicated(pt_br$pt_target))
sum(duplicated(pt_br$pt_fake_cue))
sum(duplicated(pt_br$pt_fake_target))

nrow(pt_br %>% filter(pt_cue == pt_target))

export(pt_br, "../matched_stimuli/pt_br_matched.csv", row.names = F)

# create possible trials ----
pt_br_trials <- pt_br[ , c("pt_cue", "pt_target")]
pt_br_trials$type <- "related"
pt_br_trials$cue_type <- "word"
pt_br_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
pt_br$en_cue <- tolower(pt_br$en_cue)
pt_br$en_target <- tolower(pt_br$en_target)
# match unrelated pairs as a start 
pt_br_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(pt_br_unrelated)){
  pt_br_unrelated$en_cue[i] <- pt_br$pt_cue[pt_br$en_cue == pt_br_unrelated$en_cue[i]]
  pt_br_unrelated$en_target[i] <- pt_br$pt_target[pt_br$en_target == pt_br_unrelated$en_target[i]]
}

pt_br_trials <- rbind(pt_br_trials,
                   pt_br_unrelated %>% select(-en_cosine) %>% 
                     rename("pt_cue" = "en_cue", 
                            "pt_target" = "en_target"), 
                   data.frame(pt_cue = pt_br$pt_fake_cue,
                              pt_target = pt_br$pt_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(pt_cue = pt_br$pt_cue[sample(1:1000,
                                                        1000)],
                              pt_target = pt_br$pt_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(pt_cue = pt_br$pt_fake_cue[sample(1:1000,
                                                        1000)],
                              pt_target = pt_br$pt_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(pt_br_trials[ , c("pt_cue", "pt_target")]))

# update with low cosines from random shuffle ----
# set up model
pt_br_model <- read.table("/Volumes/SPAML Backup/subs_vec/pt/subs.pt.1e6.txt", quote="\"")
pt_br_model <- na.omit(pt_br_model)
pt_br_model$V1 <- tolower(pt_br_model$V1)
pt_br_model <- pt_br_model[!duplicated(pt_br_model$V1), ]
rownames(pt_br_model) <- pt_br_model$V1
pt_br_model <- pt_br_model[ , -1]

pt_br_trials$pt_br_cosine <- NA

# get cosine
for (row in 1:nrow(pt_br_trials)){
  
  if(pt_br_trials$type[row] != "nonword") { 
    
    pt_br_trials$pt_br_cosine[row] <- cosine(as.matrix(t(pt_br_model[
    c(pt_br_trials$pt_cue[row], pt_br_trials$pt_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
pt_br_trials$ok <- TRUE
pt_br_trials$ok[pt_br_trials$type == "unrelated" & abs(pt_br_trials$pt_br_cosine) > .15] <- FALSE

good_trials <- pt_br_trials %>% filter(ok == TRUE)
bad_trials <- pt_br_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$pt_target <- sample(bad_trials$pt_target, 
                               size = length(bad_trials$pt_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$pt_br_cosine[row] <- cosine(as.matrix(t(pt_br_model[
    c(bad_trials$pt_cue[row], bad_trials$pt_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(pt_br_cosine < .15)))
bad_trials <- bad_trials %>% filter(pt_br_cosine >= .15)
nrow(bad_trials)
# ran section I ran multiple times 

whats_left <- cosine(as.matrix(t(pt_br_model[c(
  bad_trials$pt_target,
  unique(good_trials$pt_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$pt_target)){
  
  # find all words that could be paired with bad pt_target
  # as updated pt_cue
  potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$pt_target[i]] < .15] 
  
  # find all pairs of good pt_target that could
  # be paired with bad pt_cue
  potential_switch <- good_trials %>% filter(pt_cue %in% potential_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(pt_br_model[c(
    bad_trials$pt_cue[i],
    potential_switch$pt_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$pt_cue[i], bad_trials$pt_target[i],
    potential_switch$pt_cue[potential_switch$pt_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_pt_cue", "bad_pt_target", 
                           "good_pt_cue", "good_pt_target")

good_trials_small <- good_trials %>% 
  filter(!(pt_cue %in% switch_todo$good_pt_cue & type == "unrelated"))

new_good_trials <- data.frame(
  pt_cue = c(switch_todo$bad_pt_cue, switch_todo$good_pt_cue),
  pt_target = c(switch_todo$good_pt_target, switch_todo$bad_pt_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  pt_br_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$pt_br_cosine[row] <- cosine(as.matrix(t(pt_br_model[
    c(new_good_trials$pt_cue[row], new_good_trials$pt_target[row]) , ])))[2]
}

pt_br_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(pt_br_final[ , c("pt_cue", "pt_target")]))

# check cosines
tapply(pt_br_final$pt_br_cosine, pt_br_final$type, mean, na.rm = T)
tapply(pt_br_final$pt_br_cosine, pt_br_final$type, min, na.rm = T)
tapply(pt_br_final$pt_br_cosine, pt_br_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- pt_br_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(pt_target) %>% 
  filter(n != 2)

weird_trials <- pt_br_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 

# check for NA
sum(is.na(pt_br_final$pt_cue))
sum(is.na(pt_br_final$pt_target))
sum(grepl("^NA", pt_br_final$pt_cue))
sum(grepl("^NA", pt_br_final$pt_target))

# check rows
nrow(pt_br_final)
table(pt_br_final$type, pt_br_final$cue_type, pt_br_final$target_type)

pt_br_final$ok <- NULL

export(pt_br_final, "pt/pt_br/pt_br_trials_final.csv")
```

### pt Portuguese Match

```{r eval = F}
pt <- import("../matched_stimuli/pt_matched.csv")
pt_br <- import("../matched_stimuli/pt_br_matched.csv")

pt_together <- pt %>% 
  left_join(pt_br, by = c("en_cue" = "en_cue", 
                          "en_target" = "en_target"))

sum(is.na(pt_together$pt_cue.y))
sum(is.na(pt_together$pt_target.y))

sum(pt_together$pt_cue.x == pt_together$pt_cue.y)
sum(pt_together$pt_target.x == pt_together$pt_target.y)
```

## sr Serbian

```{r eval = F}
# original words
sr <- import("sr/sr_translate.csv")
sr$en_cue <- gsub("digusting", "disgusting", sr$en_cue)

# fix real words ----
sr_update <- import("sr/sr_translated_final.xlsx") %>% 
  mutate(across(everything(), tolower))

sr$sr_cue <- sr_update$FINAL_sr_cue
sr$sr_target <- sr_update$FINAL_sr_target
sr$sr_fake_cue <- sr_update$FINAL_sr_fake_cue
sr$sr_fake_target <- sr_update$FINAL_sr_fake_target
sr$en_cue <- sr_update$en_cue
sr$en_target <- sr_update$en_target
sr$en_cue <- gsub("digusting", "disgusting", sr$en_cue)

sum(duplicated(sr$sr_cue))
sum(duplicated(sr$sr_target))
sum(duplicated(sr$sr_fake_cue))
sum(duplicated(sr$sr_fake_target))

nrow(sr %>% filter(sr_cue == sr_target))

export(sr, "../matched_stimuli/sr_matched.csv", row.names = F)

# create possible trials ----
sr_trials <- sr[ , c("sr_cue", "sr_target")]
sr_trials$type <- "related"
sr_trials$cue_type <- "word"
sr_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
sr$en_cue <- tolower(sr$en_cue)
sr$en_target <- tolower(sr$en_target)
# match unrelated pairs as a start 
sr_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(sr_unrelated)){
  sr_unrelated$en_cue[i] <- sr$sr_cue[sr$en_cue == sr_unrelated$en_cue[i]]
  sr_unrelated$en_target[i] <- sr$sr_target[sr$en_target == sr_unrelated$en_target[i]]
}

sr_trials <- rbind(sr_trials,
                   sr_unrelated %>% select(-en_cosine) %>% 
                     rename("sr_cue" = "en_cue", 
                            "sr_target" = "en_target"), 
                   data.frame(sr_cue = sr$sr_fake_cue,
                              sr_target = sr$sr_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(sr_cue = sr$sr_cue[sample(1:1000,
                                                        1000)],
                              sr_target = sr$sr_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(sr_cue = sr$sr_fake_cue[sample(1:1000,
                                                        1000)],
                              sr_target = sr$sr_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(sr_trials[ , c("sr_cue", "sr_target")]))

# update with low cosines from random shuffle ----
# set up model
sr_model <- read.table("/Volumes/SPAML Backup/subs_vec/sr/subs.sr.1e6.txt", quote="\"")
sr_model <- na.omit(sr_model)
sr_model$V1 <- tolower(sr_model$V1)
sr_model <- sr_model[!duplicated(sr_model$V1), ]
rownames(sr_model) <- sr_model$V1
sr_model <- sr_model[ , -1]

sr_trials$sr_cosine <- NA

# get cosine
for (row in 1:nrow(sr_trials)){
  
  if(sr_trials$type[row] != "nonword") { 
    
    sr_trials$sr_cosine[row] <- cosine(as.matrix(t(sr_model[
    c(sr_trials$sr_cue[row], sr_trials$sr_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
sr_trials$ok <- TRUE
sr_trials$ok[sr_trials$type == "unrelated" & abs(sr_trials$sr_cosine) > .15] <- FALSE

good_trials <- sr_trials %>% filter(ok == TRUE)
bad_trials <- sr_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone
# literally I ran this until I got this worked out
bad_trials$sr_target <- sample(bad_trials$sr_target,
                               size = length(bad_trials$sr_target),
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$sr_cosine[row] <- cosine(as.matrix(t(sr_model[
    c(bad_trials$sr_cue[row], bad_trials$sr_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(sr_cosine < .15)))
bad_trials <- bad_trials %>% filter(sr_cosine >= .15)
nrow(bad_trials)
# this section I ran multiple times
# 
# whats_left <- cosine(as.matrix(t(sr_model[c(
#   bad_trials$sr_target,
#   unique(good_trials$sr_cue[good_trials$type == "unrelated"])) , ])))
# whats_left <- as.data.frame(whats_left)
# 
# switch_todo <- matrix(NA, nrow = nrow(bad_trials),
#                       ncol = 4)
# # find suggestions that the switch is ok 
# for (i in 1:length(bad_trials$sr_target)){
#   
#   # find all words that could be paired with bad sr_target
#   # as updated sr_cue
#   potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$sr_target[i]] < .15] 
#   
#   # find all pairs of good sr_target that could
#   # be paired with bad sr_cue
#   potential_switch <- good_trials %>% filter(sr_cue %in% potential_cues) %>% filter(type == "unrelated")
#   
#   # find switchables 
#   switches <- cosine(as.matrix(t(sr_model[c(
#     bad_trials$sr_cue[i],
#     potential_switch$sr_target), 
#   ])))
#   
#   new_target <- names(which.min(switches[1, ]))
#   
#   switch_todo[i , ] <- c(bad_trials$sr_cue[i], bad_trials$sr_target[i],
#     potential_switch$sr_cue[potential_switch$sr_target == new_target],
#     new_target)
# 
# }
# 
# switch_todo <- as.data.frame(switch_todo)
# colnames(switch_todo) <- c("bad_sr_cue", "bad_sr_target", 
#                            "good_sr_cue", "good_sr_target")
# 
# good_trials_small <- good_trials %>% 
#   filter(!(sr_cue %in% switch_todo$good_sr_cue & type == "unrelated"))
# 
# new_good_trials <- data.frame(
#   sr_cue = c(switch_todo$bad_sr_cue, switch_todo$good_sr_cue),
#   sr_target = c(switch_todo$good_sr_target, switch_todo$bad_sr_target),
#   type = rep("unrelated", nrow(switch_todo)*2),
#   cue_type = rep("word", nrow(switch_todo)*2),
#   target_type = rep("word", nrow(switch_todo)*2),
#   sr_cosine = rep(NA, nrow(switch_todo)*2),
#   ok = rep(FALSE, nrow(switch_todo)*2)
# )
# 
# for (row in 1:nrow(new_good_trials)){
#     new_good_trials$sr_cosine[row] <- cosine(as.matrix(t(sr_model[
#     c(new_good_trials$sr_cue[row], new_good_trials$sr_target[row]) , ])))[2]
# }
# 
# sr_final <- bind_rows(good_trials_small, new_good_trials)

# all values very high, likely unusable 
sr_final <- bind_rows(good_trials, bad_trials)
sum(duplicated(sr_final[ , c("sr_cue", "sr_target")]))

# check cosines
tapply(sr_final$sr_cosine, sr_final$type, mean, na.rm = T)
tapply(sr_final$sr_cosine, sr_final$type, min, na.rm = T)
tapply(sr_final$sr_cosine, sr_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- sr_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(sr_target) %>% 
  filter(n != 2)

weird_trials <- sr_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(sr_target %in% target_table$sr_target)

# check for NA
sum(is.na(sr_final$sr_cue))
sum(is.na(sr_final$sr_target))
sum(grepl("^NA", sr_final$sr_cue))
sum(grepl("^NA", sr_final$sr_target))

# check rows
nrow(sr_final)
table(sr_final$type, sr_final$cue_type, sr_final$target_type)

sr_final$ok <- NULL

export(sr_final, "sr/sr_trials_final.csv")
```

## es Spanish

```{r eval = F}
# original words
es <- import("es/es_translated_final.xlsx")
es$en_cue <- gsub("digusting", "disgusting", es$en_cue)
es <- es %>% 
  select(-Comments) %>% 
  rename(es_fake_target = es_fake_target_trans, 
         es_fake_cue = es_fake_cue_trans)

sum(duplicated(es$es_cue))
sum(duplicated(es$es_target))
sum(duplicated(es$es_fake_cue))
sum(duplicated(es$es_fake_target))

nrow(es %>% filter(es_cue == es_target))

export(es, "../matched_stimuli/es_matched.csv", row.names = F)

# create possible trials ----
es_trials <- es[ , c("es_cue", "es_target")]
es_trials$type <- "related"
es_trials$cue_type <- "word"
es_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
es$en_cue <- tolower(es$en_cue)
es$en_target <- tolower(es$en_target)
# match unrelated pairs as a start 
es_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(es_unrelated)){
  es_unrelated$en_cue[i] <- es$es_cue[es$en_cue == es_unrelated$en_cue[i]]
  es_unrelated$en_target[i] <- es$es_target[es$en_target == es_unrelated$en_target[i]]
}

es_trials <- rbind(es_trials,
                   es_unrelated %>% select(-en_cosine) %>% 
                     rename("es_cue" = "en_cue", 
                            "es_target" = "en_target"), 
                   data.frame(es_cue = es$es_fake_cue,
                              es_target = es$es_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(es_cue = es$es_cue[sample(1:1000,
                                                        1000)],
                              es_target = es$es_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(es_cue = es$es_fake_cue[sample(1:1000,
                                                        1000)],
                              es_target = es$es_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(es_trials[ , c("es_cue", "es_target")]))

# update with low cosines from random shuffle ----
# set up model
es_model <- read.table("/Volumes/SPAML Backup/subs_vec/es/subs.es.1e6.txt", quote="\"")
es_model <- na.omit(es_model)
es_model$V1 <- tolower(es_model$V1)
es_model <- es_model[!duplicated(es_model$V1), ]
rownames(es_model) <- es_model$V1
es_model <- es_model[ , -1]

es_trials$es_cosine <- NA

# get cosine
for (row in 1:nrow(es_trials)){
  
  if(es_trials$type[row] != "nonword") { 
    
    es_trials$es_cosine[row] <- cosine(as.matrix(t(es_model[
    c(es_trials$es_cue[row], es_trials$es_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
es_trials$ok <- TRUE
es_trials$ok[es_trials$type == "unrelated" & abs(es_trials$es_cosine) > .15] <- FALSE

good_trials <- es_trials %>% filter(ok == TRUE)
bad_trials <- es_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$es_target <- sample(bad_trials$es_target, 
                               size = length(bad_trials$es_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$es_cosine[row] <- cosine(as.matrix(t(es_model[
    c(bad_trials$es_cue[row], bad_trials$es_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(es_cosine < .15)))
bad_trials <- bad_trials %>% filter(es_cosine >= .15)
nrow(bad_trials)
# this section I ran multiple times 

whats_left <- cosine(as.matrix(t(es_model[c(
  bad_trials$es_target,
  unique(good_trials$es_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$es_target)){
  
  # find all words that could be paired with bad es_target
  # as updated es_cue
  potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$es_target[i]] < .15] 
  
  # find all pairs of good es_target that could
  # be paired with bad es_cue
  potential_switch <- good_trials %>% filter(es_cue %in% potential_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(es_model[c(
    bad_trials$es_cue[i],
    potential_switch$es_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$es_cue[i], bad_trials$es_target[i],
    potential_switch$es_cue[potential_switch$es_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_es_cue", "bad_es_target", 
                           "good_es_cue", "good_es_target")

good_trials_small <- good_trials %>% 
  filter(!(es_cue %in% switch_todo$good_es_cue & type == "unrelated"))

new_good_trials <- data.frame(
  es_cue = c(switch_todo$bad_es_cue, switch_todo$good_es_cue),
  es_target = c(switch_todo$good_es_target, switch_todo$bad_es_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  es_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$es_cosine[row] <- cosine(as.matrix(t(es_model[
    c(new_good_trials$es_cue[row], new_good_trials$es_target[row]) , ])))[2]
}

es_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(es_final[ , c("es_cue", "es_target")]))

# check cosines
tapply(es_final$es_cosine, es_final$type, mean, na.rm = T)
tapply(es_final$es_cosine, es_final$type, min, na.rm = T)
tapply(es_final$es_cosine, es_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- es_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(es_target) %>% 
  filter(n != 2)

weird_trials <- es_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(es_target %in% target_table$es_target)

# check for NA
sum(is.na(es_final$es_cue))
sum(is.na(es_final$es_target))
sum(grepl("^NA", es_final$es_cue))
sum(grepl("^NA", es_final$es_target))

# check rows
nrow(es_final)
table(es_final$type, es_final$cue_type, es_final$target_type)

es_final$ok <- NULL

export(es_final, "es/es_trials_final.csv")
```

## no Norweigan

```{r eval = F}
# original words
no <- import("no/no_translate.csv")
no$en_cue <- gsub("digusting", "disgusting", no$en_cue)

# fix real words ----
no_update <- import("no/no_translated_final.xlsx") %>% 
  mutate(across(everything(), tolower))

# fix cue words ----
cues <- no_update %>% filter(no_cue_trans != "")
for (i in 1:nrow(cues)){
  no$no_cue[no$no_cue == cues$no_cue[i] #original cue match
            & no$en_cue == cues$en_cue[i]] <- #english match
    cues$no_cue_trans[i] #new cue
}

targets <- no_update %>% filter(no_target_trans != "")
for (i in 1:nrow(targets)){
  no$no_target[no$no_target == targets$no_target[i] #original target match
            & no$en_target == targets$en_target[i]] <- #english match
    targets$no_target_trans[i] #new target
}

# fix fake words ----
cues <- no_update %>% filter(no_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  no$no_fake_cue[no$no_fake_cue == cues$no_fake_cue[i] #original cue match
            & no$en_cue == cues$en_cue[i]] <- #english match
    cues$no_fake_cue_trans[i] #new cue
}

targets <- no_update %>% filter(no_fake_target_trans != "")
for (i in 1:nrow(targets)){
  no$no_fake_target[no$no_fake_target == targets$no_fake_target[i] #original target match
            & no$en_target == targets$en_target[i]] <- #english match
    targets$no_fake_target_trans[i] #new target
}

sum(duplicated(no$no_cue))
sum(duplicated(no$no_target))
sum(duplicated(no$no_fake_cue))
sum(duplicated(no$no_fake_target))

nrow(no %>% filter(no_cue == no_target))

export(no, "../matched_stimuli/no_matched.csv", row.names = F)

# create possible trials ----
no_trials <- no[ , c("no_cue", "no_target")]
no_trials$type <- "related"
no_trials$cue_type <- "word"
no_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
no$en_cue <- tolower(no$en_cue)
no$en_target <- tolower(no$en_target)
# match unrelated pairs as a start 
no_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(no_unrelated)){
  no_unrelated$en_cue[i] <- no$no_cue[no$en_cue == no_unrelated$en_cue[i]]
  no_unrelated$en_target[i] <- no$no_target[no$en_target == no_unrelated$en_target[i]]
}

no_trials <- rbind(no_trials,
                   no_unrelated %>% select(-en_cosine) %>% 
                     rename("no_cue" = "en_cue", 
                            "no_target" = "en_target"), 
                   data.frame(no_cue = no$no_fake_cue,
                              no_target = no$no_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(no_cue = no$no_cue[sample(1:1000,
                                                        1000)],
                              no_target = no$no_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(no_cue = no$no_fake_cue[sample(1:1000,
                                                        1000)],
                              no_target = no$no_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(no_trials[ , c("no_cue", "no_target")]))

# update with low cosines from random shuffle ----
# set up model
no_model <- read.table("/Volumes/SPAML Backup/subs_vec/no/subs.no.1e6.txt", quote="\"")
no_model <- na.omit(no_model)
no_model$V1 <- tolower(no_model$V1)
no_model <- no_model[!duplicated(no_model$V1), ]
rownames(no_model) <- no_model$V1
no_model <- no_model[ , -1]

no_trials$no_cosine <- NA

# get cosine
for (row in 1:nrow(no_trials)){
  
  if(no_trials$type[row] != "nonword") { 
    
    no_trials$no_cosine[row] <- cosine(as.matrix(t(no_model[
    c(no_trials$no_cue[row], no_trials$no_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
no_trials$ok <- TRUE
no_trials$ok[no_trials$type == "unrelated" & abs(no_trials$no_cosine) > .15] <- FALSE

good_trials <- no_trials %>% filter(ok == TRUE)
bad_trials <- no_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$no_target <- sample(bad_trials$no_target, 
                               size = length(bad_trials$no_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$no_cosine[row] <- cosine(as.matrix(t(no_model[
    c(bad_trials$no_cue[row], bad_trials$no_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(no_cosine < .15)))
bad_trials <- bad_trials %>% filter(no_cosine >= .15)
nrow(bad_trials)
# this section I ran multiple times 

whats_left <- cosine(as.matrix(t(no_model[c(
  bad_trials$no_target,
  unique(good_trials$no_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$no_target)){
  
  # find all words that could be paired with bad no_target
  # as updated no_cue
  potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$no_target[i]] < .15] 
  
  # find all pairs of good no_target that could
  # be paired with bad no_cue
  potential_switch <- good_trials %>% filter(no_cue %in% potential_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(no_model[c(
    bad_trials$no_cue[i],
    potential_switch$no_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$no_cue[i], bad_trials$no_target[i],
    potential_switch$no_cue[potential_switch$no_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_no_cue", "bad_no_target", 
                           "good_no_cue", "good_no_target")

good_trials_small <- good_trials %>% 
  filter(!(no_cue %in% switch_todo$good_no_cue & type == "unrelated"))

new_good_trials <- data.frame(
  no_cue = c(switch_todo$bad_no_cue, switch_todo$good_no_cue),
  no_target = c(switch_todo$good_no_target, switch_todo$bad_no_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  no_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$no_cosine[row] <- cosine(as.matrix(t(no_model[
    c(new_good_trials$no_cue[row], new_good_trials$no_target[row]) , ])))[2]
}

no_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(no_final[ , c("no_cue", "no_target")]))

# check cosines
tapply(no_final$no_cosine, no_final$type, mean, na.rm = T)
tapply(no_final$no_cosine, no_final$type, min, na.rm = T)
tapply(no_final$no_cosine, no_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- no_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(no_target) %>% 
  filter(n != 2)

weird_trials <- no_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(no_target %in% target_table$no_target)

# check for NA
sum(is.na(no_final$no_cue))
sum(is.na(no_final$no_target))
sum(grepl("^NA", no_final$no_cue))
sum(grepl("^NA", no_final$no_target))

# check rows
nrow(no_final)
table(no_final$type, no_final$cue_type, no_final$target_type)

no_final$ok <- NULL

export(no_final, "no/no_trials_final.csv")
```

## it Italian 

```{r eval = F}
# original words
it <- import("it/it_translate.csv")
it$en_cue <- gsub("digusting", "disgusting", it$en_cue)

# fix real words ----
it_update <- import("it/it_translated_final.xlsx") %>% 
  mutate(across(everything(), tolower))

# fix cue words ----
cues <- it_update %>% filter(it_cue_trans != "")
for (i in 1:nrow(cues)){
  it$it_cue[it$it_cue == cues$it_cue[i] #original cue match
            & it$en_cue == cues$en_cue[i]] <- #english match
    cues$it_cue_trans[i] #new cue
}

targets <- it_update %>% filter(it_target_trans != "")
for (i in 1:nrow(targets)){
  it$it_target[it$it_target == targets$it_target[i] #original target match
            & it$en_target == targets$en_target[i]] <- #english match
    targets$it_target_trans[i] #new target
}

# fix fake words ----
cues <- it_update %>% filter(it_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  it$it_fake_cue[it$it_fake_cue == cues$it_fake_cue[i] #original cue match
            & it$en_cue == cues$en_cue[i]] <- #english match
    cues$it_fake_cue_trans[i] #new cue
}

targets <- it_update %>% filter(it_fake_target_trans != "")
for (i in 1:nrow(targets)){
  it$it_fake_target[it$it_fake_target == targets$it_fake_target[i] #original target match
            & it$en_target == targets$en_target[i]] <- #english match
    targets$it_fake_target_trans[i] #new target
}

sum(duplicated(it$it_cue))
sum(duplicated(it$it_target))
sum(duplicated(it$it_fake_cue))
sum(duplicated(it$it_fake_target))

nrow(it %>% filter(it_cue == it_target))

export(it,  "../matched_stimuli/it_matched.csv", row.names = F)

# create possible trials ----
it_trials <- it[ , c("it_cue", "it_target")]
it_trials$type <- "related"
it_trials$cue_type <- "word"
it_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
it$en_cue <- tolower(it$en_cue)
it$en_target <- tolower(it$en_target)
# match unrelated pairs as a start 
it_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(it_unrelated)){
  it_unrelated$en_cue[i] <- it$it_cue[it$en_cue == it_unrelated$en_cue[i]]
  it_unrelated$en_target[i] <- it$it_target[it$en_target == it_unrelated$en_target[i]]
}

it_trials <- rbind(it_trials,
                   it_unrelated %>% select(-en_cosine) %>% 
                     rename("it_cue" = "en_cue", 
                            "it_target" = "en_target"), 
                   data.frame(it_cue = it$it_fake_cue,
                              it_target = it$it_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(it_cue = it$it_cue[sample(1:1000,
                                                        1000)],
                              it_target = it$it_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(it_cue = it$it_fake_cue[sample(1:1000,
                                                        1000)],
                              it_target = it$it_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(it_trials[ , c("it_cue", "it_target")]))

# update with low cosines from random shuffle ----
# set up model
it_model <- read.table("/Volumes/SPAML Backup/subs_vec/it/subs.it.1e6.txt", quote="\"")
it_model <- na.omit(it_model)
it_model$V1 <- tolower(it_model$V1)
it_model <- it_model[!duplicated(it_model$V1), ]
rownames(it_model) <- it_model$V1
it_model <- it_model[ , -1]

it_trials$it_cosine <- NA

# get cosine
for (row in 1:nrow(it_trials)){
  
  if(it_trials$type[row] != "nonword") { 
    
    it_trials$it_cosine[row] <- cosine(as.matrix(t(it_model[
    c(it_trials$it_cue[row], it_trials$it_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
it_trials$ok <- TRUE
it_trials$ok[it_trials$type == "unrelated" & abs(it_trials$it_cosine) > .15] <- FALSE

good_trials <- it_trials %>% filter(ok == TRUE)
bad_trials <- it_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$it_target <- sample(bad_trials$it_target, 
                               size = length(bad_trials$it_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$it_cosine[row] <- cosine(as.matrix(t(it_model[
    c(bad_trials$it_cue[row], bad_trials$it_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(it_cosine < .15)))
bad_trials <- bad_trials %>% filter(it_cosine >= .15)
nrow(bad_trials)
# this section I ran multiple times 

whats_left <- cosine(as.matrix(t(it_model[c(
  bad_trials$it_target,
  unique(good_trials$it_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$it_target)){
  
  # find all words that could be paired with bad it_target
  # as updated it_cue
  pltrutial_cues <- rownames(whats_left)[whats_left[ , bad_trials$it_target[i]] < .15] 
  
  # find all pairs of good it_target that could
  # be paired with bad it_cue
  pltrutial_switch <- good_trials %>% filter(it_cue %in% pltrutial_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(it_model[c(
    bad_trials$it_cue[i],
    pltrutial_switch$it_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$it_cue[i], bad_trials$it_target[i],
    pltrutial_switch$it_cue[pltrutial_switch$it_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_it_cue", "bad_it_target", 
                           "good_it_cue", "good_it_target")

good_trials_small <- good_trials %>% 
  filter(!(it_cue %in% switch_todo$good_it_cue & type == "unrelated"))

new_good_trials <- data.frame(
  it_cue = c(switch_todo$bad_it_cue, switch_todo$good_it_cue),
  it_target = c(switch_todo$good_it_target, switch_todo$bad_it_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  it_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$it_cosine[row] <- cosine(as.matrix(t(it_model[
    c(new_good_trials$it_cue[row], new_good_trials$it_target[row]) , ])))[2]
}

it_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(it_final[ , c("it_cue", "it_target")]))

# check cosines
tapply(it_final$it_cosine, it_final$type, mean, na.rm = T)
tapply(it_final$it_cosine, it_final$type, min, na.rm = T)
tapply(it_final$it_cosine, it_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- it_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(it_target) %>% 
  filter(n != 2)

weird_trials <- it_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(it_target %in% target_table$it_target)

# check for NA
sum(is.na(it_final$it_cue))
sum(is.na(it_final$it_target))
sum(grepl("^NA", it_final$it_cue))
sum(grepl("^NA", it_final$it_target))

# check rows
nrow(it_final)
table(it_final$type, it_final$cue_type, it_final$target_type)

it_final$ok <- NULL

export(it_final, "it/it_trials_final.csv")
```

## ur Urdu

```{r eval = F}
# original words
ur <- import("ur/ur_translate.csv")
ur$en_cue <- gsub("digusting", "disgusting", ur$en_cue)

# fix real words ----
ur_update <- import("ur/ur_translate2 SPAML Apr 2022.xlsx") %>% 
  mutate(across(everything(), tolower))

# fix cue words ----
cues <- ur_update %>% filter(ur_cue_trans != "")
for (i in 1:nrow(cues)){
  ur$ur_cue[ur$ur_cue == cues$ur_cue[i] #original cue match
            & ur$en_cue == cues$en_cue[i]] <- #english match
    cues$ur_cue_trans[i] #new cue
}

targets <- ur_update %>% filter(ur_target_trans != "")
for (i in 1:nrow(targets)){
  ur$ur_target[ur$ur_target == targets$ur_target[i] #original target match
            & ur$en_target == targets$en_target[i]] <- #english match
    targets$ur_target_trans[i] #new target
}

# fix fake words ----
cues <- ur_update %>% filter(ur_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  ur$ur_fake_cue[ur$ur_fake_cue == cues$ur_fake_cue[i] #original cue match
            & ur$en_cue == cues$en_cue[i]] <- #english match
    cues$ur_fake_cue_trans[i] #new cue
}

targets <- ur_update %>% filter(ur_fake_target_trans != "")
for (i in 1:nrow(targets)){
  ur$ur_fake_target[ur$ur_fake_target == targets$ur_fake_target[i] #original target match
            & ur$en_target == targets$en_target[i]] <- #english match
    targets$ur_fake_target_trans[i] #new target
}

sum(duplicated(ur$ur_cue))
sum(duplicated(ur$ur_target))
sum(duplicated(ur$ur_fake_cue))
sum(duplicated(ur$ur_fake_target))

nrow(ur %>% filter(ur_cue == ur_target))

export(ur, "../matched_stimuli/ur_matched.csv", row.names = F)

# create possible trials ----
ur_trials <- ur[ , c("ur_cue", "ur_target")]
ur_trials$type <- "related"
ur_trials$cue_type <- "word"
ur_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
ur$en_cue <- tolower(ur$en_cue)
ur$en_target <- tolower(ur$en_target)
# match unrelated pairs as a start 
ur_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(ur_unrelated)){
  ur_unrelated$en_cue[i] <- ur$ur_cue[ur$en_cue == ur_unrelated$en_cue[i]]
  ur_unrelated$en_target[i] <- ur$ur_target[ur$en_target == ur_unrelated$en_target[i]]
}

ur_trials <- rbind(ur_trials,
                   ur_unrelated %>% select(-en_cosine) %>% 
                     rename("ur_cue" = "en_cue", 
                            "ur_target" = "en_target"), 
                   data.frame(ur_cue = ur$ur_fake_cue,
                              ur_target = ur$ur_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(ur_cue = ur$ur_cue[sample(1:1000,
                                                        1000)],
                              ur_target = ur$ur_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(ur_cue = ur$ur_fake_cue[sample(1:1000,
                                                        1000)],
                              ur_target = ur$ur_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(ur_trials[ , c("ur_cue", "ur_target")]))

# update with low cosines from random shuffle ----
# set up model
ur_model <- read.table("/Volumes/SPAML Backup/wiki_vec/ur/wiki.ur.1e6.txt", quote="\"")
ur_model <- na.omit(ur_model)
ur_model$V1 <- tolower(ur_model$V1)
ur_model <- ur_model[!duplicated(ur_model$V1), ]
rownames(ur_model) <- ur_model$V1
ur_model <- ur_model[ , -1]

ur_trials$ur_cosine <- NA

# get cosine
for (row in 1:nrow(ur_trials)){
  
  if(ur_trials$type[row] != "nonword") { 
    
    ur_trials$ur_cosine[row] <- cosine(as.matrix(t(ur_model[
    c(ur_trials$ur_cue[row], ur_trials$ur_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
ur_trials$ok <- TRUE
ur_trials$ok[ur_trials$type == "unrelated" & abs(ur_trials$ur_cosine) > .15] <- FALSE

good_trials <- ur_trials %>% filter(ok == TRUE)
bad_trials <- ur_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$ur_target <- sample(bad_trials$ur_target, 
                               size = length(bad_trials$ur_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$ur_cosine[row] <- cosine(as.matrix(t(ur_model[
    c(bad_trials$ur_cue[row], bad_trials$ur_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(ur_cosine < .15)))
bad_trials <- bad_trials %>% filter(ur_cosine >= .15)
nrow(bad_trials)
# this section I ran multiple times 

whats_left <- cosine(as.matrix(t(ur_model[c(
  bad_trials$ur_target,
  unique(good_trials$ur_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$ur_target)){
  
  # find all words that could be paired with bad ur_target
  # as updated ur_cue
  potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$ur_target[i]] < .15] 
  
  # find all pairs of good ur_target that could
  # be paired with bad ur_cue
  potential_switch <- good_trials %>% filter(ur_cue %in% potential_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(ur_model[c(
    bad_trials$ur_cue[i],
    potential_switch$ur_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$ur_cue[i], bad_trials$ur_target[i],
    potential_switch$ur_cue[potential_switch$ur_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_ur_cue", "bad_ur_target", 
                           "good_ur_cue", "good_ur_target")

good_trials_small <- good_trials %>% 
  filter(!(ur_cue %in% switch_todo$good_ur_cue & type == "unrelated"))

new_good_trials <- data.frame(
  ur_cue = c(switch_todo$bad_ur_cue, switch_todo$good_ur_cue),
  ur_target = c(switch_todo$good_ur_target, switch_todo$bad_ur_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  ur_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$ur_cosine[row] <- cosine(as.matrix(t(ur_model[
    c(new_good_trials$ur_cue[row], new_good_trials$ur_target[row]) , ])))[2]
}

ur_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(ur_final[ , c("ur_cue", "ur_target")]))

# check cosines
tapply(ur_final$ur_cosine, ur_final$type, mean, na.rm = T)
tapply(ur_final$ur_cosine, ur_final$type, min, na.rm = T)
tapply(ur_final$ur_cosine, ur_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- ur_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(ur_target) %>% 
  filter(n != 2)

weird_trials <- ur_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(ur_target %in% target_table$ur_target)

# drop extra
ur_final <- ur_final %>% 
  filter(!(ur_cue == "پرخطر" & ur_target == "لکھیں"))

# check for NA
sum(is.na(ur_final$ur_cue))
sum(is.na(ur_final$ur_target))
sum(grepl("^NA", ur_final$ur_cue))
sum(grepl("^NA", ur_final$ur_target))

# check rows
nrow(ur_final)
table(ur_final$type, ur_final$cue_type, ur_final$target_type)

ur_final$ok <- NULL

export(ur_final, "ur/ur_trials_final.csv")
```

## pl Polish

```{r eval = F}
# original words
pl <- import("pl/pl_translate.csv")
pl$en_cue <- gsub("digusting", "disgusting", pl$en_cue)

# fix real words ----
pl_update <- import("pl/pl_translated_final.xlsx") %>% 
  mutate(across(everything(), tolower))

# fix cue words ----
cues <- pl_update %>% filter(pl_cue_trans != "")
for (i in 1:nrow(cues)){
  pl$pl_cue[pl$pl_cue == cues$pl_cue[i] #original cue match
            & pl$en_cue == cues$en_cue[i]] <- #english match
    cues$pl_cue_trans[i] #new cue
}

targets <- pl_update %>% filter(pl_target_trans != "")
for (i in 1:nrow(targets)){
  pl$pl_target[pl$pl_target == targets$pl_target[i] #original target match
            & pl$en_target == targets$en_target[i]] <- #english match
    targets$pl_target_trans[i] #new target
}

# fix fake words ----
cues <- pl_update %>% filter(pl_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  pl$pl_fake_cue[pl$pl_fake_cue == cues$pl_fake_cue[i] #original cue match
            & pl$en_cue == cues$en_cue[i]] <- #english match
    cues$pl_fake_cue_trans[i] #new cue
}

targets <- pl_update %>% filter(pl_fake_target_trans != "")
for (i in 1:nrow(targets)){
  pl$pl_fake_target[pl$pl_fake_target == targets$pl_fake_target[i] #original target match
            & pl$en_target == targets$en_target[i]] <- #english match
    targets$pl_fake_target_trans[i] #new target
}

sum(duplicated(pl$pl_cue))
sum(duplicated(pl$pl_target))
sum(duplicated(pl$pl_fake_cue))
sum(duplicated(pl$pl_fake_target))

nrow(pl %>% filter(pl_cue == pl_target))

export(pl, "../matched_stimuli/pl_matched.csv", row.names = F)

# create plssible trials ----
pl_trials <- pl[ , c("pl_cue", "pl_target")]
pl_trials$type <- "related"
pl_trials$cue_type <- "word"
pl_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
pl$en_cue <- tolower(pl$en_cue)
pl$en_target <- tolower(pl$en_target)
# match unrelated pairs as a start 
pl_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(pl_unrelated)){
  pl_unrelated$en_cue[i] <- pl$pl_cue[pl$en_cue == pl_unrelated$en_cue[i]]
  pl_unrelated$en_target[i] <- pl$pl_target[pl$en_target == pl_unrelated$en_target[i]]
}

pl_trials <- rbind(pl_trials,
                   pl_unrelated %>% select(-en_cosine) %>% 
                     rename("pl_cue" = "en_cue", 
                            "pl_target" = "en_target"), 
                   data.frame(pl_cue = pl$pl_fake_cue,
                              pl_target = pl$pl_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(pl_cue = pl$pl_cue[sample(1:1000,
                                                        1000)],
                              pl_target = pl$pl_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(pl_cue = pl$pl_fake_cue[sample(1:1000,
                                                        1000)],
                              pl_target = pl$pl_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(pl_trials[ , c("pl_cue", "pl_target")]))

# update with low cosines from random shuffle ----
# set up model
pl_model <- read.table("/Volumes/SPAML Backup/subs_vec/pl/subs.pl.1e6.txt", quote="\"")
pl_model <- na.omit(pl_model)
pl_model$V1 <- tolower(pl_model$V1)
pl_model <- pl_model[!duplicated(pl_model$V1), ]
rownames(pl_model) <- pl_model$V1
pl_model <- pl_model[ , -1]

pl_trials$pl_cosine <- NA

# get cosine
for (row in 1:nrow(pl_trials)){
  
  if(pl_trials$type[row] != "nonword") { 
    
    pl_trials$pl_cosine[row] <- cosine(as.matrix(t(pl_model[
    c(pl_trials$pl_cue[row], pl_trials$pl_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
pl_trials$ok <- TRUE
pl_trials$ok[pl_trials$type == "unrelated" & abs(pl_trials$pl_cosine) > .15] <- FALSE

good_trials <- pl_trials %>% filter(ok == TRUE)
bad_trials <- pl_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$pl_target <- sample(bad_trials$pl_target, 
                               size = length(bad_trials$pl_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$pl_cosine[row] <- cosine(as.matrix(t(pl_model[
    c(bad_trials$pl_cue[row], bad_trials$pl_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(pl_cosine < .15)))
bad_trials <- bad_trials %>% filter(pl_cosine >= .15)
nrow(bad_trials)
# this section I ran multiple times 

whats_left <- cosine(as.matrix(t(pl_model[c(
  bad_trials$pl_target,
  unique(good_trials$pl_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$pl_target)){
  
  # find all words that could be paired with bad pl_target
  # as updated pl_cue
  pltrutial_cues <- rownames(whats_left)[whats_left[ , bad_trials$pl_target[i]] < .15] 
  
  # find all pairs of good pl_target that could
  # be paired with bad pl_cue
  pltrutial_switch <- good_trials %>% filter(pl_cue %in% pltrutial_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(pl_model[c(
    bad_trials$pl_cue[i],
    pltrutial_switch$pl_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$pl_cue[i], bad_trials$pl_target[i],
    pltrutial_switch$pl_cue[pltrutial_switch$pl_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_pl_cue", "bad_pl_target", 
                           "good_pl_cue", "good_pl_target")

good_trials_small <- good_trials %>% 
  filter(!(pl_cue %in% switch_todo$good_pl_cue & type == "unrelated"))

new_good_trials <- data.frame(
  pl_cue = c(switch_todo$bad_pl_cue, switch_todo$good_pl_cue),
  pl_target = c(switch_todo$good_pl_target, switch_todo$bad_pl_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  pl_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$pl_cosine[row] <- cosine(as.matrix(t(pl_model[
    c(new_good_trials$pl_cue[row], new_good_trials$pl_target[row]) , ])))[2]
}

pl_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(pl_final[ , c("pl_cue", "pl_target")]))

# check cosines
tapply(pl_final$pl_cosine, pl_final$type, mean, na.rm = T)
tapply(pl_final$pl_cosine, pl_final$type, min, na.rm = T)
tapply(pl_final$pl_cosine, pl_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- pl_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(pl_target) %>% 
  filter(n != 2)

weird_trials <- pl_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(pl_target %in% target_table$pl_target)

# check for NA
sum(is.na(pl_final$pl_cue))
sum(is.na(pl_final$pl_target))
sum(grepl("^NA", pl_final$pl_cue))
sum(grepl("^NA", pl_final$pl_target))

# check rows
nrow(pl_final)
table(pl_final$type, pl_final$cue_type, pl_final$target_type)

pl_final$ok <- NULL

export(pl_final, "pl/pl_trials_final.csv")
```

## ro Romanian 

```{r eval = F}
# fix real words ----
ro_update <- import("ro/ro_translated_final.xlsx") %>% 
  mutate(across(everything(), tolower))

ro <- ro_update %>% 
  select(ro_cue_trans, ro_target_trans, 
         ro_fake_cue_update2, ro_fake_target_update2, 
         en_cue, en_target) %>% 
  rename(ro_cue = ro_cue_trans, 
         ro_target = ro_target_trans, 
         ro_fake_cue = ro_fake_cue_update2, 
         ro_fake_target = ro_fake_target_update2)

sum(duplicated(ro$ro_cue))
sum(duplicated(ro$ro_target))
sum(duplicated(ro$ro_fake_cue))
sum(duplicated(ro$ro_fake_target))

nrow(ro %>% filter(ro_cue == ro_target))

export(ro, "../matched_stimuli/ro_matched.csv", row.names = F)

# create rossible trials ----
ro_trials <- ro[ , c("ro_cue", "ro_target")]
ro_trials$type <- "related"
ro_trials$cue_type <- "word"
ro_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
ro$en_cue <- tolower(ro$en_cue)
ro$en_target <- tolower(ro$en_target)
# match unrelated pairs as a start 
ro_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(ro_unrelated)){
  ro_unrelated$en_cue[i] <- ro$ro_cue[ro$en_cue == ro_unrelated$en_cue[i]]
  ro_unrelated$en_target[i] <- ro$ro_target[ro$en_target == ro_unrelated$en_target[i]]
}

ro_trials <- rbind(ro_trials,
                   ro_unrelated %>% select(-en_cosine) %>% 
                     rename("ro_cue" = "en_cue", 
                            "ro_target" = "en_target"), 
                   data.frame(ro_cue = ro$ro_fake_cue,
                              ro_target = ro$ro_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(ro_cue = ro$ro_cue[sample(1:1000,
                                                        1000)],
                              ro_target = ro$ro_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(ro_cue = ro$ro_fake_cue[sample(1:1000,
                                                        1000)],
                              ro_target = ro$ro_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(ro_trials[ , c("ro_cue", "ro_target")]))

# update with low cosines from random shuffle ----
# set up model
ro_model <- read.table("/Volumes/SPAML Backup/subs_vec/ro/subs.ro.1e6.txt", quote="\"")
ro_model <- na.omit(ro_model)
ro_model$V1 <- tolower(ro_model$V1)
ro_model <- ro_model[!duplicated(ro_model$V1), ]
rownames(ro_model) <- ro_model$V1
ro_model <- ro_model[ , -1]

ro_trials$ro_cosine <- NA

# get cosine
for (row in 1:nrow(ro_trials)){
  
  if(ro_trials$type[row] != "nonword") { 
    
    ro_trials$ro_cosine[row] <- cosine(as.matrix(t(ro_model[
    c(ro_trials$ro_cue[row], ro_trials$ro_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
ro_trials$ok <- TRUE
ro_trials$ok[ro_trials$type == "unrelated" & abs(ro_trials$ro_cosine) > .15] <- FALSE

good_trials <- ro_trials %>% filter(ok == TRUE)
bad_trials <- ro_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$ro_target <- sample(bad_trials$ro_target, 
                               size = length(bad_trials$ro_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$ro_cosine[row] <- cosine(as.matrix(t(ro_model[
    c(bad_trials$ro_cue[row], bad_trials$ro_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(ro_cosine < .15)))
bad_trials <- bad_trials %>% filter(ro_cosine >= .15)
nrow(bad_trials)
# this section I ran multiple times 

whats_left <- cosine(as.matrix(t(ro_model[c(
  bad_trials$ro_target,
  unique(good_trials$ro_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$ro_target)){
  
  # find all words that could be paired with bad ro_target
  # as updated ro_cue
  rotrutial_cues <- rownames(whats_left)[whats_left[ , bad_trials$ro_target[i]] < .15] 
  
  # find all pairs of good ro_target that could
  # be paired with bad ro_cue
  rotrutial_switch <- good_trials %>% filter(ro_cue %in% rotrutial_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(ro_model[c(
    bad_trials$ro_cue[i],
    rotrutial_switch$ro_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$ro_cue[i], bad_trials$ro_target[i],
    rotrutial_switch$ro_cue[rotrutial_switch$ro_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_ro_cue", "bad_ro_target", 
                           "good_ro_cue", "good_ro_target")

good_trials_small <- good_trials %>% 
  filter(!(ro_cue %in% switch_todo$good_ro_cue & type == "unrelated"))

new_good_trials <- data.frame(
  ro_cue = c(switch_todo$bad_ro_cue, switch_todo$good_ro_cue),
  ro_target = c(switch_todo$good_ro_target, switch_todo$bad_ro_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  ro_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$ro_cosine[row] <- cosine(as.matrix(t(ro_model[
    c(new_good_trials$ro_cue[row], new_good_trials$ro_target[row]) , ])))[2]
}

ro_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(ro_final[ , c("ro_cue", "ro_target")]))

# check cosines
tapply(ro_final$ro_cosine, ro_final$type, mean, na.rm = T)
tapply(ro_final$ro_cosine, ro_final$type, min, na.rm = T)
tapply(ro_final$ro_cosine, ro_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- ro_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(ro_target) %>% 
  filter(n != 2)

weird_trials <- ro_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(ro_target %in% target_table$ro_target)

# add missing one
ro_final <- rbind(ro_final, 
                      c("permite", "roșie", "unrelated", "word", "word", NA, NA))

# check for NA
sum(is.na(ro_final$ro_cue))
sum(is.na(ro_final$ro_target))
sum(grepl("^NA", ro_final$ro_cue))
sum(grepl("^NA", ro_final$ro_target))

# check rows
nrow(ro_final)
table(ro_final$type, ro_final$cue_type, ro_final$target_type)

ro_final$ok <- NULL

export(ro_final, "ro/ro_trials_final.csv")
```

## nl Dutch

```{r eval = F}
# original words
nl <- import("nl/nl_translate.csv")
nl$en_cue <- gsub("digusting", "disgusting", nl$en_cue)

# fix real words ----
nl_update <- import("nl/nl_translated_final.xlsx") %>% 
  mutate(across(everything(), tolower))

# fix cue words ----
cues <- nl_update %>% filter(nl_cue_trans != "")
for (i in 1:nrow(cues)){
  nl$nl_cue[nl$nl_cue == cues$nl_cue[i] #original cue match
            & nl$en_cue == cues$en_cue[i]] <- #english match
    cues$nl_cue_trans[i] #new cue
}

targets <- nl_update %>% filter(nl_target_trans != "")
for (i in 1:nrow(targets)){
  nl$nl_target[nl$nl_target == targets$nl_target[i] #original target match
            & nl$en_target == targets$en_target[i]] <- #english match
    targets$nl_target_trans[i] #new target
}

# fix fake words ----
cues <- nl_update %>% filter(nl_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  nl$nl_fake_cue[nl$nl_fake_cue == cues$nl_fake_cue[i] #original cue match
            & nl$en_cue == cues$en_cue[i]] <- #english match
    cues$nl_fake_cue_trans[i] #new cue
}

targets <- nl_update %>% filter(nl_fake_target_trans != "")
for (i in 1:nrow(targets)){
  nl$nl_fake_target[nl$nl_fake_target == targets$nl_fake_target[i] #original target match
            & nl$en_target == targets$en_target[i]] <- #english match
    targets$nl_fake_target_trans[i] #new target
}

sum(duplicated(nl$nl_cue))
sum(duplicated(nl$nl_target))
sum(duplicated(nl$nl_fake_cue))
sum(duplicated(nl$nl_fake_target))

nrow(nl %>% filter(nl_cue == nl_target))

export(nl, "../matched_stimuli/nl_matched.csv", row.names = F)

# create rossible trials ----
nl_trials <- nl[ , c("nl_cue", "nl_target")]
nl_trials$type <- "related"
nl_trials$cue_type <- "word"
nl_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
nl$en_cue <- tolower(nl$en_cue)
nl$en_target <- tolower(nl$en_target)
# match unrelated pairs as a start 
nl_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(nl_unrelated)){
  nl_unrelated$en_cue[i] <- nl$nl_cue[nl$en_cue == nl_unrelated$en_cue[i]]
  nl_unrelated$en_target[i] <- nl$nl_target[nl$en_target == nl_unrelated$en_target[i]]
}

nl_trials <- rbind(nl_trials,
                   nl_unrelated %>% select(-en_cosine) %>% 
                     rename("nl_cue" = "en_cue", 
                            "nl_target" = "en_target"), 
                   data.frame(nl_cue = nl$nl_fake_cue,
                              nl_target = nl$nl_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(nl_cue = nl$nl_cue[sample(1:1000,
                                                        1000)],
                              nl_target = nl$nl_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(nl_cue = nl$nl_fake_cue[sample(1:1000,
                                                        1000)],
                              nl_target = nl$nl_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(nl_trials[ , c("nl_cue", "nl_target")]))

# update with low cosines from random shuffle ----
# set up model
nl_model <- read.table("/Volumes/SPAML Backup/subs_vec/nl/subs.nl.1e6.txt", quote="\"")
nl_model <- na.omit(nl_model)
nl_model$V1 <- tolower(nl_model$V1)
nl_model <- nl_model[!duplicated(nl_model$V1), ]
rownames(nl_model) <- nl_model$V1
nl_model <- nl_model[ , -1]

nl_trials$nl_cosine <- NA

# get cosine
for (row in 1:nrow(nl_trials)){
  
  if(nl_trials$type[row] != "nonword") { 
    
    nl_trials$nl_cosine[row] <- cosine(as.matrix(t(nl_model[
    c(nl_trials$nl_cue[row], nl_trials$nl_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
nl_trials$ok <- TRUE
nl_trials$ok[nl_trials$type == "unrelated" & abs(nl_trials$nl_cosine) > .15] <- FALSE

good_trials <- nl_trials %>% filter(ok == TRUE)
bad_trials <- nl_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$nl_target <- sample(bad_trials$nl_target, 
                               size = length(bad_trials$nl_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$nl_cosine[row] <- cosine(as.matrix(t(nl_model[
    c(bad_trials$nl_cue[row], bad_trials$nl_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(nl_cosine < .15)))
bad_trials <- bad_trials %>% filter(nl_cosine >= .15)
nrow(bad_trials)
# this section I ran multiple times 

whats_left <- cosine(as.matrix(t(nl_model[c(
  bad_trials$nl_target,
  unique(good_trials$nl_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$nl_target)){
  
  # find all words that could be paired with bad nl_target
  # as updated nl_cue
  rotrutial_cues <- rownames(whats_left)[whats_left[ , bad_trials$nl_target[i]] < .15] 
  
  # find all pairs of good nl_target that could
  # be paired with bad nl_cue
  rotrutial_switch <- good_trials %>% filter(nl_cue %in% rotrutial_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(nl_model[c(
    bad_trials$nl_cue[i],
    rotrutial_switch$nl_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$nl_cue[i], bad_trials$nl_target[i],
    rotrutial_switch$nl_cue[rotrutial_switch$nl_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_nl_cue", "bad_nl_target", 
                           "good_nl_cue", "good_nl_target")

good_trials_small <- good_trials %>% 
  filter(!(nl_cue %in% switch_todo$good_nl_cue & type == "unrelated"))

new_good_trials <- data.frame(
  nl_cue = c(switch_todo$bad_nl_cue, switch_todo$good_nl_cue),
  nl_target = c(switch_todo$good_nl_target, switch_todo$bad_nl_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  nl_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$nl_cosine[row] <- cosine(as.matrix(t(nl_model[
    c(new_good_trials$nl_cue[row], new_good_trials$nl_target[row]) , ])))[2]
}

nl_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(nl_final[ , c("nl_cue", "nl_target")]))

# check cosines
tapply(nl_final$nl_cosine, nl_final$type, mean, na.rm = T)
tapply(nl_final$nl_cosine, nl_final$type, min, na.rm = T)
tapply(nl_final$nl_cosine, nl_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- nl_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(nl_target) %>% 
  filter(n != 2)

weird_trials <- nl_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(nl_target %in% target_table$nl_target)

# check for NA
sum(is.na(nl_final$nl_cue))
sum(is.na(nl_final$nl_target))
sum(grepl("^NA", nl_final$nl_cue))
sum(grepl("^NA", nl_final$nl_target))

# check rows
nrow(nl_final)
table(nl_final$type, nl_final$cue_type, nl_final$target_type)

nl_final$ok <- NULL

export(nl_final, "nl/nl_trials_final.csv")
```

## sk Slovak

```{r eval = F}
# original words
sk <- import("sk/sk_translate.csv")
sk$en_cue <- gsub("digusting", "disgusting", sk$en_cue)

# fix real words ----
sk_update <- import("sk/sk_translated_final.xlsx") %>% 
  mutate(across(everything(), tolower))

# fix cue words ----
cues <- sk_update %>% filter(sk_cue_trans != "")
for (i in 1:nrow(cues)){
  sk$sk_cue[sk$sk_cue == cues$sk_cue[i] #original cue match
            & sk$en_cue == cues$en_cue[i]] <- #english match
    cues$sk_cue_trans[i] #new cue
}

targets <- sk_update %>% filter(sk_target_trans != "")
for (i in 1:nrow(targets)){
  sk$sk_target[sk$sk_target == targets$sk_target[i] #original target match
            & sk$en_target == targets$en_target[i]] <- #english match
    targets$sk_target_trans[i] #new target
}

# fix fake words ----
cues <- sk_update %>% filter(sk_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  sk$sk_fake_cue[sk$sk_fake_cue == cues$sk_fake_cue[i] #original cue match
            & sk$en_cue == cues$en_cue[i]] <- #english match
    cues$sk_fake_cue_trans[i] #new cue
}

targets <- sk_update %>% filter(sk_fake_target_trans != "")
for (i in 1:nrow(targets)){
  sk$sk_fake_target[sk$sk_fake_target == targets$sk_fake_target[i] #original target match
            & sk$en_target == targets$en_target[i]] <- #english match
    targets$sk_fake_target_trans[i] #new target
}

# this one is being dumb
sk$sk_target[sk$en_target == "FALSE"] <- "nepravdivý"

sum(duplicated(sk$sk_cue))
sum(duplicated(sk$sk_target))
sum(duplicated(sk$sk_fake_cue))
sum(duplicated(sk$sk_fake_target))

nrow(sk %>% filter(sk_cue == sk_target))

export(sk, "../matched_stimuli/sk_matched.csv", row.names = F)

# create possible trials ----
sk_trials <- sk[ , c("sk_cue", "sk_target")]
sk_trials$type <- "related"
sk_trials$cue_type <- "word"
sk_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
sk$en_cue <- tolower(sk$en_cue)
sk$en_target <- tolower(sk$en_target)
# match unrelated pairs as a start 
sk_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(sk_unrelated)){
  sk_unrelated$en_cue[i] <- sk$sk_cue[sk$en_cue == sk_unrelated$en_cue[i]]
  sk_unrelated$en_target[i] <- sk$sk_target[sk$en_target == sk_unrelated$en_target[i]]
}

sk_trials <- rbind(sk_trials,
                   sk_unrelated %>% select(-en_cosine) %>% 
                     rename("sk_cue" = "en_cue", 
                            "sk_target" = "en_target"), 
                   data.frame(sk_cue = sk$sk_fake_cue,
                              sk_target = sk$sk_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(sk_cue = sk$sk_cue[sample(1:1000,
                                                        1000)],
                              sk_target = sk$sk_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(sk_cue = sk$sk_fake_cue[sample(1:1000,
                                                        1000)],
                              sk_target = sk$sk_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(sk_trials[ , c("sk_cue", "sk_target")]))

# update with low cosines from random shuffle ----
# set up model
sk_model <- read.table("/Volumes/SPAML Backup/subs_vec/sk/subs.sk.1e6.txt", quote="\"")
sk_model <- na.omit(sk_model)
sk_model$V1 <- tolower(sk_model$V1)
sk_model <- sk_model[!duplicated(sk_model$V1), ]
rownames(sk_model) <- sk_model$V1
sk_model <- sk_model[ , -1]

sk_trials$sk_cosine <- NA

# get cosine
for (row in 1:nrow(sk_trials)){
  
  if(sk_trials$type[row] != "nonword") { 
    
    sk_trials$sk_cosine[row] <- cosine(as.matrix(t(sk_model[
    c(sk_trials$sk_cue[row], sk_trials$sk_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
sk_trials$ok <- TRUE
sk_trials$ok[sk_trials$type == "unrelated" & abs(sk_trials$sk_cosine) > .15] <- FALSE

good_trials <- sk_trials %>% filter(ok == TRUE)
bad_trials <- sk_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$sk_target <- sample(bad_trials$sk_target, 
                               size = length(bad_trials$sk_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$sk_cosine[row] <- cosine(as.matrix(t(sk_model[
    c(bad_trials$sk_cue[row], bad_trials$sk_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(sk_cosine < .15)))
bad_trials <- bad_trials %>% filter(sk_cosine >= .15)
nrow(bad_trials)
# this section I ran multiple times 

whats_left <- cosine(as.matrix(t(sk_model[c(
  bad_trials$sk_target,
  unique(good_trials$sk_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$sk_target)){
  
  # find all words that could be paired with bad sk_target
  # as updated sk_cue
  rotrutial_cues <- rownames(whats_left)[whats_left[ , bad_trials$sk_target[i]] < .15] 
  
  # find all pairs of good sk_target that could
  # be paired with bad sk_cue
  rotrutial_switch <- good_trials %>% filter(sk_cue %in% rotrutial_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(sk_model[c(
    bad_trials$sk_cue[i],
    rotrutial_switch$sk_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$sk_cue[i], bad_trials$sk_target[i],
    rotrutial_switch$sk_cue[rotrutial_switch$sk_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_sk_cue", "bad_sk_target", 
                           "good_sk_cue", "good_sk_target")

good_trials_small <- good_trials %>% 
  filter(!(sk_cue %in% switch_todo$good_sk_cue & type == "unrelated"))

new_good_trials <- data.frame(
  sk_cue = c(switch_todo$bad_sk_cue, switch_todo$good_sk_cue),
  sk_target = c(switch_todo$good_sk_target, switch_todo$bad_sk_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  sk_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$sk_cosine[row] <- cosine(as.matrix(t(sk_model[
    c(new_good_trials$sk_cue[row], new_good_trials$sk_target[row]) , ])))[2]
}

sk_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(sk_final[ , c("sk_cue", "sk_target")]))

# check cosines
tapply(sk_final$sk_cosine, sk_final$type, mean, na.rm = T)
tapply(sk_final$sk_cosine, sk_final$type, min, na.rm = T)
tapply(sk_final$sk_cosine, sk_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- sk_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(sk_target) %>% 
  filter(n != 2)

weird_trials <- sk_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(sk_target %in% target_table$sk_target)

# check for NA
sum(is.na(sk_final$sk_cue))
sum(is.na(sk_final$sk_target))
sum(grepl("^NA", sk_final$sk_cue))
sum(grepl("^NA", sk_final$sk_target))

# check rows
nrow(sk_final)
table(sk_final$type, sk_final$cue_type, sk_final$target_type)

sk_final$ok <- NULL

export(sk_final, "sk/sk_trials_final.csv")
```