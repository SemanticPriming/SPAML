---
title: "Finalize Stimuli"
author: "Erin M. Buchanan"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This document takes in the translations for each of the finished languages, updates the stimuli so they are consistent across languages, and creates the trials for each language. 

## Libraries

```{r}
library(rio)
library(stringi)
library(lsa)
library(dplyr)
# library(quanteda)
# library(sylly)
# library(tidytext)
# library(tidyr)
# library(stringr)
# library(stringdist)
```

Note: all models were downloaded from subs2vec github and stored on a separate drive, as they are very large. Also, this document is in the order that we added languages, not alphabetical like the other documents.

## en English

For English, we need to correct:
  
  - The fake trials that are not appropriate (fixed)
  - The unrelated trials in ensure a low cosine 
  
```{r eval = F}
# original words
en <- import("en/en_translate.csv")

# fix fake words ----
en_update <- import("en/en_translate_checked.xlsx")
cue_fix <- 
  bind_rows(
    (en_update %>% 
      filter(cue_vowel == "no") %>%
      select(en_cue, en_fake_cue)),
    (en_update %>% 
      filter(en_update$cue_pronounce == "no") %>% 
      select(en_cue, en_fake_cue)), 
    (en_update %>% 
       filter(cue_real == "yes") %>% 
       select(en_cue, en_fake_cue))
  ) %>% unique()

target_fix <- 
  bind_rows(
    (en_update %>% 
      filter(target_vowel == "no") %>%
      select(en_target, en_fake_target)),
    (en_update %>% 
      filter(en_update$target_pronounce == "no") %>% 
      select(en_target, en_fake_target)), 
    (en_update %>% 
       filter(target_real == "yes") %>% 
       select(en_target, en_fake_target))
  ) %>% unique()

# export(bind_rows(cue_fix, target_fix), "en/en_tofix.csv")
en_update <- import("en/en_tofix_fixed.csv")

cues <- en_update %>% filter(en_fake_cue != "")
for (i in 1:nrow(cues)){
  en$en_fake_cue[en$en_fake_cue == cues$en_fake_cue[i]
                 & en$en_cue == cues$en_cue[i]] <- cues$fixed[i]
}

targets <- en_update %>% filter(en_fake_target != "")
for (i in 1:nrow(targets)){
  en$en_fake_target[en$en_fake_target == targets$en_fake_target[i]
                    & en$en_target == targets$en_target[i]] <- targets$fixed[i]
}

sum(duplicated(en$en_cue))
sum(duplicated(en$en_target))
sum(duplicated(en$en_fake_cue))
sum(duplicated(en$en_fake_target))
sum(en$en_cue == en$en_target)

export(en, "../matched_stimuli/en_matched.csv", row.names = F)

# create possible trials ----
en_trials <- en[ , c("en_cue", "en_target")]
en_trials$type <- "related"
en_trials$cue_type <- "word"
en_trials$target_type <- "word"

en_trials <- rbind(en_trials,
                   data.frame(en_cue = ru$en_cue,
                              en_target = ru$en_target[sample(1:1000,
                                                              1000)],
                              type = "unrelated",
                              cue_type = "word",
                              target_type = "word"),
                   data.frame(en_cue = ru$en_fake_cue,
                              en_target = ru$en_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(en_cue = ru$en_cue[sample(1:1000,
                                                        1000)],
                              en_target = ru$en_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(en_cue = ru$en_fake_cue[sample(1:1000,
                                                        1000)],
                              en_target = ru$en_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(en_trials[ , c("en_cue", "en_target")]))

# update with low cosines from random shuffle ----
# set up model
en_model <- read.table("/Volumes/SPAML Backup/subs_vec/en/subs.en.1e6.txt", quote="\"")
en_model <- na.omit(en_model)
en_model$V1 <- tolower(en_model$V1)
en_model <- en_model[!duplicated(en_model$V1), ]
rownames(en_model) <- en_model$V1
en_model <- en_model[ , -1]

en_trials$en_cosine <- NA

# get cosine
for (row in 1:nrow(en_trials)){
  
  if(en_trials$type[row] != "nonword") { 
    
    en_trials$en_cosine[row] <- cosine(as.matrix(t(en_model[
    c(en_trials$en_cue[row], en_trials$en_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
en_trials$ok <- TRUE
en_trials$ok[en_trials$type == "unrelated" & abs(en_trials$en_cosine) > .15] <- FALSE

good_trials <- en_trials %>% filter(ok == TRUE)
bad_trials <- en_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I evened out 
bad_trials$en_target <- sample(bad_trials$en_target, 
                               size = length(bad_trials$en_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$en_cosine[row] <- cosine(as.matrix(t(en_model[
    c(bad_trials$en_cue[row], bad_trials$en_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(en_cosine < .15)))
bad_trials <- bad_trials %>% filter(en_cosine >= .15)
# end section I ran multiple times 

whats_left <- cosine(as.matrix(t(en_model[c(
  bad_trials$en_target,
  unique(good_trials$en_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$en_target)){
  
  # find all words that could be paired with bad en_target
  # as updated en_cue
  potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$en_target[i]] < .15] 
  
  # find all pairs of good en_target that could
  # be paired with bad en_cue
  potential_switch <- good_trials %>% filter(en_cue %in% potential_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(en_model[c(
    bad_trials$en_cue[i],
    potential_switch$en_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$en_cue[i], bad_trials$en_target[i],
    potential_switch$en_cue[potential_switch$en_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_en_cue", "bad_en_target", 
                           "good_en_cue", "good_en_target")

good_trials_small <- good_trials %>% 
  filter(!(en_cue %in% switch_todo$good_en_cue & type == "unrelated"))

new_good_trials <- data.frame(
  en_cue = c(switch_todo$bad_en_cue, switch_todo$good_en_cue),
  en_target = c(switch_todo$good_en_target, switch_todo$bad_en_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  en_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$en_cosine[row] <- cosine(as.matrix(t(en_model[
    c(new_good_trials$en_cue[row], new_good_trials$en_target[row]) , ])))[2]
}

en_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(en_final[ , c("en_cue", "en_target")]))


tapply(en_final$en_cosine, en_final$type, mean, na.rm = T)
tapply(en_final$en_cosine, en_final$type, min, na.rm = T)
tapply(en_final$en_cosine, en_final$type, max, na.rm = T)

en_final$ok <- NULL

export(en_final, "en/en_trials_final.csv")
```

## ru Russian 

```{r eval = F}
# original words
ru <- import("ru/ru_translate.csv")

# fix real words ----
ru_update <- import("ru/ru_translated_AK.xlsx")

cues <- ru_update %>% filter(ru_cue_trans != "")
for (i in 1:nrow(cues)){
  ru$ru_cue[ru$ru_cue == cues$ru_cue[i] #original cue match
            & ru$en_cue == cues$en_cue[i]] <- #english match 
    cues$ru_cue_trans[i] #new cue 
}

targets <- ru_update %>% filter(ru_target_trans != "")
for (i in 1:nrow(targets)){
  ru$ru_target[ru$ru_target == targets$ru_target[i] #original target match
            & ru$en_target == targets$en_target[i]] <- #english match 
    targets$ru_target_trans[i] #new target 
}

# # fix fake words ----
# cues <- ru_update %>% filter(ru_fake_cue_trans != "")
# for (i in 1:nrow(cues)){
#   ru$ru_fake_cue[ru$ru_fake_cue == cues$ru_fake_cue[i] #original cue match
#             & ru$en_cue == cues$en_cue[i]] <- #english match 
#     cues$ru_fake_cue_trans[i] #new cue 
# }
# 
# targets <- ru_update %>% filter(ru_fake_target_trans != "")
# for (i in 1:nrow(targets)){
#   ru$ru_fake_target[ru$ru_fake_target == targets$ru_fake_target[i] #original target match
#             & ru$en_target == targets$en_target[i]] <- #english match 
#     targets$ru_fake_target_trans[i] #new target 
# }

ru$ru_fake_target <- ru_update$ru_fake_target_fix
ru$ru_fake_cue <- ru_update$ru_fake_cue_fix

sum(duplicated(ru$ru_cue))
sum(duplicated(ru$ru_target))
sum(duplicated(ru$ru_fake_cue))
sum(duplicated(ru$ru_fake_target))
sum(ru$ru_cue == ru$ru_target)

export(ru, "../matched_stimuli/ru_matched.csv", row.names = F)

# create possible trials ----
ru_trials <- ru[ , c("ru_cue", "ru_target")]
ru_trials$type <- "related"
ru_trials$cue_type <- "word"
ru_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
ru$en_cue <- tolower(ru$en_cue)
ru$en_target <- tolower(ru$en_target)
# match unrelated pairs as a start 
ru_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(ru_unrelated)){
  ru_unrelated$en_cue[i] <- ru$ru_cue[ru$en_cue == ru_unrelated$en_cue[i]]
  ru_unrelated$en_target[i] <- ru$ru_target[ru$en_target == ru_unrelated$en_target[i]]
}

ru_trials <- rbind(ru_trials,
                   ru_unrelated %>% select(-en_cosine) %>% 
                     rename("ru_cue" = "en_cue", 
                            "ru_target" = "en_target"), 
                   data.frame(ru_cue = ru$ru_fake_cue,
                              ru_target = ru$ru_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(ru_cue = ru$ru_cue[sample(1:1000,
                                                        1000)],
                              ru_target = ru$ru_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(ru_cue = ru$ru_fake_cue[sample(1:1000,
                                                        1000)],
                              ru_target = ru$ru_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(ru_trials[ , c("ru_cue", "ru_target")]))

# update with low cosines from random shuffle ----
# set up model
ru_model <- read.table("/Volumes/SPAML Backup/subs_vec/ru/subs.ru.1e6.txt", quote="\"")
ru_model <- na.omit(ru_model)
ru_model$V1 <- tolower(ru_model$V1)
ru_model <- ru_model[!duplicated(ru_model$V1), ]
rownames(ru_model) <- ru_model$V1
ru_model <- ru_model[ , -1]

ru_trials$ru_cosine <- NA

# get cosine
for (row in 1:nrow(ru_trials)){
  
  if(ru_trials$type[row] != "nonword") { 
    
    ru_trials$ru_cosine[row] <- cosine(as.matrix(t(ru_model[
    c(ru_trials$ru_cue[row], ru_trials$ru_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
ru_trials$ok <- TRUE
ru_trials$ok[ru_trials$type == "unrelated" & abs(ru_trials$ru_cosine) > .15] <- FALSE

good_trials <- ru_trials %>% filter(ok == TRUE)
bad_trials <- ru_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$ru_target <- sample(bad_trials$ru_target, 
                               size = length(bad_trials$ru_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$ru_cosine[row] <- cosine(as.matrix(t(ru_model[
    c(bad_trials$ru_cue[row], bad_trials$ru_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(ru_cosine < .15)))
bad_trials <- bad_trials %>% filter(ru_cosine >= .15)
nrow(bad_trials)
# rud section I ran multiple times 

whats_left <- cosine(as.matrix(t(ru_model[c(
  bad_trials$ru_target,
  unique(good_trials$ru_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$ru_target)){
  
  # find all words that could be paired with bad ru_target
  # as updated ru_cue
  potrutial_cues <- rownames(whats_left)[whats_left[ , bad_trials$ru_target[i]] < .15] 
  
  # find all pairs of good ru_target that could
  # be paired with bad ru_cue
  potrutial_switch <- good_trials %>% filter(ru_cue %in% potrutial_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(ru_model[c(
    bad_trials$ru_cue[i],
    potrutial_switch$ru_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$ru_cue[i], bad_trials$ru_target[i],
    potrutial_switch$ru_cue[potrutial_switch$ru_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_ru_cue", "bad_ru_target", 
                           "good_ru_cue", "good_ru_target")

good_trials_small <- good_trials %>% 
  filter(!(ru_cue %in% switch_todo$good_ru_cue & type == "unrelated"))

new_good_trials <- data.frame(
  ru_cue = c(switch_todo$bad_ru_cue, switch_todo$good_ru_cue),
  ru_target = c(switch_todo$good_ru_target, switch_todo$bad_ru_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  ru_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$ru_cosine[row] <- cosine(as.matrix(t(ru_model[
    c(new_good_trials$ru_cue[row], new_good_trials$ru_target[row]) , ])))[2]
}

ru_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(ru_final[ , c("ru_cue", "ru_target")]))


tapply(ru_final$ru_cosine, ru_final$type, mean, na.rm = T)
tapply(ru_final$ru_cosine, ru_final$type, min, na.rm = T)
tapply(ru_final$ru_cosine, ru_final$type, max, na.rm = T)

ru_final$ok <- NULL

export(ru_final, "ru/ru_trials_final.csv")
```

## tr Turkish

```{r eval = F}
# original words
tr <- import("tr/tr_translate.csv")

# fix real words ----
# tr_update <- import("tr/tr_translated_Aslan.xlsx") second person added to this file 
tr_update <- import("tr/tr_translated_Elif.xlsx")

cues <- tr_update %>% filter(tr_cue_update != "")
for (i in 1:nrow(cues)){
  tr$tr_cue[tr$tr_cue == cues$tr_cue[i] #original cue match
            & tr$en_cue == cues$en_cue[i]] <- #english match 
    cues$tr_cue_update[i] #new cue 
}

targets <- tr_update %>% filter(tr_target_update != "")
for (i in 1:nrow(targets)){
  tr$tr_target[tr$tr_target == targets$tr_target[i] #original target match
            & tr$en_target == targets$en_target[i]] <- #english match 
    targets$tr_target_update[i] #new target 
}

# find matches and edit
tr %>% filter(tr_cue == tr_target)

# fix fake words ----
cues <- tr_update %>% filter(tr_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  tr$tr_fake_cue[tr$tr_fake_cue == cues$tr_fake_cue[i] #original cue match
            & tr$en_cue == cues$en_cue[i]] <- #english match 
    cues$tr_fake_cue_trans[i] #new cue 
}

targets <- tr_update %>% filter(tr_fake_target_trans != "")
for (i in 1:nrow(targets)){
  tr$tr_fake_target[tr$tr_fake_target == targets$tr_fake_target[i] #original target match
            & tr$en_target == targets$en_target[i]] <- #english match 
    targets$tr_fake_target_trans[i] #new target 
}

sum(duplicated(tr$tr_cue))
sum(duplicated(tr$tr_target))
sum(duplicated(tr$tr_fake_cue))
sum(duplicated(tr$tr_fake_target))
sum(tr$tr_cue == tr$tr_target)

export(tr, "../matched_stimuli/tr_matched.csv", row.names = F)

# create possible trials ----
tr_trials <- tr[ , c("tr_cue", "tr_target")]
tr_trials$type <- "related"
tr_trials$cue_type <- "word"
tr_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
tr$en_cue <- tolower(tr$en_cue)
tr$en_target <- tolower(tr$en_target)
# match unrelated pairs as a start 
tr_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(tr_unrelated)){
  tr_unrelated$en_cue[i] <- tr$tr_cue[tr$en_cue == tr_unrelated$en_cue[i]]
  tr_unrelated$en_target[i] <- tr$tr_target[tr$en_target == tr_unrelated$en_target[i]]
}

tr_trials <- rbind(tr_trials,
                   tr_unrelated %>% select(-en_cosine) %>% 
                     rename("tr_cue" = "en_cue", 
                            "tr_target" = "en_target"), 
                   data.frame(tr_cue = tr$tr_fake_cue,
                              tr_target = tr$tr_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(tr_cue = tr$tr_cue[sample(1:1000,
                                                        1000)],
                              tr_target = tr$tr_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(tr_cue = tr$tr_fake_cue[sample(1:1000,
                                                        1000)],
                              tr_target = tr$tr_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(tr_trials[ , c("tr_cue", "tr_target")]))

# update with low cosines from random shuffle ----
# set up model
tr_model <- read.table("/Volumes/SPAML Backup/subs_vec/tr/subs.tr.1e6.txt", quote="\"")
tr_model <- na.omit(tr_model)
tr_model$V1 <- tolower(tr_model$V1)
tr_model <- tr_model[!duplicated(tr_model$V1), ]
rownames(tr_model) <- tr_model$V1
tr_model <- tr_model[ , -1]

tr_trials$tr_cosine <- NA

# get cosine
for (row in 1:nrow(tr_trials)){
  
  if(tr_trials$type[row] != "nonword") { 
    
    tr_trials$tr_cosine[row] <- cosine(as.matrix(t(tr_model[
    c(tr_trials$tr_cue[row], tr_trials$tr_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
tr_trials$ok <- TRUE
tr_trials$ok[tr_trials$type == "unrelated" & abs(tr_trials$tr_cosine) > .15] <- FALSE

good_trials <- tr_trials %>% filter(ok == TRUE)
bad_trials <- tr_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$tr_target <- sample(bad_trials$tr_target, 
                               size = length(bad_trials$tr_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$tr_cosine[row] <- cosine(as.matrix(t(tr_model[
    c(bad_trials$tr_cue[row], bad_trials$tr_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(tr_cosine < .15)))
bad_trials <- bad_trials %>% filter(tr_cosine >= .15)
nrow(bad_trials)
# end section I ran multiple times 

whats_left <- cosine(as.matrix(t(tr_model[c(
  bad_trials$tr_target,
  unique(good_trials$tr_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$tr_target)){
  
  # find all words that could be paired with bad tr_target
  # as updated tr_cue
  potrutial_cues <- rownames(whats_left)[whats_left[ , bad_trials$tr_target[i]] < .15] 
  
  # find all pairs of good tr_target that could
  # be paired with bad tr_cue
  potrutial_switch <- good_trials %>% filter(tr_cue %in% potrutial_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(tr_model[c(
    bad_trials$tr_cue[i],
    potrutial_switch$tr_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$tr_cue[i], bad_trials$tr_target[i],
    potrutial_switch$tr_cue[potrutial_switch$tr_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_tr_cue", "bad_tr_target", 
                           "good_tr_cue", "good_tr_target")

good_trials_small <- good_trials %>% 
  filter(!(tr_cue %in% switch_todo$good_tr_cue & type == "unrelated"))

new_good_trials <- data.frame(
  tr_cue = c(switch_todo$bad_tr_cue, switch_todo$good_tr_cue),
  tr_target = c(switch_todo$good_tr_target, switch_todo$bad_tr_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  tr_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$tr_cosine[row] <- cosine(as.matrix(t(tr_model[
    c(new_good_trials$tr_cue[row], new_good_trials$tr_target[row]) , ])))[2]
}

tr_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(tr_final[ , c("tr_cue", "tr_target")]))


tapply(tr_final$tr_cosine, tr_final$type, mean, na.rm = T)
tapply(tr_final$tr_cosine, tr_final$type, min, na.rm = T)
tapply(tr_final$tr_cosine, tr_final$type, max, na.rm = T)

tr_final$ok <- NULL

export(tr_final, "tr/tr_trials_final.csv")
```

## ko Korean

```{r eval = F}
# original words
# don't use the original trials because there are lot of weird typos
# that were clearly fixed in the translated sheet
ko <- import("ko/ko_translated.xlsx")
ko_temp <- import("ko/ko_translate.csv")
ko <- ko %>% select(colnames(ko_temp))

# fix real words ----
ko_update <- import("ko/ko_translated.xlsx")

cues <- ko_update %>% filter(ko_cue_trans != "")
for (i in 1:nrow(cues)){
  ko$ko_cue[ko$ko_cue == cues$ko_cue[i] #original cue match
            & ko$en_cue == cues$en_cue[i]] <- #english match 
    cues$ko_cue_trans[i] #new cue 
}

targets <- ko_update %>% filter(ko_target_trans != "")
for (i in 1:nrow(targets)){
  ko$ko_target[ko$ko_target == targets$ko_target[i] #original target match
            & ko$en_target == targets$en_target[i]] <- #english match 
    targets$ko_target_trans[i] #new target 
}

# find matches and edit
ko %>% filter(ko_cue == ko_target)

# fix fake words ----
cues <- ko_update %>% filter(ko_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  ko$ko_fake_cue[ko$ko_fake_cue == cues$ko_fake_cue[i] #original cue match
            & ko$en_cue == cues$en_cue[i]] <- #english match 
    cues$ko_fake_cue_trans[i] #new cue 
}

targets <- ko_update %>% filter(ko_fake_target_trans != "")
for (i in 1:nrow(targets)){
  ko$ko_fake_target[ko$ko_fake_target == targets$ko_fake_target[i] #original target match
            & ko$en_target == targets$en_target[i]] <- #english match 
    targets$ko_fake_target_trans[i] #new target 
}

sum(duplicated(ko$ko_cue))
sum(duplicated(ko$ko_target))
sum(duplicated(ko$ko_fake_cue))
sum(duplicated(ko$ko_fake_target))
sum(ko$ko_cue == ko$ko_target)

export(ko, "../matched_stimuli/ko_matched.csv", row.names = F)

# create possible trials ----
ko_trials <- ko[ , c("ko_cue", "ko_target")]
ko_trials$type <- "related"
ko_trials$cue_type <- "word"
ko_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
ko$en_cue <- tolower(ko$en_cue)
ko$en_target <- tolower(ko$en_target)
# match unrelated pairs as a start 
ko_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(ko_unrelated)){
  ko_unrelated$en_cue[i] <- ko$ko_cue[ko$en_cue == ko_unrelated$en_cue[i]]
  ko_unrelated$en_target[i] <- ko$ko_target[ko$en_target == ko_unrelated$en_target[i]]
}

ko_trials <- rbind(ko_trials,
                   ko_unrelated %>% select(-en_cosine) %>% 
                     rename("ko_cue" = "en_cue", 
                            "ko_target" = "en_target"), 
                   data.frame(ko_cue = ko$ko_fake_cue,
                              ko_target = ko$ko_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(ko_cue = ko$ko_cue[sample(1:1000,
                                                        1000)],
                              ko_target = ko$ko_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(ko_cue = ko$ko_fake_cue[sample(1:1000,
                                                        1000)],
                              ko_target = ko$ko_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(ko_trials[ , c("ko_cue", "ko_target")]))

# update with low cosines from random shuffle ----
# set up model
ko_model <- read.table("/Volumes/SPAML Backup/subs_vec/ko/subs.ko.1e6.txt", quote="\"")
ko_model <- na.omit(ko_model)
ko_model$V1 <- tolower(ko_model$V1)
ko_model <- ko_model[!duplicated(ko_model$V1), ]
rownames(ko_model) <- ko_model$V1
ko_model <- ko_model[ , -1]

ko_trials$ko_cosine <- NA

# get cosine
for (row in 1:nrow(ko_trials)){
  
  if(ko_trials$type[row] != "nonword") { 
    
    ko_trials$ko_cosine[row] <- cosine(as.matrix(t(ko_model[
    c(ko_trials$ko_cue[row], ko_trials$ko_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
# if they are NA, they are zero 
ko_trials$ko_cosine[is.na(ko_trials$ko_cosine) & ko_trials$type == "unrelated"] <- 0
ko_trials$ok <- TRUE
ko_trials$ok[ko_trials$type == "unrelated" & abs(ko_trials$ko_cosine) > .15] <- FALSE

good_trials <- ko_trials %>% filter(ok == TRUE)
bad_trials <- ko_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$ko_target <- sample(bad_trials$ko_target, 
                               size = length(bad_trials$ko_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$ko_cosine[row] <- cosine(as.matrix(t(ko_model[
    c(bad_trials$ko_cue[row], bad_trials$ko_target[row]) , ])))[2]
}

# deal with zeros 
bad_trials$ko_cosine[is.na(bad_trials$ko_cosine)] <- 0
bad_trials$ko_cosine[bad_trials$ko_target == "땡땡"] <- 0
bad_trials$ko_cosine[bad_trials$ko_target == "버리다"] <- 0

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(ko_cosine < .15))) # update to 20
bad_trials <- bad_trials %>% filter(ko_cosine >= .15)
nrow(bad_trials)

whats_left <- cosine(as.matrix(t(ko_model[c(
  bad_trials$ko_target,
  unique(good_trials$ko_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$ko_target)){
  
  # find all words that could be paired with bad ko_target
  potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$ko_target[i]] < .20] 
  
  # find all pairs of good ko_target that could
  # be paired with bad ko_cue
  potential_switch <- good_trials %>% filter(ko_cue %in% potential_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(ko_model[c(
    bad_trials$ko_cue[i],
    potential_switch$ko_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$ko_cue[i], bad_trials$ko_target[i],
    potential_switch$ko_cue[potential_switch$ko_target == new_target][1],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_ko_cue", "bad_ko_target", 
                           "good_ko_cue", "good_ko_target")

good_trials_small <- good_trials %>% 
  filter(!(ko_cue %in% switch_todo$good_ko_cue & type == "unrelated")) 

new_good_trials <- data.frame(
  ko_cue = c(switch_todo$bad_ko_cue, switch_todo$good_ko_cue),
  ko_target = c(switch_todo$good_ko_target, switch_todo$bad_ko_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  ko_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$ko_cosine[row] <- cosine(as.matrix(t(ko_model[
    c(new_good_trials$ko_cue[row], new_good_trials$ko_target[row]) , ])))[2]
}

# creates too many so sample 
ko_final <- bind_rows(good_trials_small, new_good_trials[sample(1:nrow(new_good_trials), 5000-nrow(good_trials_small), replace = F), ])
sum(duplicated(ko_final[ , c("ko_cue", "ko_target")]))

tapply(ko_final$ko_cosine, ko_final$type, mean, na.rm = T)
tapply(ko_final$ko_cosine, ko_final$type, min, na.rm = T)
tapply(ko_final$ko_cosine, ko_final$type, max, na.rm = T)

ko_final$ok <- NULL

export(ko_final, "ko/ko_trials_final.csv")
```

## cs Czech

```{r eval = F}
# original words
# make sure to use the translated sheet so we don't have issues 
# that were clearly fixed in the translated sheet
cs <- import("cs/cs_update2.xlsx")
cs_temp <- import("cs/cs_translate.csv")
cs <- cs %>% select(colnames(cs_temp))

# fix real words ----
cs_update <- import("cs/cs_update2.xlsx")

cues <- cs_update %>% filter(cs_cue_final != "")
for (i in 1:nrow(cues)){
  cs$cs_cue[cs$cs_cue == cues$cs_cue[i] #original cue match
            & cs$en_cue == cues$en_cue[i]] <- #english match 
    cues$cs_cue_final[i] #new cue 
}

targets <- cs_update %>% filter(cs_target_final != "")
for (i in 1:nrow(targets)){
  cs$cs_target[cs$cs_target == targets$cs_target[i] #original target match
            & cs$en_target == targets$en_target[i]] <- #english match 
    targets$cs_target_final[i] #new target 
}

# find matches and edit
cs %>% filter(cs_cue == cs_target)

# fix fake words ----
cues <- cs_update %>% filter(cs_fake_cue_final != "")
for (i in 1:nrow(cues)){
  cs$cs_fake_cue[cs$cs_fake_cue == cues$cs_fake_cue[i] #original cue match
            & cs$en_cue == cues$en_cue[i]] <- #english match 
    cues$cs_fake_cue_final[i] #new cue 
}

targets <- cs_update %>% filter(cs_fake_target_final != "")
for (i in 1:nrow(targets)){
  cs$cs_fake_target[cs$cs_fake_target == targets$cs_fake_target[i] #original target match
            & cs$en_target == targets$en_target[i]] <- #english match 
    targets$cs_fake_target_final[i] #new target 
}

cues <- cs_update %>% filter(cs_fake_cue_final2 != "")
for (i in 1:nrow(cues)){
  cs$cs_fake_cue[cs$cs_fake_cue == cues$cs_fake_cue[i] #original cue match
            & cs$en_cue == cues$en_cue[i]] <- #english match 
    cues$cs_fake_cue_final2[i] #new cue 
}

targets <- cs_update %>% filter(cs_fake_target_final2 != "")
for (i in 1:nrow(targets)){
  cs$cs_fake_target[cs$cs_fake_target == targets$cs_fake_target[i] #original target match
            & cs$en_target == targets$en_target[i]] <- #english match 
    targets$cs_fake_target_final2[i] #new target 
}


sum(duplicated(cs$cs_cue))
sum(duplicated(cs$cs_target))
sum(duplicated(cs$cs_fake_cue))
sum(duplicated(cs$cs_fake_target))
sum(cs$cs_cue == cs$cs_target)

export(cs, "../matched_stimuli/cs_matched.csv", row.names = F)

# create possible trials ----
cs_trials <- cs[ , c("cs_cue", "cs_target")]
cs_trials$type <- "related"
cs_trials$cue_type <- "word"
cs_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
cs$en_cue <- tolower(cs$en_cue)
cs$en_target <- tolower(cs$en_target)
# match unrelated pairs as a start 
cs_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(cs_unrelated)){
  cs_unrelated$en_cue[i] <- cs$cs_cue[cs$en_cue == cs_unrelated$en_cue[i]]
  cs_unrelated$en_target[i] <- cs$cs_target[cs$en_target == cs_unrelated$en_target[i]]
}

cs_trials <- rbind(cs_trials,
                   cs_unrelated %>% select(-en_cosine) %>% 
                     rename("cs_cue" = "en_cue", 
                            "cs_target" = "en_target"), 
                   data.frame(cs_cue = cs$cs_fake_cue,
                              cs_target = cs$cs_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(cs_cue = cs$cs_cue[sample(1:1000,
                                                        1000)],
                              cs_target = cs$cs_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(cs_cue = cs$cs_fake_cue[sample(1:1000,
                                                        1000)],
                              cs_target = cs$cs_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(cs_trials[ , c("cs_cue", "cs_target")]))

# update with low cosines from random shuffle ----
# set up model
cs_model <- read.table("/Volumes/SPAML Backup/subs_vec/cs/subs.cs.1e6.txt", quote="\"")
cs_model <- na.omit(cs_model)
cs_model$V1 <- tolower(cs_model$V1)
cs_model <- cs_model[!duplicated(cs_model$V1), ]
rownames(cs_model) <- cs_model$V1
cs_model <- cs_model[ , -1]

cs_trials$cs_cosine <- NA

# get cosine
for (row in 1:nrow(cs_trials)){
  
  if(cs_trials$type[row] != "nonword") { 
    
    cs_trials$cs_cosine[row] <- cosine(as.matrix(t(cs_model[
    c(cs_trials$cs_cue[row], cs_trials$cs_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
# if they are NA, they are zero 
cs_trials$cs_cosine[is.na(cs_trials$cs_cosine) & cs_trials$type == "unrelated"] <- 0
cs_trials$ok <- TRUE
cs_trials$ok[cs_trials$type == "unrelated" & abs(cs_trials$cs_cosine) > .15] <- FALSE

good_trials <- cs_trials %>% filter(ok == TRUE)
bad_trials <- cs_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$cs_target <- sample(bad_trials$cs_target, 
                               size = length(bad_trials$cs_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$cs_cosine[row] <- cosine(as.matrix(t(cs_model[
    c(bad_trials$cs_cue[row], bad_trials$cs_target[row]) , ])))[2]
}

# deal with zeros 
bad_trials$cs_cosine[is.na(bad_trials$cs_cosine)] <- 0

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(cs_cosine < .15))) # update to 20
bad_trials <- bad_trials %>% filter(cs_cosine >= .15)
nrow(bad_trials)

whats_left <- cosine(as.matrix(t(cs_model[c(
  bad_trials$cs_target,
  unique(good_trials$cs_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$cs_target)){
  
  # find all words that could be paired with bad cs_target
  potential_cues <- rownames(whats_left)[whats_left[ , bad_trials$cs_target[i]] < .20] 
  
  # find all pairs of good cs_target that could
  # be paired with bad cs_cue
  potential_switch <- good_trials %>% filter(cs_cue %in% potential_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(cs_model[c(
    bad_trials$cs_cue[i],
    potential_switch$cs_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$cs_cue[i], bad_trials$cs_target[i],
    potential_switch$cs_cue[potential_switch$cs_target == new_target][1],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_cs_cue", "bad_cs_target", 
                           "good_cs_cue", "good_cs_target")

good_trials_small <- good_trials %>% 
  filter(!(cs_cue %in% switch_todo$good_cs_cue & type == "unrelated")) 

new_good_trials <- data.frame(
  cs_cue = c(switch_todo$bad_cs_cue, switch_todo$good_cs_cue),
  cs_target = c(switch_todo$good_cs_target, switch_todo$bad_cs_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  cs_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$cs_cosine[row] <- cosine(as.matrix(t(cs_model[
    c(new_good_trials$cs_cue[row], new_good_trials$cs_target[row]) , ])))[2]
}

# creates too many so sample 
cs_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(cs_final[ , c("cs_cue", "cs_target")]))

tapply(cs_final$cs_cosine, cs_final$type, mean, na.rm = T)
tapply(cs_final$cs_cosine, cs_final$type, min, na.rm = T)
tapply(cs_final$cs_cosine, cs_final$type, max, na.rm = T)

cs_final$ok <- NULL

export(cs_final, "cs/cs_trials_final.csv")
```

## ja Japanese

```{r eval = F}
# original words the japanese team did this for me
ja <- import("ja/ja_translated_final.xlsx")
colnames(ja) <- gsub("_final", "", colnames(ja))

ja %>% filter(ja_cue == ja_target)

sum(duplicated(ja$ja_cue))
sum(duplicated(ja$ja_target))
sum(duplicated(ja$ja_fake_cue))
sum(duplicated(ja$ja_fake_target))
sum(ja$ja_cue == ja$ja_target)

export(ja, "../matched_stimuli/ja_matched.csv", row.names = F)

# create possible trials ----
ja_trials <- ja[ , c("ja_cue", "ja_target")]
ja_trials$type <- "related"
ja_trials$cue_type <- "word"
ja_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
ja$en_cue <- tolower(ja$en_cue)
ja$en_target <- tolower(ja$en_target)
# match unrelated pairs as a start 
ja_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(ja_unrelated)){
  ja_unrelated$en_cue[i] <- ja$ja_cue[ja$en_cue == ja_unrelated$en_cue[i]]
  ja_unrelated$en_target[i] <- ja$ja_target[ja$en_target == ja_unrelated$en_target[i]]
}

ja_trials <- rbind(ja_trials,
                   ja_unrelated %>% select(-en_cosine) %>% 
                     rename("ja_cue" = "en_cue", 
                            "ja_target" = "en_target"), 
                   data.frame(ja_cue = ja$ja_fake_cue,
                              ja_target = ja$ja_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(ja_cue = ja$ja_cue[sample(1:1000,
                                                        1000)],
                              ja_target = ja$ja_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(ja_cue = ja$ja_fake_cue[sample(1:1000,
                                                        1000)],
                              ja_target = ja$ja_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(ja_trials[ , c("ja_cue", "ja_target")]))

# update with low cosines from random shuffle ----
# set up model
ja_model <- import("/Volumes/SPAML Backup/subs_vec/ja/ja_300_5_sg_wxd.csv")
ja_model <- na.omit(ja_model)
ja_model$V1 <- tolower(ja_model$V1)
ja_model <- ja_model[-1 , ]
ja_model <- ja_model[!duplicated(ja_model$V1), ]
rownames(ja_model) <- ja_model$V1
ja_model <- ja_model[ , -1]

ja_trials$ja_cosine <- NA

# get cosine
for (row in 1:nrow(ja_trials)){
  
  if(ja_trials$type[row] != "nonword") { 
    
    if (ja_trials$ja_cue[row] %in% rownames(ja_model) & 
        ja_trials$ja_target[row] %in% rownames(ja_model)){
    ja_trials$ja_cosine[row] <- cosine(as.matrix(t(ja_model[
    c(ja_trials$ja_cue[row], ja_trials$ja_target[row]) , ])))[2]
    } else { 
      ja_trials$ja_cosine[row] <- 0 
    }
    
  }
  
}

# update trials that have cosines too big 
ja_trials$ok <- TRUE
ja_trials$ok[ja_trials$type == "unrelated" & abs(ja_trials$ja_cosine) > .15] <- FALSE

good_trials <- ja_trials %>% filter(ok == TRUE)
bad_trials <- ja_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$ja_target <- sample(bad_trials$ja_target, 
                               size = length(bad_trials$ja_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
  
    if (bad_trials$ja_cue[row] %in% rownames(ja_model) & 
        bad_trials$ja_target[row] %in% rownames(ja_model)){
    bad_trials$ja_cosine[row] <- cosine(as.matrix(t(ja_model[
    c(bad_trials$ja_cue[row], bad_trials$ja_target[row]) , ])))[2]
    } else { 
      bad_trials$ja_cosine[row] <- 0 
    }
}

# deal with zeros 
bad_trials$ja_cosine[is.na(bad_trials$ja_cosine)] <- 0

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(ja_cosine < .50))) # update to 20
bad_trials <- bad_trials %>% filter(ja_cosine >= .50)
nrow(bad_trials)

whats_left <- cosine(as.matrix(t(ja_model[c(
  bad_trials$ja_target,
  unique(good_trials$ja_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

# just deal with the wild JA ones 
ja_final <- bind_rows(good_trials, bad_trials)
sum(duplicated(ja_final[ , c("ja_cue", "ja_target")]))

tapply(ja_final$ja_cosine, ja_final$type, mean, na.rm = T)
tapply(ja_final$ja_cosine, ja_final$type, min, na.rm = T)
tapply(ja_final$ja_cosine, ja_final$type, max, na.rm = T)

ja_final$ok <- NULL

export(ja_final, "ja/ja_trials_final.csv")
```

## da Danish

```{r eval = F}
# original words
da <- import("da/da_translate.csv")

# fix real words ----
da_update <- import("da/da_translated-v4.xlsx")

cues <- da_update %>% filter(da_cue_trans != "")
for (i in 1:nrow(cues)){
  da$da_cue[da$da_cue == cues$da_cue[i] #original cue match
            & da$en_cue == cues$en_cue[i]] <- #english match 
    cues$da_cue_trans[i] #new cue 
}

targets <- da_update %>% filter(da_target_trans != "")
for (i in 1:nrow(targets)){
  da$da_target[da$da_target == targets$da_target[i] #original target match
            & da$en_target == targets$en_target[i]] <- #english match 
    targets$da_target_trans[i] #new target 
}

# fix fake words ----
# cues <- da_update %>% filter(da_fake_cue_trans != "")
# for (i in 1:nrow(cues)){
#   da$da_fake_cue[da$da_fake_cue == cues$da_fake_cue[i] #original cue match
#             & da$en_cue == cues$en_cue[i]] <- #english match
#     cues$da_fake_cue_trans[i] #new cue
# }
# 
# targets <- da_update %>% filter(da_fake_target_trans != "")
# for (i in 1:nrow(targets)){
#   da$da_fake_target[da$da_fake_target == targets$da_fake_target[i] #original target match
#             & da$en_target == targets$en_target[i]] <- #english match
#     targets$da_fake_target_trans[i] #new target
# }
da$da_fake_target <- da_update$da_fake_target_final
da$da_fake_cue <- da_update$da_fake_cue_final

sum(duplicated(da$da_cue))
sum(duplicated(da$da_target))
sum(duplicated(da$da_fake_cue))
sum(duplicated(da$da_fake_target))

nrow(da %>% filter(da_cue == da_target))

export(da, "../matched_stimuli/da_matched.csv", row.names = F)

# create possible trials ----
da_trials <- da[ , c("da_cue", "da_target")]
da_trials$type <- "related"
da_trials$cue_type <- "word"
da_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
da$en_cue <- tolower(da$en_cue)
da$en_target <- tolower(da$en_target)
# match unrelated pairs as a start 
da_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(da_unrelated)){
  da_unrelated$en_cue[i] <- da$da_cue[da$en_cue == da_unrelated$en_cue[i]]
  da_unrelated$en_target[i] <- da$da_target[da$en_target == da_unrelated$en_target[i]]
}

da_trials <- rbind(da_trials,
                   da_unrelated %>% select(-en_cosine) %>% 
                     rename("da_cue" = "en_cue", 
                            "da_target" = "en_target"), 
                   data.frame(da_cue = da$da_fake_cue,
                              da_target = da$da_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(da_cue = da$da_cue[sample(1:1000,
                                                        1000)],
                              da_target = da$da_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(da_cue = da$da_fake_cue[sample(1:1000,
                                                        1000)],
                              da_target = da$da_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(da_trials[ , c("da_cue", "da_target")]))

# update with low cosines from random shuffle ----
# set up model
da_model <- read.table("/Volumes/SPAML Backup/subs_vec/da/subs.da.1e6.txt", quote="\"")
da_model <- na.omit(da_model)
da_model$V1 <- tolower(da_model$V1)
da_model <- da_model[!duplicated(da_model$V1), ]
rownames(da_model) <- da_model$V1
da_model <- da_model[ , -1]

da_trials$da_cosine <- NA

# get cosine
for (row in 1:nrow(da_trials)){
  
  if(da_trials$type[row] != "nonword") { 
    
    da_trials$da_cosine[row] <- cosine(as.matrix(t(da_model[
    c(da_trials$da_cue[row], da_trials$da_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
da_trials$ok <- TRUE
da_trials$ok[da_trials$type == "unrelated" & abs(da_trials$da_cosine) > .15] <- FALSE

good_trials <- da_trials %>% filter(ok == TRUE)
bad_trials <- da_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$da_target <- sample(bad_trials$da_target, 
                               size = length(bad_trials$da_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$da_cosine[row] <- cosine(as.matrix(t(da_model[
    c(bad_trials$da_cue[row], bad_trials$da_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(da_cosine < .15)))
bad_trials <- bad_trials %>% filter(da_cosine >= .15)
nrow(bad_trials)
# ran section I ran multiple times 

whats_left <- cosine(as.matrix(t(da_model[c(
  bad_trials$da_target,
  unique(good_trials$da_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$da_target)){
  
  # find all words that could be paired with bad da_target
  # as updated da_cue
  potrutial_cues <- rownames(whats_left)[whats_left[ , bad_trials$da_target[i]] < .15] 
  
  # find all pairs of good da_target that could
  # be paired with bad da_cue
  potrutial_switch <- good_trials %>% filter(da_cue %in% potrutial_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(da_model[c(
    bad_trials$da_cue[i],
    potrutial_switch$da_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$da_cue[i], bad_trials$da_target[i],
    potrutial_switch$da_cue[potrutial_switch$da_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_da_cue", "bad_da_target", 
                           "good_da_cue", "good_da_target")

good_trials_small <- good_trials %>% 
  filter(!(da_cue %in% switch_todo$good_da_cue & type == "unrelated"))

new_good_trials <- data.frame(
  da_cue = c(switch_todo$bad_da_cue, switch_todo$good_da_cue),
  da_target = c(switch_todo$good_da_target, switch_todo$bad_da_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  da_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$da_cosine[row] <- cosine(as.matrix(t(da_model[
    c(new_good_trials$da_cue[row], new_good_trials$da_target[row]) , ])))[2]
}

da_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(da_final[ , c("da_cue", "da_target")]))

# check cosines
tapply(da_final$da_cosine, da_final$type, mean, na.rm = T)
tapply(da_final$da_cosine, da_final$type, min, na.rm = T)
tapply(da_final$da_cosine, da_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- da_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(da_target) %>% 
  filter(n != 2)

weird_trials <- da_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(da_target %in% target_table$da_target)

# check for NA
sum(is.na(da_final$da_cue))
sum(is.na(da_final$da_target))
sum(grepl("^NA", da_final$da_cue))
sum(grepl("^NA", da_final$da_target))

# check rows
nrow(da_final)
table(da_final$type, da_final$cue_type, da_final$target_type)

da_final$ok <- NULL

export(da_final, "da/da_trials_final.csv")
```

## de German

```{r eval = F}
# original words
de <- import("de/de_translate.csv")
de$en_cue <- gsub("digusting", "disgusting", de$en_cue)

# fix real words ----
de_update <- import("de/de_translate_final.xlsx") %>% 
  mutate(across(everything(), tolower))

# fix cue words ----
# cues <- de_update %>% filter(de_cue_trans != "")
# for (i in 1:nrow(cues)){
#   de$de_cue[de$de_cue == cues$de_cue[i] #original cue match
#             & de$en_cue == cues$en_cue[i]] <- #english match 
#     cues$de_cue_trans[i] #new cue 
# }
# 
# 
# targets <- de_update %>% filter(de_target_trans != "")
# for (i in 1:nrow(targets)){
#   de$de_target[de$de_target == targets$de_target[i] #original target match
#             & de$en_target == targets$en_target[i]] <- #english match 
#     targets$de_target_trans[i] #new target 
# }
de$de_cue <- de_update$de_cue_trans_final
de$de_target <- de_update$de_target_trans_final

# fix fake words ----
# cues <- de_update %>% filter(de_fake_cue_trans != "")
# for (i in 1:nrow(cues)){
#   de$de_fake_cue[de$de_fake_cue == cues$de_fake_cue[i] #original cue match
#             & de$en_cue == cues$en_cue[i]] <- #english match
#     cues$de_fake_cue_trans[i] #new cue
# }
# 
# targets <- de_update %>% filter(de_fake_target_trans != "")
# for (i in 1:nrow(targets)){
#   de$de_fake_target[de$de_fake_target == targets$de_fake_target[i] #original target match
#             & de$en_target == targets$en_target[i]] <- #english match
#     targets$de_fake_target_trans[i] #new target
# }
de$de_fake_cue <- de_update$de_fake_cue_trans_final
de$de_fake_target <- de_update$de_fake_target_trans_final

sum(duplicated(de$de_cue))
sum(duplicated(de$de_target))
sum(duplicated(de$de_fake_cue))
sum(duplicated(de$de_fake_target))

nrow(de %>% filter(de_cue == de_target))

export(de, "../matched_stimuli/de_matched.csv", row.names = F)

# create possible trials ----
de_trials <- de[ , c("de_cue", "de_target")]
de_trials$type <- "related"
de_trials$cue_type <- "word"
de_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
de$en_cue <- tolower(de$en_cue)
de$en_target <- tolower(de$en_target)
# match unrelated pairs as a start 
de_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(de_unrelated)){
  de_unrelated$en_cue[i] <- de$de_cue[de$en_cue == de_unrelated$en_cue[i]]
  de_unrelated$en_target[i] <- de$de_target[de$en_target == de_unrelated$en_target[i]]
}

de_trials <- rbind(de_trials,
                   de_unrelated %>% select(-en_cosine) %>% 
                     rename("de_cue" = "en_cue", 
                            "de_target" = "en_target"), 
                   data.frame(de_cue = de$de_fake_cue,
                              de_target = de$de_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(de_cue = de$de_cue[sample(1:1000,
                                                        1000)],
                              de_target = de$de_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(de_cue = de$de_fake_cue[sample(1:1000,
                                                        1000)],
                              de_target = de$de_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(de_trials[ , c("de_cue", "de_target")]))

# update with low cosines from random shuffle ----
# set up model
de_model <- read.table("/Volumes/SPAML Backup/subs_vec/de/subs.de.1e6.txt", quote="\"")
de_model <- na.omit(de_model)
de_model$V1 <- tolower(de_model$V1)
de_model <- de_model[!duplicated(de_model$V1), ]
rownames(de_model) <- de_model$V1
de_model <- de_model[ , -1]

de_trials$de_cosine <- NA

# get cosine
for (row in 1:nrow(de_trials)){
  
  if(de_trials$type[row] != "nonword") { 
    
    de_trials$de_cosine[row] <- cosine(as.matrix(t(de_model[
    c(de_trials$de_cue[row], de_trials$de_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
de_trials$ok <- TRUE
de_trials$ok[de_trials$type == "unrelated" & abs(de_trials$de_cosine) > .15] <- FALSE

good_trials <- de_trials %>% filter(ok == TRUE)
bad_trials <- de_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$de_target <- sample(bad_trials$de_target, 
                               size = length(bad_trials$de_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$de_cosine[row] <- cosine(as.matrix(t(de_model[
    c(bad_trials$de_cue[row], bad_trials$de_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(de_cosine < .15)))
bad_trials <- bad_trials %>% filter(de_cosine >= .15)
nrow(bad_trials)
# ran section I ran multiple times 

whats_left <- cosine(as.matrix(t(de_model[c(
  bad_trials$de_target,
  unique(good_trials$de_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$de_target)){
  
  # find all words that could be paired with bad de_target
  # as updated de_cue
  potrutial_cues <- rownames(whats_left)[whats_left[ , bad_trials$de_target[i]] < .15] 
  
  # find all pairs of good de_target that could
  # be paired with bad de_cue
  potrutial_switch <- good_trials %>% filter(de_cue %in% potrutial_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(de_model[c(
    bad_trials$de_cue[i],
    potrutial_switch$de_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$de_cue[i], bad_trials$de_target[i],
    potrutial_switch$de_cue[potrutial_switch$de_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_de_cue", "bad_de_target", 
                           "good_de_cue", "good_de_target")

good_trials_small <- good_trials %>% 
  filter(!(de_cue %in% switch_todo$good_de_cue & type == "unrelated"))

new_good_trials <- data.frame(
  de_cue = c(switch_todo$bad_de_cue, switch_todo$good_de_cue),
  de_target = c(switch_todo$good_de_target, switch_todo$bad_de_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  de_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$de_cosine[row] <- cosine(as.matrix(t(de_model[
    c(new_good_trials$de_cue[row], new_good_trials$de_target[row]) , ])))[2]
}

de_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(de_final[ , c("de_cue", "de_target")]))

# check cosines
tapply(de_final$de_cosine, de_final$type, mean, na.rm = T)
tapply(de_final$de_cosine, de_final$type, min, na.rm = T)
tapply(de_final$de_cosine, de_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- de_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(de_target) %>% 
  filter(n != 2)

weird_trials <- de_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(de_target %in% target_table$de_target)

# check for NA
sum(is.na(de_final$de_cue))
sum(is.na(de_final$de_target))
sum(grepl("^NA", de_final$de_cue))
sum(grepl("^NA", de_final$de_target))

# check rows
nrow(de_final)
table(de_final$type, de_final$cue_type, de_final$target_type)

de_final$ok <- NULL

export(de_final, "de/de_trials_final.csv")
```

## ar Arabic

```{r eval = F}
# original words
ar <- import("ar/ar_translate.csv")
ar$en_cue <- gsub("digusting", "disgusting", ar$en_cue)

# fix real words ----
ar_update <- import("ar/ar_translatecomplete.xlsx") %>% 
  mutate(across(everything(), tolower))

# # fix cue words ----
# cues <- ar_update %>% filter(ar_cue_trans != "")
# for (i in 1:nrow(cues)){
#   ar$ar_cue[ar$ar_cue == cues$ar_cue[i] #original cue match
#             & ar$en_cue == cues$en_cue[i]] <- #english match
#     cues$ar_cue_trans[i] #new cue
# }

ar$ar_cue <- ar_update$ar_cue_final

# targets <- ar_update %>% filter(ar_target_trans != "")
# for (i in 1:nrow(targets)){
#   ar$ar_target[ar$ar_target == targets$ar_target[i] #original target match
#             & ar$en_target == targets$en_target[i]] <- #english match
#     targets$ar_target_trans[i] #new target
# }

ar$ar_target <- ar_update$ar_target_final

# fix fake words ----
cues <- ar_update %>% filter(ar_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  ar$ar_fake_cue[ar$ar_fake_cue == cues$ar_fake_cue[i] #original cue match
            & ar$en_cue == cues$en_cue[i]] <- #english match
    cues$ar_fake_cue_trans[i] #new cue
}

targets <- ar_update %>% filter(ar_fake_target_trans != "")
for (i in 1:nrow(targets)){
  ar$ar_fake_target[ar$ar_fake_target == targets$ar_fake_target[i] #original target match
            & ar$en_target == targets$en_target[i]] <- #english match
    targets$ar_fake_target_trans[i] #new target
}

sum(duplicated(ar$ar_cue))
sum(duplicated(ar$ar_target))
sum(duplicated(ar$ar_fake_cue))
sum(duplicated(ar$ar_fake_target))

nrow(ar %>% filter(ar_cue == ar_target))

export(ar, "../matched_stimuli/ar_matched.csv", row.names = F)

# create possible trials ----
ar_trials <- ar[ , c("ar_cue", "ar_target")]
ar_trials$type <- "related"
ar_trials$cue_type <- "word"
ar_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
ar$en_cue <- tolower(ar$en_cue)
ar$en_target <- tolower(ar$en_target)
# match unrelated pairs as a start 
ar_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(ar_unrelated)){
  ar_unrelated$en_cue[i] <- ar$ar_cue[ar$en_cue == ar_unrelated$en_cue[i]]
  ar_unrelated$en_target[i] <- ar$ar_target[ar$en_target == ar_unrelated$en_target[i]]
}

ar_trials <- rbind(ar_trials,
                   ar_unrelated %>% select(-en_cosine) %>% 
                     rename("ar_cue" = "en_cue", 
                            "ar_target" = "en_target"), 
                   data.frame(ar_cue = ar$ar_fake_cue,
                              ar_target = ar$ar_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(ar_cue = ar$ar_cue[sample(1:1000,
                                                        1000)],
                              ar_target = ar$ar_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(ar_cue = ar$ar_fake_cue[sample(1:1000,
                                                        1000)],
                              ar_target = ar$ar_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(ar_trials[ , c("ar_cue", "ar_target")]))

# update with low cosines from random shuffle ----
# set up model
ar_model <- read.table("/Volumes/SPAML Backup/subs_vec/ar/subs.ar.1e6.txt", quote="\"")
ar_model <- na.omit(ar_model)
ar_model$V1 <- tolower(ar_model$V1)
ar_model <- ar_model[!duplicated(ar_model$V1), ]
rownames(ar_model) <- ar_model$V1
ar_model <- ar_model[ , -1]

ar_trials$ar_cosine <- NA

# get cosine
for (row in 1:nrow(ar_trials)){
  
  if(ar_trials$type[row] != "nonword") { 
    
    ar_trials$ar_cosine[row] <- cosine(as.matrix(t(ar_model[
    c(ar_trials$ar_cue[row], ar_trials$ar_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
ar_trials$ok <- TRUE
ar_trials$ok[ar_trials$type == "unrelated" & abs(ar_trials$ar_cosine) > .15] <- FALSE

good_trials <- ar_trials %>% filter(ok == TRUE)
bad_trials <- ar_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$ar_target <- sample(bad_trials$ar_target, 
                               size = length(bad_trials$ar_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$ar_cosine[row] <- cosine(as.matrix(t(ar_model[
    c(bad_trials$ar_cue[row], bad_trials$ar_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(ar_cosine < .15)))
bad_trials <- bad_trials %>% filter(ar_cosine >= .15)
nrow(bad_trials)
# this section I ran multiple times 

whats_left <- cosine(as.matrix(t(ar_model[c(
  bad_trials$ar_target,
  unique(good_trials$ar_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$ar_target)){
  
  # find all words that could be paired with bad ar_target
  # as updated ar_cue
  potrutial_cues <- rownames(whats_left)[whats_left[ , bad_trials$ar_target[i]] < .15] 
  
  # find all pairs of good ar_target that could
  # be paired with bad ar_cue
  potrutial_switch <- good_trials %>% filter(ar_cue %in% potrutial_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(ar_model[c(
    bad_trials$ar_cue[i],
    potrutial_switch$ar_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$ar_cue[i], bad_trials$ar_target[i],
    potrutial_switch$ar_cue[potrutial_switch$ar_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_ar_cue", "bad_ar_target", 
                           "good_ar_cue", "good_ar_target")

good_trials_small <- good_trials %>% 
  filter(!(ar_cue %in% switch_todo$good_ar_cue & type == "unrelated"))

new_good_trials <- data.frame(
  ar_cue = c(switch_todo$bad_ar_cue, switch_todo$good_ar_cue),
  ar_target = c(switch_todo$good_ar_target, switch_todo$bad_ar_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  ar_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$ar_cosine[row] <- cosine(as.matrix(t(ar_model[
    c(new_good_trials$ar_cue[row], new_good_trials$ar_target[row]) , ])))[2]
}

ar_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(ar_final[ , c("ar_cue", "ar_target")]))

# check cosines
tapply(ar_final$ar_cosine, ar_final$type, mean, na.rm = T)
tapply(ar_final$ar_cosine, ar_final$type, min, na.rm = T)
tapply(ar_final$ar_cosine, ar_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- ar_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(ar_target) %>% 
  filter(n != 2)

weird_trials <- ar_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(ar_target %in% target_table$ar_target)

# check for NA
sum(is.na(ar_final$ar_cue))
sum(is.na(ar_final$ar_target))
sum(grepl("^NA", ar_final$ar_cue))
sum(grepl("^NA", ar_final$ar_target))

# check rows
nrow(ar_final)
table(ar_final$type, ar_final$cue_type, ar_final$target_type)

ar_final$ok <- NULL

export(ar_final, "ar/ar_trials_final.csv")
```

## fa Farsi NEED NEW WORDS  

```{r eval = F}
# original words
fa <- import("fa/fa_translate.csv")
fa$en_cue <- gsub("digusting", "disgusting", fa$en_cue)

# fix real words ----
fa_update <- import("fa/fa_translate.xlsx") %>% 
  mutate(across(everything(), tolower))

# fix cue words ----
cues <- fa_update %>% filter(fa_cue_trans != "")
for (i in 1:nrow(cues)){
  fa$fa_cue[fa$fa_cue == cues$fa_cue[i] #original cue match
            & fa$en_cue == cues$en_cue[i]] <- #english match
    cues$fa_cue_trans[i] #new cue
}

targets <- fa_update %>% filter(fa_target_trans != "")
for (i in 1:nrow(targets)){
  fa$fa_target[fa$fa_target == targets$fa_target[i] #original target match
            & fa$en_target == targets$en_target[i]] <- #english match
    targets$fa_target_trans[i] #new target
}

# fix fake words ----
cues <- fa_update %>% filter(fa_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  fa$fa_fake_cue[fa$fa_fake_cue == cues$fa_fake_cue[i] #original cue match
            & fa$en_cue == cues$en_cue[i]] <- #english match
    cues$fa_fake_cue_trans[i] #new cue
}

targets <- fa_update %>% filter(fa_fake_target_trans != "")
for (i in 1:nrow(targets)){
  fa$fa_fake_target[fa$fa_fake_target == targets$fa_fake_target[i] #original target match
            & fa$en_target == targets$en_target[i]] <- #english match
    targets$fa_fake_target_trans[i] #new target
}

sum(duplicated(fa$fa_cue))
sum(duplicated(fa$fa_target))
sum(duplicated(fa$fa_fake_cue))
sum(duplicated(fa$fa_fake_target))

nrow(fa %>% filter(fa_cue == fa_target))

export(fi, "../matched_stimuli/fa_matched.csv", row.names = F)

# create possible trials ----
fa_trials <- fi[ , c("fa_cue", "fa_target")]
fa_trials$type <- "related"
fa_trials$cue_type <- "word"
fa_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
fa$en_cue <- tolower(fa$en_cue)
fa$en_target <- tolower(fa$en_target)
# match unrelated pairs as a start 
fa_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(fa_unrelated)){
  fa_unrelated$en_cue[i] <- fa$fa_cue[fa$en_cue == fa_unrelated$en_cue[i]]
  fa_unrelated$en_target[i] <- fa$fa_target[fa$en_target == fa_unrelated$en_target[i]]
}

fa_trials <- rbind(fa_trials,
                   fa_unrelated %>% select(-en_cosine) %>% 
                     rename("fa_cue" = "en_cue", 
                            "fa_target" = "en_target"), 
                   data.frame(fa_cue = fa$fa_fake_cue,
                              fa_target = fa$fa_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(fa_cue = fa$fa_cue[sample(1:1000,
                                                        1000)],
                              fa_target = fa$fa_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(fa_cue = fa$fa_fake_cue[sample(1:1000,
                                                        1000)],
                              fa_target = fa$fa_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(fa_trials[ , c("fa_cue", "fa_target")]))

# update with low cosines from random shuffle ----
# set up model
fa_model <- read.table("/Volumes/SPAML Backup/subs_vec/fa_br/subs.pt.1e6.txt", quote="\"")
fa_model <- na.omit(fa_model)
fa_model$V1 <- tolower(fa_model$V1)
fa_model <- fa_model[!duplicated(fa_model$V1), ]
rownames(fa_model) <- fa_model$V1
fa_model <- fa_model[ , -1]

fa_trials$fa_cosine <- NA

# get cosine
for (row in 1:nrow(fa_trials)){
  
  if(fa_trials$type[row] != "nonword") { 
    
    fa_trials$fa_cosine[row] <- cosine(as.matrix(t(fa_model[
    c(fa_trials$fa_cue[row], fa_trials$fa_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
fa_trials$ok <- TRUE
fa_trials$ok[fa_trials$type == "unrelated" & abs(fa_trials$fa_cosine) > .15] <- FALSE

good_trials <- fa_trials %>% filter(ok == TRUE)
bad_trials <- fa_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$fa_target <- sample(bad_trials$fa_target, 
                               size = length(bad_trials$fa_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$fa_cosine[row] <- cosine(as.matrix(t(fa_model[
    c(bad_trials$fa_cue[row], bad_trials$fa_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(fa_cosine < .15)))
bad_trials <- bad_trials %>% filter(fa_cosine >= .15)
nrow(bad_trials)
# ran section I ran multiple times 

whats_left <- cosine(as.matrix(t(fa_model[c(
  bad_trials$fa_target,
  unique(good_trials$fa_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$fa_target)){
  
  # find all words that could be paired with bad fa_target
  # as updated fa_cue
  potrutial_cues <- rownames(whats_left)[whats_left[ , bad_trials$fa_target[i]] < .15] 
  
  # find all pairs of good fa_target that could
  # be paired with bad fa_cue
  potrutial_switch <- good_trials %>% filter(fa_cue %in% potrutial_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(fa_model[c(
    bad_trials$fa_cue[i],
    potrutial_switch$fa_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$fa_cue[i], bad_trials$fa_target[i],
    potrutial_switch$fa_cue[potrutial_switch$fa_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_fa_cue", "bad_fa_target", 
                           "good_fa_cue", "good_fa_target")

good_trials_small <- good_trials %>% 
  filter(!(fa_cue %in% switch_todo$good_fa_cue & type == "unrelated"))

new_good_trials <- data.frame(
  fa_cue = c(switch_todo$bad_fa_cue, switch_todo$good_fa_cue),
  fa_target = c(switch_todo$good_fa_target, switch_todo$bad_fa_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  fa_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$fa_cosine[row] <- cosine(as.matrix(t(fa_model[
    c(new_good_trials$fa_cue[row], new_good_trials$fa_target[row]) , ])))[2]
}

fa_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(fa_final[ , c("fa_cue", "fa_target")]))

# check cosines
tapply(fa_final$fa_cosine, fa_final$type, mean, na.rm = T)
tapply(fa_final$fa_cosine, fa_final$type, min, na.rm = T)
tapply(fa_final$fa_cosine, fa_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- fa_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(fa_target) %>% 
  filter(n != 2)

weird_trials <- fa_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(fa_target %in% target_table$fa_target)

# check for NA
sum(is.na(fa_final$fa_cue))
sum(is.na(fa_final$fa_target))
sum(grepl("^NA", fa_final$fa_cue))
sum(grepl("^NA", fa_final$fa_target))

# check rows
nrow(fa_final)
table(fa_final$type, fa_final$cue_type, fa_final$target_type)

fa_final$ok <- NULL

export(fa_final, "fa_br/fa_trials_final.csv")
```

## fi Finnish

```{r eval = F}
# original words
fi <- import("fi/fi_translate.csv")
fi$en_cue <- gsub("digusting", "disgusting", fi$en_cue)

# fix real words ----
fi_update <- import("fi/fi_translate_TS2022_04_29.xlsx") %>% 
  mutate(across(everything(), tolower))

# fix cue words ----
cues <- fi_update %>% filter(fi_cue_trans != "")
for (i in 1:nrow(cues)){
  fi$fi_cue[fi$fi_cue == cues$fi_cue[i] #original cue match
            & fi$en_cue == cues$en_cue[i]] <- #english match
    cues$fi_cue_trans[i] #new cue
}

targets <- fi_update %>% filter(fi_target_trans != "")
for (i in 1:nrow(targets)){
  fi$fi_target[fi$fi_target == targets$fi_target[i] #original target match
            & fi$en_target == targets$en_target[i]] <- #english match
    targets$fi_target_trans[i] #new target
}

# fix fake words ----
cues <- fi_update %>% filter(fi_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  fi$fi_fake_cue[fi$fi_fake_cue == cues$fi_fake_cue[i] #original cue match
            & fi$en_cue == cues$en_cue[i]] <- #english match
    cues$fi_fake_cue_trans[i] #new cue
}

targets <- fi_update %>% filter(fi_fake_target_trans != "")
for (i in 1:nrow(targets)){
  fi$fi_fake_target[fi$fi_fake_target == targets$fi_fake_target[i] #original target match
            & fi$en_target == targets$en_target[i]] <- #english match
    targets$fi_fake_target_trans[i] #new target
}

sum(duplicated(fi$fi_cue))
sum(duplicated(fi$fi_target))
sum(duplicated(fi$fi_fake_cue))
sum(duplicated(fi$fi_fake_target))

nrow(fi %>% filter(fi_cue == fi_target))

export(fi, "../matched_stimuli/fi_matched.csv", row.names = F)

# create possible trials ----
fi_trials <- fi[ , c("fi_cue", "fi_target")]
fi_trials$type <- "related"
fi_trials$cue_type <- "word"
fi_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
fi$en_cue <- tolower(fi$en_cue)
fi$en_target <- tolower(fi$en_target)
# match unrelated pairs as a start 
fi_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(fi_unrelated)){
  fi_unrelated$en_cue[i] <- fi$fi_cue[fi$en_cue == fi_unrelated$en_cue[i]]
  fi_unrelated$en_target[i] <- fi$fi_target[fi$en_target == fi_unrelated$en_target[i]]
}

fi_trials <- rbind(fi_trials,
                   fi_unrelated %>% select(-en_cosine) %>% 
                     rename("fi_cue" = "en_cue", 
                            "fi_target" = "en_target"), 
                   data.frame(fi_cue = fi$fi_fake_cue,
                              fi_target = fi$fi_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(fi_cue = fi$fi_cue[sample(1:1000,
                                                        1000)],
                              fi_target = fi$fi_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(fi_cue = fi$fi_fake_cue[sample(1:1000,
                                                        1000)],
                              fi_target = fi$fi_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(fi_trials[ , c("fi_cue", "fi_target")]))

# update with low cosines from random shuffle ----
# set up model
fi_model <- read.table("/Volumes/SPAML Backup/subs_vec/fi/subs.fi.1e6.txt", quote="\"")
fi_model <- na.omit(fi_model)
fi_model$V1 <- tolower(fi_model$V1)
fi_model <- fi_model[!duplicated(fi_model$V1), ]
rownames(fi_model) <- fi_model$V1
fi_model <- fi_model[ , -1]

fi_trials$fi_cosine <- NA

# get cosine
for (row in 1:nrow(fi_trials)){
  
  if(fi_trials$type[row] != "nonword") { 
    
    fi_trials$fi_cosine[row] <- cosine(as.matrix(t(fi_model[
    c(fi_trials$fi_cue[row], fi_trials$fi_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
fi_trials$ok <- TRUE
fi_trials$ok[fi_trials$type == "unrelated" & abs(fi_trials$fi_cosine) > .15] <- FALSE

good_trials <- fi_trials %>% filter(ok == TRUE)
bad_trials <- fi_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$fi_target <- sample(bad_trials$fi_target, 
                               size = length(bad_trials$fi_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$fi_cosine[row] <- cosine(as.matrix(t(fi_model[
    c(bad_trials$fi_cue[row], bad_trials$fi_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(fi_cosine < .15)))
bad_trials <- bad_trials %>% filter(fi_cosine >= .15)
nrow(bad_trials)
# this section I ran multiple times 

whats_left <- cosine(as.matrix(t(fi_model[c(
  bad_trials$fi_target,
  unique(good_trials$fi_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$fi_target)){
  
  # find all words that could be paired with bad fi_target
  # as updated fi_cue
  potrutial_cues <- rownames(whats_left)[whats_left[ , bad_trials$fi_target[i]] < .15] 
  
  # find all pairs of good fi_target that could
  # be paired with bad fi_cue
  potrutial_switch <- good_trials %>% filter(fi_cue %in% potrutial_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(fi_model[c(
    bad_trials$fi_cue[i],
    potrutial_switch$fi_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$fi_cue[i], bad_trials$fi_target[i],
    potrutial_switch$fi_cue[potrutial_switch$fi_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_fi_cue", "bad_fi_target", 
                           "good_fi_cue", "good_fi_target")

good_trials_small <- good_trials %>% 
  filter(!(fi_cue %in% switch_todo$good_fi_cue & type == "unrelated"))

new_good_trials <- data.frame(
  fi_cue = c(switch_todo$bad_fi_cue, switch_todo$good_fi_cue),
  fi_target = c(switch_todo$good_fi_target, switch_todo$bad_fi_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  fi_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$fi_cosine[row] <- cosine(as.matrix(t(fi_model[
    c(new_good_trials$fi_cue[row], new_good_trials$fi_target[row]) , ])))[2]
}

fi_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(fi_final[ , c("fi_cue", "fi_target")]))

# check cosines
tapply(fi_final$fi_cosine, fi_final$type, mean, na.rm = T)
tapply(fi_final$fi_cosine, fi_final$type, min, na.rm = T)
tapply(fi_final$fi_cosine, fi_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- fi_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(fi_target) %>% 
  filter(n != 2)

weird_trials <- fi_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(fi_target %in% target_table$fi_target)

# check for NA
sum(is.na(fi_final$fi_cue))
sum(is.na(fi_final$fi_target))
sum(grepl("^NA", fi_final$fi_cue))
sum(grepl("^NA", fi_final$fi_target))

# check rows
nrow(fi_final)
table(fi_final$type, fi_final$cue_type, fi_final$target_type)

fi_final$ok <- NULL

export(fi_final, "fi/fi_trials_final.csv")
```

## fr French 

```{r eval = F}
# they formatted it nicely  ----
fr <- import("fr/fr_translate_final.csv") %>% 
  mutate(across(everything(), tolower))
fr$en_cue <- gsub("digusting", "disgusting", fr$en_cue)

sum(duplicated(fr$fr_cue))
sum(duplicated(fr$fr_target))
sum(duplicated(fr$fr_fake_cue))
sum(duplicated(fr$fr_fake_target))

nrow(fr %>% filter(fr_cue == fr_target))

export(fr, "../matched_stimuli/fr_matched.csv", row.names = F)

# create possible trials ----
fr_trials <- fr[ , c("fr_cue", "fr_target")]
fr_trials$type <- "related"
fr_trials$cue_type <- "word"
fr_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
fr$en_cue <- tolower(fr$en_cue)
fr$en_target <- tolower(fr$en_target)
# match unrelated pairs as a start 
fr_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(fr_unrelated)){
  fr_unrelated$en_cue[i] <- fr$fr_cue[fr$en_cue == fr_unrelated$en_cue[i]]
  fr_unrelated$en_target[i] <- fr$fr_target[fr$en_target == fr_unrelated$en_target[i]]
}

fr_trials <- rbind(fr_trials,
                   fr_unrelated %>% select(-en_cosine) %>% 
                     rename("fr_cue" = "en_cue", 
                            "fr_target" = "en_target"), 
                   data.frame(fr_cue = fr$fr_fake_cue,
                              fr_target = fr$fr_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(fr_cue = fr$fr_cue[sample(1:1000,
                                                        1000)],
                              fr_target = fr$fr_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(fr_cue = fr$fr_fake_cue[sample(1:1000,
                                                        1000)],
                              fr_target = fr$fr_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(fr_trials[ , c("fr_cue", "fr_target")]))

# update with low cosines from random shuffle ----
# set up model
fr_model <- read.table("/Volumes/SPAML Backup/subs_vec/fr/subs.fr.1e6.txt", quote="\"")
fr_model <- na.omit(fr_model)
fr_model$V1 <- tolower(fr_model$V1)
fr_model <- fr_model[!duplicated(fr_model$V1), ]
rownames(fr_model) <- fr_model$V1
fr_model <- fr_model[ , -1]

fr_trials$fr_cosine <- NA

# get cosine
for (row in 1:nrow(fr_trials)){
  
  if(fr_trials$type[row] != "nonword") { 
    
    fr_trials$fr_cosine[row] <- cosine(as.matrix(t(fr_model[
    c(fr_trials$fr_cue[row], fr_trials$fr_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
fr_trials$ok <- TRUE
fr_trials$ok[fr_trials$type == "unrelated" & abs(fr_trials$fr_cosine) > .15] <- FALSE

good_trials <- fr_trials %>% filter(ok == TRUE)
bad_trials <- fr_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$fr_target <- sample(bad_trials$fr_target, 
                               size = length(bad_trials$fr_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$fr_cosine[row] <- cosine(as.matrix(t(fr_model[
    c(bad_trials$fr_cue[row], bad_trials$fr_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(fr_cosine < .15)))
bad_trials <- bad_trials %>% filter(fr_cosine >= .15)
nrow(bad_trials)
# this section I ran multiple times 

whats_left <- cosine(as.matrix(t(fr_model[c(
  bad_trials$fr_target,
  unique(good_trials$fr_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$fr_target)){
  
  # find all words that could be paired with bad fr_target
  # as updated fr_cue
  potrutial_cues <- rownames(whats_left)[whats_left[ , bad_trials$fr_target[i]] < .15] 
  
  # find all pairs of good fr_target that could
  # be paired with bad fr_cue
  potrutial_switch <- good_trials %>% filter(fr_cue %in% potrutial_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(fr_model[c(
    bad_trials$fr_cue[i],
    potrutial_switch$fr_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$fr_cue[i], bad_trials$fr_target[i],
    potrutial_switch$fr_cue[potrutial_switch$fr_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_fr_cue", "bad_fr_target", 
                           "good_fr_cue", "good_fr_target")

good_trials_small <- good_trials %>% 
  filter(!(fr_cue %in% switch_todo$good_fr_cue & type == "unrelated"))

new_good_trials <- data.frame(
  fr_cue = c(switch_todo$bad_fr_cue, switch_todo$good_fr_cue),
  fr_target = c(switch_todo$good_fr_target, switch_todo$bad_fr_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  fr_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$fr_cosine[row] <- cosine(as.matrix(t(fr_model[
    c(new_good_trials$fr_cue[row], new_good_trials$fr_target[row]) , ])))[2]
}

fr_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(fr_final[ , c("fr_cue", "fr_target")]))

# check cosines
tapply(fr_final$fr_cosine, fr_final$type, mean, na.rm = T)
tapply(fr_final$fr_cosine, fr_final$type, min, na.rm = T)
tapply(fr_final$fr_cosine, fr_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- fr_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(fr_target) %>% 
  filter(n != 2)

weird_trials <- fr_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(fr_target %in% target_table$fr_target)

# check for NA
sum(is.na(fr_final$fr_cue))
sum(is.na(fr_final$fr_target))
sum(grepl("^NA", fr_final$fr_cue))
sum(grepl("^NA", fr_final$fr_target))

# check rows
nrow(fr_final)
table(fr_final$type, fr_final$cue_type, fr_final$target_type)

fr_final$ok <- NULL

export(fr_final, "fr/fr_trials_final.csv")
```

## el Greek

```{r eval = F}
# original words
el <- import("el/el_translate.csv")
el$en_cue <- gsub("digusting", "disgusting", el$en_cue)

# fix real words ----
el_update <- import("el/el_translate_final.xlsx") %>% 
  mutate(across(everything(), tolower))

# fix cue words ----
cues <- el_update %>% filter(el_cue_trans != "")
for (i in 1:nrow(cues)){
  el$el_cue[el$el_cue == cues$el_cue[i] #original cue match
            & el$en_cue == cues$en_cue[i]] <- #english match
    cues$el_cue_trans[i] #new cue
}

targets <- el_update %>% filter(el_target_trans != "")
for (i in 1:nrow(targets)){
  el$el_target[el$el_target == targets$el_target[i] #original target match
            & el$en_target == targets$en_target[i]] <- #english match
    targets$el_target_trans[i] #new target
}

# fix fake words ----
cues <- el_update %>% filter(el_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  el$el_fake_cue[el$el_fake_cue == cues$el_fake_cue[i] #original cue match
            & el$en_cue == cues$en_cue[i]] <- #english match
    cues$el_fake_cue_trans[i] #new cue
}

targets <- el_update %>% filter(el_fake_target_trans != "")
for (i in 1:nrow(targets)){
  el$el_fake_target[el$el_fake_target == targets$el_fake_target[i] #original target match
            & el$en_target == targets$en_target[i]] <- #english match
    targets$el_fake_target_trans[i] #new target
}

sum(duplicated(el$el_cue))
sum(duplicated(el$el_target))
sum(duplicated(el$el_fake_cue))
sum(duplicated(el$el_fake_target))

nrow(el %>% filter(el_cue == el_target))

export(el, "../matched_stimuli/el_matched.csv", row.names = F)

# create possible trials ----
el_trials <- el[ , c("el_cue", "el_target")]
el_trials$type <- "related"
el_trials$cue_type <- "word"
el_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
el$en_cue <- tolower(el$en_cue)
el$en_target <- tolower(el$en_target)
# match unrelated pairs as a start 
el_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(el_unrelated)){
  el_unrelated$en_cue[i] <- el$el_cue[el$en_cue == el_unrelated$en_cue[i]]
  el_unrelated$en_target[i] <- el$el_target[el$en_target == el_unrelated$en_target[i]]
}

el_trials <- rbind(el_trials,
                   el_unrelated %>% select(-en_cosine) %>% 
                     rename("el_cue" = "en_cue", 
                            "el_target" = "en_target"), 
                   data.frame(el_cue = el$el_fake_cue,
                              el_target = el$el_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(el_cue = el$el_cue[sample(1:1000,
                                                        1000)],
                              el_target = el$el_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(el_cue = el$el_fake_cue[sample(1:1000,
                                                        1000)],
                              el_target = el$el_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(el_trials[ , c("el_cue", "el_target")]))

# update with low cosines from random shuffle ----
# set up model
el_model <- read.table("/Volumes/SPAML Backup/subs_vec/el/subs.el.1e6.txt", quote="\"")
el_model <- na.omit(el_model)
el_model$V1 <- tolower(el_model$V1)
el_model <- el_model[!duplicated(el_model$V1), ]
rownames(el_model) <- el_model$V1
el_model <- el_model[ , -1]

el_trials$el_cosine <- NA

# get cosine
for (row in 1:nrow(el_trials)){
  
  if(el_trials$type[row] != "nonword") { 
    
    el_trials$el_cosine[row] <- cosine(as.matrix(t(el_model[
    c(el_trials$el_cue[row], el_trials$el_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
el_trials$ok <- TRUE
el_trials$ok[el_trials$type == "unrelated" & abs(el_trials$el_cosine) > .15] <- FALSE

good_trials <- el_trials %>% filter(ok == TRUE)
bad_trials <- el_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$el_target <- sample(bad_trials$el_target, 
                               size = length(bad_trials$el_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$el_cosine[row] <- cosine(as.matrix(t(el_model[
    c(bad_trials$el_cue[row], bad_trials$el_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(el_cosine < .15)))
bad_trials <- bad_trials %>% filter(el_cosine >= .15)
nrow(bad_trials)
# ran section I ran multiple times 

whats_left <- cosine(as.matrix(t(el_model[c(
  bad_trials$el_target,
  unique(good_trials$el_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$el_target)){
  
  # find all words that could be paired with bad el_target
  # as updated el_cue
  potrutial_cues <- rownames(whats_left)[whats_left[ , bad_trials$el_target[i]] < .15] 
  
  # find all pairs of good el_target that could
  # be paired with bad el_cue
  potrutial_switch <- good_trials %>% filter(el_cue %in% potrutial_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(el_model[c(
    bad_trials$el_cue[i],
    potrutial_switch$el_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$el_cue[i], bad_trials$el_target[i],
    potrutial_switch$el_cue[potrutial_switch$el_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_el_cue", "bad_el_target", 
                           "good_el_cue", "good_el_target")

good_trials_small <- good_trials %>% 
  filter(!(el_cue %in% switch_todo$good_el_cue & type == "unrelated"))

new_good_trials <- data.frame(
  el_cue = c(switch_todo$bad_el_cue, switch_todo$good_el_cue),
  el_target = c(switch_todo$good_el_target, switch_todo$bad_el_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  el_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$el_cosine[row] <- cosine(as.matrix(t(el_model[
    c(new_good_trials$el_cue[row], new_good_trials$el_target[row]) , ])))[2]
}

el_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(el_final[ , c("el_cue", "el_target")]))

# check cosines
tapply(el_final$el_cosine, el_final$type, mean, na.rm = T)
tapply(el_final$el_cosine, el_final$type, min, na.rm = T)
tapply(el_final$el_cosine, el_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- el_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(el_target) %>% 
  filter(n != 2)

weird_trials <- el_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(el_target %in% target_table$el_target)

# check for NA
sum(is.na(el_final$el_cue))
sum(is.na(el_final$el_target))
sum(grepl("^NA", el_final$el_cue))
sum(grepl("^NA", el_final$el_target))

# check rows
nrow(el_final)
table(el_final$type, el_final$cue_type, el_final$target_type)

el_final$ok <- NULL

export(el_final, "el/el_trials_final.csv")
```

## he Hebrew TO DO 

```{r eval = F}
# original words
he <- import("he/he_translate.csv")
he$en_cue <- gsub("digusting", "disgusting", he$en_cue)

# fix real words ----
he_update <- import("he/he_translate2 SPAML Apr 2022.xlsx") %>% 
  mutate(across(everything(), tolower))

# fix cue words ----
cues <- he_update %>% filter(he_cue_trans != "")
for (i in 1:nrow(cues)){
  he$he_cue[he$he_cue == cues$he_cue[i] #original cue match
            & he$en_cue == cues$en_cue[i]] <- #english match
    cues$he_cue_trans[i] #new cue
}

targets <- he_update %>% filter(he_target_trans != "")
for (i in 1:nrow(targets)){
  he$he_target[he$he_target == targets$he_target[i] #original target match
            & he$en_target == targets$en_target[i]] <- #english match
    targets$he_target_trans[i] #new target
}

# fix fake words ----
cues <- he_update %>% filter(he_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  he$he_fake_cue[he$he_fake_cue == cues$he_fake_cue[i] #original cue match
            & he$en_cue == cues$en_cue[i]] <- #english match
    cues$he_fake_cue_trans[i] #new cue
}

targets <- he_update %>% filter(he_fake_target_trans != "")
for (i in 1:nrow(targets)){
  he$he_fake_target[he$he_fake_target == targets$he_fake_target[i] #original target match
            & he$en_target == targets$en_target[i]] <- #english match
    targets$he_fake_target_trans[i] #new target
}

sum(duplicated(he$he_cue))
sum(duplicated(he$he_target))
sum(duplicated(he$he_fake_cue))
sum(duplicated(he$he_fake_target))

nrow(he %>% filter(he_cue == he_target))

export(he, "../matched_stimuli/he_matched.csv", row.names = F)

# create possible trials ----
he_trials <- ur[ , c("he_cue", "he_target")]
he_trials$type <- "related"
he_trials$cue_type <- "word"
he_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
he$en_cue <- tolower(he$en_cue)
he$en_target <- tolower(he$en_target)
# match unrelated pairs as a start 
he_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(he_unrelated)){
  he_unrelated$en_cue[i] <- he$he_cue[he$en_cue == he_unrelated$en_cue[i]]
  he_unrelated$en_target[i] <- he$he_target[he$en_target == he_unrelated$en_target[i]]
}

he_trials <- rbind(he_trials,
                   he_unrelated %>% select(-en_cosine) %>% 
                     rename("he_cue" = "en_cue", 
                            "he_target" = "en_target"), 
                   data.frame(he_cue = he$he_fake_cue,
                              he_target = he$he_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(he_cue = he$he_cue[sample(1:1000,
                                                        1000)],
                              he_target = he$he_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(he_cue = he$he_fake_cue[sample(1:1000,
                                                        1000)],
                              he_target = he$he_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(he_trials[ , c("he_cue", "he_target")]))

# update with low cosines from random shuffle ----
# set up model
he_model <- read.table("/Volumes/SPAML Backup/wiki_vec/he/wiki.ur.1e6.txt", quote="\"")
he_model <- na.omit(he_model)
he_model$V1 <- tolower(he_model$V1)
he_model <- he_model[!duplicated(he_model$V1), ]
rownames(he_model) <- he_model$V1
he_model <- he_model[ , -1]

he_trials$he_cosine <- NA

# get cosine
for (row in 1:nrow(he_trials)){
  
  if(he_trials$type[row] != "nonword") { 
    
    he_trials$he_cosine[row] <- cosine(as.matrix(t(he_model[
    c(he_trials$he_cue[row], he_trials$he_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
he_trials$ok <- TRUE
he_trials$ok[he_trials$type == "unrelated" & abs(he_trials$he_cosine) > .15] <- FALSE

good_trials <- he_trials %>% filter(ok == TRUE)
bad_trials <- he_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$he_target <- sample(bad_trials$he_target, 
                               size = length(bad_trials$he_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$he_cosine[row] <- cosine(as.matrix(t(he_model[
    c(bad_trials$he_cue[row], bad_trials$he_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(he_cosine < .15)))
bad_trials <- bad_trials %>% filter(he_cosine >= .15)
nrow(bad_trials)
# this section I ran multiple times 

whats_left <- cosine(as.matrix(t(he_model[c(
  bad_trials$he_target,
  unique(good_trials$he_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$he_target)){
  
  # find all words that could be paired with bad he_target
  # as updated he_cue
  potrutial_cues <- rownames(whats_left)[whats_left[ , bad_trials$he_target[i]] < .15] 
  
  # find all pairs of good he_target that could
  # be paired with bad he_cue
  potrutial_switch <- good_trials %>% filter(he_cue %in% potrutial_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(he_model[c(
    bad_trials$he_cue[i],
    potrutial_switch$he_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$he_cue[i], bad_trials$he_target[i],
    potrutial_switch$he_cue[potrutial_switch$he_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_he_cue", "bad_he_target", 
                           "good_he_cue", "good_he_target")

good_trials_small <- good_trials %>% 
  filter(!(he_cue %in% switch_todo$good_he_cue & type == "unrelated"))

new_good_trials <- data.frame(
  he_cue = c(switch_todo$bad_he_cue, switch_todo$good_he_cue),
  he_target = c(switch_todo$good_he_target, switch_todo$bad_he_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  he_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$he_cosine[row] <- cosine(as.matrix(t(he_model[
    c(new_good_trials$he_cue[row], new_good_trials$he_target[row]) , ])))[2]
}

he_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(he_final[ , c("he_cue", "he_target")]))

# check cosines
tapply(he_final$he_cosine, he_final$type, mean, na.rm = T)
tapply(he_final$he_cosine, he_final$type, min, na.rm = T)
tapply(he_final$he_cosine, he_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- he_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(he_target) %>% 
  filter(n != 2)

weird_trials <- he_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(he_target %in% target_table$he_target)

# drop extra
he_final <- he_final %>% 
  filter(!(he_cue == "پرخطر" & he_target == "لکھیں"))

# check for NA
sum(is.na(he_final$he_cue))
sum(is.na(he_final$he_target))
sum(grepl("^NA", he_final$he_cue))
sum(grepl("^NA", he_final$he_target))

# check rows
nrow(he_final)
table(he_final$type, he_final$cue_type, he_final$target_type)

he_final$ok <- NULL

export(he_final, "he/he_trials_final.csv")
```


## hi Hindi NEED WORDS  

## hu Hungarian FIX DUPLICATES

```{r eval = F}
# original words
hu <- import("hu/hu_translate.csv")
hu$en_cue <- gsub("digusting", "disgusting", hu$en_cue)

# fix real words ----
hu_update <- import("hu/hu_translate.xlsx") %>% 
  mutate(across(everything(), tolower))

# fix cue words ----
cues <- hu_update %>% filter(hu_cue_trans != "")
for (i in 1:nrow(cues)){
  hu$hu_cue[hu$hu_cue == cues$hu_cue[i] #original cue match
            & hu$en_cue == cues$en_cue[i]] <- #english match
    cues$hu_cue_trans[i] #new cue
}

targets <- hu_update %>% filter(hu_target_trans != "")
for (i in 1:nrow(targets)){
  hu$hu_target[hu$hu_target == targets$hu_target[i] #original target match
            & hu$en_target == targets$en_target[i]] <- #english match
    targets$hu_target_trans[i] #new target
}

# fix fake words ----
cues <- hu_update %>% filter(hu_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  hu$hu_fake_cue[hu$hu_fake_cue == cues$hu_fake_cue[i] #original cue match
            & hu$en_cue == cues$en_cue[i]] <- #english match
    cues$hu_fake_cue_trans[i] #new cue
}

targets <- hu_update %>% filter(hu_fake_target_trans != "")
for (i in 1:nrow(targets)){
  hu$hu_fake_target[hu$hu_fake_target == targets$hu_fake_target[i] #original target match
            & hu$en_target == targets$en_target[i]] <- #english match
    targets$hu_fake_target_trans[i] #new target
}

sum(duplicated(hu$hu_cue))
sum(duplicated(hu$hu_target))
sum(duplicated(hu$hu_fake_cue))
sum(duplicated(hu$hu_fake_target))

nrow(hu %>% filter(hu_cue == hu_target))

export(ur, "../matched_stimuli/hu_matched.csv", row.names = F)

# create possible trials ----
hu_trials <- hu[ , c("hu_cue", "hu_target")]
hu_trials$type <- "related"
hu_trials$cue_type <- "word"
hu_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
hu$en_cue <- tolower(hu$en_cue)
hu$en_target <- tolower(hu$en_target)
# match unrelated pairs as a start 
hu_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(hu_unrelated)){
  hu_unrelated$en_cue[i] <- hu$hu_cue[hu$en_cue == hu_unrelated$en_cue[i]]
  hu_unrelated$en_target[i] <- hu$hu_target[hu$en_target == hu_unrelated$en_target[i]]
}

hu_trials <- rbind(hu_trials,
                   hu_unrelated %>% select(-en_cosine) %>% 
                     rename("hu_cue" = "en_cue", 
                            "hu_target" = "en_target"), 
                   data.frame(hu_cue = hu$hu_fake_cue,
                              hu_target = hu$hu_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(hu_cue = hu$hu_cue[sample(1:1000,
                                                        1000)],
                              hu_target = hu$hu_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(hu_cue = hu$hu_fake_cue[sample(1:1000,
                                                        1000)],
                              hu_target = hu$hu_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(hu_trials[ , c("hu_cue", "hu_target")]))

# update with low cosines from random shuffle ----
# set up model
hu_model <- read.table("/Volumes/SPAML Backup/subs_vec/hu_br/subs.pt.1e6.txt", quote="\"")
hu_model <- na.omit(hu_model)
hu_model$V1 <- tolower(hu_model$V1)
hu_model <- hu_model[!duplicated(hu_model$V1), ]
rownames(hu_model) <- hu_model$V1
hu_model <- hu_model[ , -1]

hu_trials$hu_cosine <- NA

# get cosine
for (row in 1:nrow(hu_trials)){
  
  if(hu_trials$type[row] != "nonword") { 
    
    hu_trials$hu_cosine[row] <- cosine(as.matrix(t(hu_model[
    c(hu_trials$hu_cue[row], hu_trials$hu_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
hu_trials$ok <- TRUE
hu_trials$ok[hu_trials$type == "unrelated" & abs(hu_trials$hu_cosine) > .15] <- FALSE

good_trials <- hu_trials %>% filter(ok == TRUE)
bad_trials <- hu_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$hu_target <- sample(bad_trials$hu_target, 
                               size = length(bad_trials$hu_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$hu_cosine[row] <- cosine(as.matrix(t(hu_model[
    c(bad_trials$hu_cue[row], bad_trials$hu_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(hu_cosine < .15)))
bad_trials <- bad_trials %>% filter(hu_cosine >= .15)
nrow(bad_trials)
# ran section I ran multiple times 

whats_left <- cosine(as.matrix(t(hu_model[c(
  bad_trials$hu_target,
  unique(good_trials$hu_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$hu_target)){
  
  # find all words that could be paired with bad hu_target
  # as updated hu_cue
  potrutial_cues <- rownames(whats_left)[whats_left[ , bad_trials$hu_target[i]] < .15] 
  
  # find all pairs of good hu_target that could
  # be paired with bad hu_cue
  potrutial_switch <- good_trials %>% filter(hu_cue %in% potrutial_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(hu_model[c(
    bad_trials$hu_cue[i],
    potrutial_switch$hu_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$hu_cue[i], bad_trials$hu_target[i],
    potrutial_switch$hu_cue[potrutial_switch$hu_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_hu_cue", "bad_hu_target", 
                           "good_hu_cue", "good_hu_target")

good_trials_small <- good_trials %>% 
  filter(!(hu_cue %in% switch_todo$good_hu_cue & type == "unrelated"))

new_good_trials <- data.frame(
  hu_cue = c(switch_todo$bad_hu_cue, switch_todo$good_hu_cue),
  hu_target = c(switch_todo$good_hu_target, switch_todo$bad_hu_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  hu_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$hu_cosine[row] <- cosine(as.matrix(t(hu_model[
    c(new_good_trials$hu_cue[row], new_good_trials$hu_target[row]) , ])))[2]
}

hu_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(hu_final[ , c("hu_cue", "hu_target")]))

# check cosines
tapply(hu_final$hu_cosine, hu_final$type, mean, na.rm = T)
tapply(hu_final$hu_cosine, hu_final$type, min, na.rm = T)
tapply(hu_final$hu_cosine, hu_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- hu_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(hu_target) %>% 
  filter(n != 2)

weird_trials <- hu_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(hu_target %in% target_table$hu_target)

# check for NA
sum(is.na(hu_final$hu_cue))
sum(is.na(hu_final$hu_target))
sum(grepl("^NA", hu_final$hu_cue))
sum(grepl("^NA", hu_final$hu_target))

# check rows
nrow(hu_final)
table(hu_final$type, hu_final$cue_type, hu_final$target_type)

hu_final$ok <- NULL

export(hu_final, "hu_br/hu_trials_final.csv")
```

## zh Simplified Chinese NEED FINAL

## zh Traditional Chinese NEED FINAL

## pt Portuguese COSINE 

```{r eval = F}
# original words
pt <- import("pt/pt_translate.csv")
pt$en_cue <- gsub("digusting", "disgusting", pt$en_cue)

# fix real words ----
pt_update <- import("pt/pt_translate_Revised.xlsx") %>% 
  mutate(across(everything(), tolower))

# fix cue words ----
cues <- pt_update %>% filter(pt_cue_trans != "")
for (i in 1:nrow(cues)){
  pt$pt_cue[pt$pt_cue == cues$pt_cue[i] #original cue match
            & pt$en_cue == cues$en_cue[i]] <- #english match
    cues$pt_cue_trans[i] #new cue
}

targets <- pt_update %>% filter(pt_target_trans != "")
for (i in 1:nrow(targets)){
  pt$pt_target[pt$pt_target == targets$pt_target[i] #original target match
            & pt$en_target == targets$en_target[i]] <- #english match
    targets$pt_target_trans[i] #new target
}

# fix fake words ----
cues <- pt_update %>% filter(pt_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  pt$pt_fake_cue[pt$pt_fake_cue == cues$pt_fake_cue[i] #original cue match
            & pt$en_cue == cues$en_cue[i]] <- #english match
    cues$pt_fake_cue_trans[i] #new cue
}

targets <- pt_update %>% filter(pt_fake_target_trans != "")
for (i in 1:nrow(targets)){
  pt$pt_fake_target[pt$pt_fake_target == targets$pt_fake_target[i] #original target match
            & pt$en_target == targets$en_target[i]] <- #english match
    targets$pt_fake_target_trans[i] #new target
}

sum(duplicated(pt$pt_cue))
sum(duplicated(pt$pt_target))
sum(duplicated(pt$pt_fake_cue))
sum(duplicated(pt$pt_fake_target))

nrow(pt %>% filter(pt_cue == pt_target))

export(pt, "../matched_stimuli/pt_matched.csv", row.names = F)

# create possible trials ----
pt_trials <- pt[ , c("pt_cue", "pt_target")]
pt_trials$type <- "related"
pt_trials$cue_type <- "word"
pt_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
pt$en_cue <- tolower(pt$en_cue)
pt$en_target <- tolower(pt$en_target)
# match unrelated pairs as a start 
pt_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(pt_unrelated)){
  pt_unrelated$en_cue[i] <- pt$pt_cue[pt$en_cue == pt_unrelated$en_cue[i]]
  pt_unrelated$en_target[i] <- pt$pt_target[pt$en_target == pt_unrelated$en_target[i]]
}

pt_trials <- rbind(pt_trials,
                   pt_unrelated %>% select(-en_cosine) %>% 
                     rename("pt_cue" = "en_cue", 
                            "pt_target" = "en_target"), 
                   data.frame(pt_cue = pt$pt_fake_cue,
                              pt_target = pt$pt_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(pt_cue = pt$pt_cue[sample(1:1000,
                                                        1000)],
                              pt_target = pt$pt_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(pt_cue = pt$pt_fake_cue[sample(1:1000,
                                                        1000)],
                              pt_target = pt$pt_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(pt_trials[ , c("pt_cue", "pt_target")]))

# update with low cosines from random shuffle ----
# set up model
pt_model <- read.table("/Volumes/SPAML Backup/subs_vec/pt/subs.pt.1e6.txt", quote="\"")
pt_model <- na.omit(pt_model)
pt_model$V1 <- tolower(pt_model$V1)
pt_model <- pt_model[!duplicated(pt_model$V1), ]
rownames(pt_model) <- pt_model$V1
pt_model <- pt_model[ , -1]

pt_trials$pt_cosine <- NA

# get cosine
for (row in 1:nrow(pt_trials)){
  
  if(pt_trials$type[row] != "nonword") { 
    
    pt_trials$pt_cosine[row] <- cosine(as.matrix(t(pt_model[
    c(pt_trials$pt_cue[row], pt_trials$pt_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
pt_trials$ok <- TRUE
pt_trials$ok[pt_trials$type == "unrelated" & abs(pt_trials$pt_cosine) > .15] <- FALSE

good_trials <- pt_trials %>% filter(ok == TRUE)
bad_trials <- pt_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$pt_target <- sample(bad_trials$pt_target, 
                               size = length(bad_trials$pt_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$pt_cosine[row] <- cosine(as.matrix(t(pt_model[
    c(bad_trials$pt_cue[row], bad_trials$pt_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(pt_cosine < .15)))
bad_trials <- bad_trials %>% filter(pt_cosine >= .15)
nrow(bad_trials)
# ran section I ran multiple times 

whats_left <- cosine(as.matrix(t(pt_model[c(
  bad_trials$pt_target,
  unique(good_trials$pt_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$pt_target)){
  
  # find all words that could be paired with bad pt_target
  # as updated pt_cue
  potrutial_cues <- rownames(whats_left)[whats_left[ , bad_trials$pt_target[i]] < .15] 
  
  # find all pairs of good pt_target that could
  # be paired with bad pt_cue
  potrutial_switch <- good_trials %>% filter(pt_cue %in% potrutial_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(pt_model[c(
    bad_trials$pt_cue[i],
    potrutial_switch$pt_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$pt_cue[i], bad_trials$pt_target[i],
    potrutial_switch$pt_cue[potrutial_switch$pt_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_pt_cue", "bad_pt_target", 
                           "good_pt_cue", "good_pt_target")

good_trials_small <- good_trials %>% 
  filter(!(pt_cue %in% switch_todo$good_pt_cue & type == "unrelated"))

new_good_trials <- data.frame(
  pt_cue = c(switch_todo$bad_pt_cue, switch_todo$good_pt_cue),
  pt_target = c(switch_todo$good_pt_target, switch_todo$bad_pt_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  pt_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$pt_cosine[row] <- cosine(as.matrix(t(pt_model[
    c(new_good_trials$pt_cue[row], new_good_trials$pt_target[row]) , ])))[2]
}

pt_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(pt_final[ , c("pt_cue", "pt_target")]))

# check cosines
tapply(pt_final$pt_cosine, pt_final$type, mean, na.rm = T)
tapply(pt_final$pt_cosine, pt_final$type, min, na.rm = T)
tapply(pt_final$pt_cosine, pt_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- pt_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(pt_target) %>% 
  filter(n != 2)

weird_trials <- pt_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(pt_target %in% target_table$pt_target)

# check for NA
sum(is.na(pt_final$pt_cue))
sum(is.na(pt_final$pt_target))
sum(grepl("^NA", pt_final$pt_cue))
sum(grepl("^NA", pt_final$pt_target))

# check rows
nrow(pt_final)
table(pt_final$type, pt_final$cue_type, pt_final$target_type)

pt_final$ok <- NULL

export(pt_final, "pt/pt_trials_final.csv")
```

## pt_br Brazilian Portuguese COSINE

```{r eval = F}
# original words
pt_br <- import("pt/pt_translate.csv")
pt_br$en_cue <- gsub("digusting", "disgusting", pt_br$en_cue)

# fix real words ----
pt_br_update <- import("pt/pt_br/pt_stimuli_translated_Brazilian.xlsx") %>% 
  mutate(across(everything(), tolower))

# fix cue words ----
cues <- pt_br_update %>% filter(pt_cue_trans != "")
for (i in 1:nrow(cues)){
  pt_br$pt_cue[pt_br$pt_cue == cues$pt_cue[i] #original cue match
            & pt_br$en_cue == cues$en_cue[i]] <- #english match
    cues$pt_cue_trans[i] #new cue
}

targets <- pt_br_update %>% filter(pt_target_trans != "")
for (i in 1:nrow(targets)){
  pt_br$pt_target[pt_br$pt_target == targets$pt_target[i] #original target match
            & pt_br$en_target == targets$en_target[i]] <- #english match
    targets$pt_target_trans[i] #new target
}

# fix fake words ----
cues <- pt_br_update %>% filter(pt_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  pt_br$pt_fake_cue[pt_br$pt_fake_cue == cues$pt_fake_cue[i] #original cue match
            & pt_br$en_cue == cues$en_cue[i]] <- #english match
    cues$pt_fake_cue_trans[i] #new cue
}

targets <- pt_br_update %>% filter(pt_fake_target_trans != "")
for (i in 1:nrow(targets)){
  pt_br$pt_fake_target[pt_br$pt_fake_target == targets$pt_fake_target[i] #original target match
            & pt_br$en_target == targets$en_target[i]] <- #english match
    targets$pt_fake_target_trans[i] #new target
}

sum(duplicated(pt_br$pt_cue))
sum(duplicated(pt_br$pt_target))
sum(duplicated(pt_br$pt_fake_cue))
sum(duplicated(pt_br$pt_fake_target))

nrow(pt_br %>% filter(pt_cue == pt_target))

export(pt_br, "../matched_stimuli/pt_br_matched.csv", row.names = F)

# create possible trials ----
pt_br_trials <- pt_br[ , c("pt_br_cue", "pt_br_target")]
pt_br_trials$type <- "related"
pt_br_trials$cue_type <- "word"
pt_br_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
pt_br$en_cue <- tolower(pt_br$en_cue)
pt_br$en_target <- tolower(pt_br$en_target)
# match unrelated pairs as a start 
pt_br_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(pt_br_unrelated)){
  pt_br_unrelated$en_cue[i] <- pt_br$pt_br_cue[pt_br$en_cue == pt_br_unrelated$en_cue[i]]
  pt_br_unrelated$en_target[i] <- pt_br$pt_br_target[pt_br$en_target == pt_br_unrelated$en_target[i]]
}

pt_br_trials <- rbind(pt_br_trials,
                   pt_br_unrelated %>% select(-en_cosine) %>% 
                     rename("pt_br_cue" = "en_cue", 
                            "pt_br_target" = "en_target"), 
                   data.frame(pt_br_cue = pt_br$pt_br_fake_cue,
                              pt_br_target = pt_br$pt_br_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(pt_br_cue = pt_br$pt_br_cue[sample(1:1000,
                                                        1000)],
                              pt_br_target = pt_br$pt_br_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(pt_br_cue = pt_br$pt_br_fake_cue[sample(1:1000,
                                                        1000)],
                              pt_br_target = pt_br$pt_br_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(pt_br_trials[ , c("pt_br_cue", "pt_br_target")]))

# update with low cosines from random shuffle ----
# set up model
pt_br_model <- read.table("/Volumes/SPAML Backup/subs_vec/pt_br_br/subs.pt.1e6.txt", quote="\"")
pt_br_model <- na.omit(pt_br_model)
pt_br_model$V1 <- tolower(pt_br_model$V1)
pt_br_model <- pt_br_model[!duplicated(pt_br_model$V1), ]
rownames(pt_br_model) <- pt_br_model$V1
pt_br_model <- pt_br_model[ , -1]

pt_br_trials$pt_br_cosine <- NA

# get cosine
for (row in 1:nrow(pt_br_trials)){
  
  if(pt_br_trials$type[row] != "nonword") { 
    
    pt_br_trials$pt_br_cosine[row] <- cosine(as.matrix(t(pt_br_model[
    c(pt_br_trials$pt_br_cue[row], pt_br_trials$pt_br_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
pt_br_trials$ok <- TRUE
pt_br_trials$ok[pt_br_trials$type == "unrelated" & abs(pt_br_trials$pt_br_cosine) > .15] <- FALSE

good_trials <- pt_br_trials %>% filter(ok == TRUE)
bad_trials <- pt_br_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$pt_br_target <- sample(bad_trials$pt_br_target, 
                               size = length(bad_trials$pt_br_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$pt_br_cosine[row] <- cosine(as.matrix(t(pt_br_model[
    c(bad_trials$pt_br_cue[row], bad_trials$pt_br_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(pt_br_cosine < .15)))
bad_trials <- bad_trials %>% filter(pt_br_cosine >= .15)
nrow(bad_trials)
# ran section I ran multiple times 

whats_left <- cosine(as.matrix(t(pt_br_model[c(
  bad_trials$pt_br_target,
  unique(good_trials$pt_br_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$pt_br_target)){
  
  # find all words that could be paired with bad pt_br_target
  # as updated pt_br_cue
  potrutial_cues <- rownames(whats_left)[whats_left[ , bad_trials$pt_br_target[i]] < .15] 
  
  # find all pairs of good pt_br_target that could
  # be paired with bad pt_br_cue
  potrutial_switch <- good_trials %>% filter(pt_br_cue %in% potrutial_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(pt_br_model[c(
    bad_trials$pt_br_cue[i],
    potrutial_switch$pt_br_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$pt_br_cue[i], bad_trials$pt_br_target[i],
    potrutial_switch$pt_br_cue[potrutial_switch$pt_br_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_pt_br_cue", "bad_pt_br_target", 
                           "good_pt_br_cue", "good_pt_br_target")

good_trials_small <- good_trials %>% 
  filter(!(pt_br_cue %in% switch_todo$good_pt_br_cue & type == "unrelated"))

new_good_trials <- data.frame(
  pt_br_cue = c(switch_todo$bad_pt_br_cue, switch_todo$good_pt_br_cue),
  pt_br_target = c(switch_todo$good_pt_br_target, switch_todo$bad_pt_br_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  pt_br_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$pt_br_cosine[row] <- cosine(as.matrix(t(pt_br_model[
    c(new_good_trials$pt_br_cue[row], new_good_trials$pt_br_target[row]) , ])))[2]
}

pt_br_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(pt_br_final[ , c("pt_br_cue", "pt_br_target")]))

# check cosines
tapply(pt_br_final$pt_br_cosine, pt_br_final$type, mean, na.rm = T)
tapply(pt_br_final$pt_br_cosine, pt_br_final$type, min, na.rm = T)
tapply(pt_br_final$pt_br_cosine, pt_br_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- pt_br_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(pt_br_target) %>% 
  filter(n != 2)

weird_trials <- pt_br_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(pt_br_target %in% target_table$pt_br_target)

# check for NA
sum(is.na(pt_br_final$pt_br_cue))
sum(is.na(pt_br_final$pt_br_target))
sum(grepl("^NA", pt_br_final$pt_br_cue))
sum(grepl("^NA", pt_br_final$pt_br_target))

# check rows
nrow(pt_br_final)
table(pt_br_final$type, pt_br_final$cue_type, pt_br_final$target_type)

pt_br_final$ok <- NULL

export(pt_br_final, "pt_br_br/pt_br_trials_final.csv")
```

### pt Portuguese Match

```{r eval = F}
pt <- import("../matched_stimuli/pt_matched.csv")
pt_br <- import("../matched_stimuli/pt_br_matched.csv")

pt_together <- pt %>% 
  left_join(pt_br, by = c("en_cue" = "en_cue", 
                          "en_target" = "en_target"))

sum(is.na(pt_together$pt_cue.y))
sum(is.na(pt_together$pt_target.y))

sum(pt_together$pt_cue.x == pt_together$pt_cue.y)
sum(pt_together$pt_target.x == pt_together$pt_target.y)
```

## sr Serbian

```{r eval = F}
# original words
sr <- import("sr/sr_translate.csv")
sr$en_cue <- gsub("digusting", "disgusting", sr$en_cue)

# fix real words ----
sr_update <- import("sr/sr_translate.xlsx") %>% 
  mutate(across(everything(), tolower))

sr$sr_cue <- sr_update$FINAL_sr_cue
sr$sr_target <- sr_update$FINAL_sr_target
sr$sr_fake_cue <- sr_update$FINAL_sr_fake_cue
sr$sr_fake_target <- sr_update$FINAL_sr_fake_target
sr$en_cue <- sr_update$en_cue
sr$en_target <- sr_update$en_target
sr$en_cue <- gsub("digusting", "disgusting", sr$en_cue)

sum(duplicated(sr$sr_cue))
sum(duplicated(sr$sr_target))
sum(duplicated(sr$sr_fake_cue))
sum(duplicated(sr$sr_fake_target))

nrow(sr %>% filter(sr_cue == sr_target))

export(sr, "../matched_stimuli/sr_matched.csv", row.names = F)

# create possible trials ----
sr_trials <- sr[ , c("sr_cue", "sr_target")]
sr_trials$type <- "related"
sr_trials$cue_type <- "word"
sr_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
sr$en_cue <- tolower(sr$en_cue)
sr$en_target <- tolower(sr$en_target)
# match unrelated pairs as a start 
sr_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(sr_unrelated)){
  sr_unrelated$en_cue[i] <- sr$sr_cue[sr$en_cue == sr_unrelated$en_cue[i]]
  sr_unrelated$en_target[i] <- sr$sr_target[sr$en_target == sr_unrelated$en_target[i]]
}

sr_trials <- rbind(sr_trials,
                   sr_unrelated %>% select(-en_cosine) %>% 
                     rename("sr_cue" = "en_cue", 
                            "sr_target" = "en_target"), 
                   data.frame(sr_cue = sr$sr_fake_cue,
                              sr_target = sr$sr_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(sr_cue = sr$sr_cue[sample(1:1000,
                                                        1000)],
                              sr_target = sr$sr_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(sr_cue = sr$sr_fake_cue[sample(1:1000,
                                                        1000)],
                              sr_target = sr$sr_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(sr_trials[ , c("sr_cue", "sr_target")]))

# update with low cosines from random shuffle ----
# set up model
sr_model <- read.table("/Volumes/SPAML Backup/subs_vec/sr/subs.sr.1e6.txt", quote="\"")
sr_model <- na.omit(sr_model)
sr_model$V1 <- tolower(sr_model$V1)
sr_model <- sr_model[!duplicated(sr_model$V1), ]
rownames(sr_model) <- sr_model$V1
sr_model <- sr_model[ , -1]

sr_trials$sr_cosine <- NA

# get cosine
for (row in 1:nrow(sr_trials)){
  
  if(sr_trials$type[row] != "nonword") { 
    
    sr_trials$sr_cosine[row] <- cosine(as.matrix(t(sr_model[
    c(sr_trials$sr_cue[row], sr_trials$sr_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
sr_trials$ok <- TRUE
sr_trials$ok[sr_trials$type == "unrelated" & abs(sr_trials$sr_cosine) > .15] <- FALSE

good_trials <- sr_trials %>% filter(ok == TRUE)
bad_trials <- sr_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone
# literally I ran this until I got this worked out
bad_trials$sr_target <- sample(bad_trials$sr_target,
                               size = length(bad_trials$sr_target),
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$sr_cosine[row] <- cosine(as.matrix(t(sr_model[
    c(bad_trials$sr_cue[row], bad_trials$sr_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(sr_cosine < .15)))
bad_trials <- bad_trials %>% filter(sr_cosine >= .15)
nrow(bad_trials)
# this section I ran multiple times
# 
# whats_left <- cosine(as.matrix(t(sr_model[c(
#   bad_trials$sr_target,
#   unique(good_trials$sr_cue[good_trials$type == "unrelated"])) , ])))
# whats_left <- as.data.frame(whats_left)
# 
# switch_todo <- matrix(NA, nrow = nrow(bad_trials),
#                       ncol = 4)
# # find suggestions that the switch is ok 
# for (i in 1:length(bad_trials$sr_target)){
#   
#   # find all words that could be paired with bad sr_target
#   # as updated sr_cue
#   potrutial_cues <- rownames(whats_left)[whats_left[ , bad_trials$sr_target[i]] < .15] 
#   
#   # find all pairs of good sr_target that could
#   # be paired with bad sr_cue
#   potrutial_switch <- good_trials %>% filter(sr_cue %in% potrutial_cues) %>% filter(type == "unrelated")
#   
#   # find switchables 
#   switches <- cosine(as.matrix(t(sr_model[c(
#     bad_trials$sr_cue[i],
#     potrutial_switch$sr_target), 
#   ])))
#   
#   new_target <- names(which.min(switches[1, ]))
#   
#   switch_todo[i , ] <- c(bad_trials$sr_cue[i], bad_trials$sr_target[i],
#     potrutial_switch$sr_cue[potrutial_switch$sr_target == new_target],
#     new_target)
# 
# }
# 
# switch_todo <- as.data.frame(switch_todo)
# colnames(switch_todo) <- c("bad_sr_cue", "bad_sr_target", 
#                            "good_sr_cue", "good_sr_target")
# 
# good_trials_small <- good_trials %>% 
#   filter(!(sr_cue %in% switch_todo$good_sr_cue & type == "unrelated"))
# 
# new_good_trials <- data.frame(
#   sr_cue = c(switch_todo$bad_sr_cue, switch_todo$good_sr_cue),
#   sr_target = c(switch_todo$good_sr_target, switch_todo$bad_sr_target),
#   type = rep("unrelated", nrow(switch_todo)*2),
#   cue_type = rep("word", nrow(switch_todo)*2),
#   target_type = rep("word", nrow(switch_todo)*2),
#   sr_cosine = rep(NA, nrow(switch_todo)*2),
#   ok = rep(FALSE, nrow(switch_todo)*2)
# )
# 
# for (row in 1:nrow(new_good_trials)){
#     new_good_trials$sr_cosine[row] <- cosine(as.matrix(t(sr_model[
#     c(new_good_trials$sr_cue[row], new_good_trials$sr_target[row]) , ])))[2]
# }
# 
# sr_final <- bind_rows(good_trials_small, new_good_trials)

# all values very high, likely unusable 
sr_final <- bind_rows(good_trials, bad_trials)
sum(duplicated(sr_final[ , c("sr_cue", "sr_target")]))

# check cosines
tapply(sr_final$sr_cosine, sr_final$type, mean, na.rm = T)
tapply(sr_final$sr_cosine, sr_final$type, min, na.rm = T)
tapply(sr_final$sr_cosine, sr_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- sr_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(sr_target) %>% 
  filter(n != 2)

weird_trials <- sr_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(sr_target %in% target_table$sr_target)

# check for NA
sum(is.na(sr_final$sr_cue))
sum(is.na(sr_final$sr_target))
sum(grepl("^NA", sr_final$sr_cue))
sum(grepl("^NA", sr_final$sr_target))

# check rows
nrow(sr_final)
table(sr_final$type, sr_final$cue_type, sr_final$target_type)

sr_final$ok <- NULL

export(sr_final, "sr/sr_trials_final.csv")
```

## es Spanish GET NEW FILE

## bu Bulgarian GET NEW FILE 

## no Norweigan GET NEW FILE

## it Italian CHECK WITH TEAM 

## ur Urdu

```{r eval = F}
# original words
ur <- import("ur/ur_translate.csv")
ur$en_cue <- gsub("digusting", "disgusting", ur$en_cue)

# fix real words ----
ur_update <- import("ur/ur_translate2 SPAML Apr 2022.xlsx") %>% 
  mutate(across(everything(), tolower))

# fix cue words ----
cues <- ur_update %>% filter(ur_cue_trans != "")
for (i in 1:nrow(cues)){
  ur$ur_cue[ur$ur_cue == cues$ur_cue[i] #original cue match
            & ur$en_cue == cues$en_cue[i]] <- #english match
    cues$ur_cue_trans[i] #new cue
}

targets <- ur_update %>% filter(ur_target_trans != "")
for (i in 1:nrow(targets)){
  ur$ur_target[ur$ur_target == targets$ur_target[i] #original target match
            & ur$en_target == targets$en_target[i]] <- #english match
    targets$ur_target_trans[i] #new target
}

# fix fake words ----
cues <- ur_update %>% filter(ur_fake_cue_trans != "")
for (i in 1:nrow(cues)){
  ur$ur_fake_cue[ur$ur_fake_cue == cues$ur_fake_cue[i] #original cue match
            & ur$en_cue == cues$en_cue[i]] <- #english match
    cues$ur_fake_cue_trans[i] #new cue
}

targets <- ur_update %>% filter(ur_fake_target_trans != "")
for (i in 1:nrow(targets)){
  ur$ur_fake_target[ur$ur_fake_target == targets$ur_fake_target[i] #original target match
            & ur$en_target == targets$en_target[i]] <- #english match
    targets$ur_fake_target_trans[i] #new target
}

sum(duplicated(ur$ur_cue))
sum(duplicated(ur$ur_target))
sum(duplicated(ur$ur_fake_cue))
sum(duplicated(ur$ur_fake_target))

nrow(ur %>% filter(ur_cue == ur_target))

export(ur, "../matched_stimuli/ur_matched.csv", row.names = F)

# create possible trials ----
ur_trials <- ur[ , c("ur_cue", "ur_target")]
ur_trials$type <- "related"
ur_trials$cue_type <- "word"
ur_trials$target_type <- "word"

en <- import("en/en_trials_final.csv")
ur$en_cue <- tolower(ur$en_cue)
ur$en_target <- tolower(ur$en_target)
# match unrelated pairs as a start 
ur_unrelated <- en %>% filter(type == "unrelated")
for (i in 1:nrow(ur_unrelated)){
  ur_unrelated$en_cue[i] <- ur$ur_cue[ur$en_cue == ur_unrelated$en_cue[i]]
  ur_unrelated$en_target[i] <- ur$ur_target[ur$en_target == ur_unrelated$en_target[i]]
}

ur_trials <- rbind(ur_trials,
                   ur_unrelated %>% select(-en_cosine) %>% 
                     rename("ur_cue" = "en_cue", 
                            "ur_target" = "en_target"), 
                   data.frame(ur_cue = ur$ur_fake_cue,
                              ur_target = ur$ur_target[sample(1:1000,
                                                              1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "word"),
                   data.frame(ur_cue = ur$ur_cue[sample(1:1000,
                                                        1000)],
                              ur_target = ur$ur_fake_target,
                              type = "nonword",
                              cue_type = "word",
                              target_type = "nonword"),
                   data.frame(ur_cue = ur$ur_fake_cue[sample(1:1000,
                                                        1000)],
                              ur_target = ur$ur_fake_target[sample(1:1000,
                                                        1000)],
                              type = "nonword",
                              cue_type = "nonword",
                              target_type = "nonword"))

# check dups run until 0
sum(duplicated(ur_trials[ , c("ur_cue", "ur_target")]))

# update with low cosines from random shuffle ----
# set up model
ur_model <- read.table("/Volumes/SPAML Backup/wiki_vec/ur/wiki.ur.1e6.txt", quote="\"")
ur_model <- na.omit(ur_model)
ur_model$V1 <- tolower(ur_model$V1)
ur_model <- ur_model[!duplicated(ur_model$V1), ]
rownames(ur_model) <- ur_model$V1
ur_model <- ur_model[ , -1]

ur_trials$ur_cosine <- NA

# get cosine
for (row in 1:nrow(ur_trials)){
  
  if(ur_trials$type[row] != "nonword") { 
    
    ur_trials$ur_cosine[row] <- cosine(as.matrix(t(ur_model[
    c(ur_trials$ur_cue[row], ur_trials$ur_target[row]) , ])))[2]

  }
  
}

# update trials that have cosines too big 
ur_trials$ok <- TRUE
ur_trials$ok[ur_trials$type == "unrelated" & abs(ur_trials$ur_cosine) > .15] <- FALSE

good_trials <- ur_trials %>% filter(ok == TRUE)
bad_trials <- ur_trials %>% filter(ok == FALSE)

# iterate on those bad trials until all gone 
# literally I ran this until I got this worked out 
bad_trials$ur_target <- sample(bad_trials$ur_target, 
                               size = length(bad_trials$ur_target), 
                               replace = FALSE)
for (row in 1:nrow(bad_trials)){
    bad_trials$ur_cosine[row] <- cosine(as.matrix(t(ur_model[
    c(bad_trials$ur_cue[row], bad_trials$ur_target[row]) , ])))[2]
}

good_trials <- bind_rows(good_trials,
                         (bad_trials %>% filter(ur_cosine < .15)))
bad_trials <- bad_trials %>% filter(ur_cosine >= .15)
nrow(bad_trials)
# this section I ran multiple times 

whats_left <- cosine(as.matrix(t(ur_model[c(
  bad_trials$ur_target,
  unique(good_trials$ur_cue[good_trials$type == "unrelated"])) , ])))
whats_left <- as.data.frame(whats_left)

switch_todo <- matrix(NA, nrow = nrow(bad_trials),
                      ncol = 4)
# find suggestions that the switch is ok 
for (i in 1:length(bad_trials$ur_target)){
  
  # find all words that could be paired with bad ur_target
  # as updated ur_cue
  potrutial_cues <- rownames(whats_left)[whats_left[ , bad_trials$ur_target[i]] < .15] 
  
  # find all pairs of good ur_target that could
  # be paired with bad ur_cue
  potrutial_switch <- good_trials %>% filter(ur_cue %in% potrutial_cues) %>% filter(type == "unrelated")
  
  # find switchables 
  switches <- cosine(as.matrix(t(ur_model[c(
    bad_trials$ur_cue[i],
    potrutial_switch$ur_target), 
  ])))
  
  new_target <- names(which.min(switches[1, ]))
  
  switch_todo[i , ] <- c(bad_trials$ur_cue[i], bad_trials$ur_target[i],
    potrutial_switch$ur_cue[potrutial_switch$ur_target == new_target],
    new_target)

}

switch_todo <- as.data.frame(switch_todo)
colnames(switch_todo) <- c("bad_ur_cue", "bad_ur_target", 
                           "good_ur_cue", "good_ur_target")

good_trials_small <- good_trials %>% 
  filter(!(ur_cue %in% switch_todo$good_ur_cue & type == "unrelated"))

new_good_trials <- data.frame(
  ur_cue = c(switch_todo$bad_ur_cue, switch_todo$good_ur_cue),
  ur_target = c(switch_todo$good_ur_target, switch_todo$bad_ur_target),
  type = rep("unrelated", nrow(switch_todo)*2),
  cue_type = rep("word", nrow(switch_todo)*2),
  target_type = rep("word", nrow(switch_todo)*2),
  ur_cosine = rep(NA, nrow(switch_todo)*2),
  ok = rep(FALSE, nrow(switch_todo)*2)
)

for (row in 1:nrow(new_good_trials)){
    new_good_trials$ur_cosine[row] <- cosine(as.matrix(t(ur_model[
    c(new_good_trials$ur_cue[row], new_good_trials$ur_target[row]) , ])))[2]
}

ur_final <- bind_rows(good_trials_small, new_good_trials)
sum(duplicated(ur_final[ , c("ur_cue", "ur_target")]))

# check cosines
tapply(ur_final$ur_cosine, ur_final$type, mean, na.rm = T)
tapply(ur_final$ur_cosine, ur_final$type, min, na.rm = T)
tapply(ur_final$ur_cosine, ur_final$type, max, na.rm = T)

# check that everyone has a mate
target_table <- ur_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  count(ur_target) %>% 
  filter(n != 2)

weird_trials <- ur_final %>% 
  filter(target_type == "word") %>% 
  filter(type != "nonword") %>% 
  filter(ur_target %in% target_table$ur_target)

# drop extra
ur_final <- ur_final %>% 
  filter(!(ur_cue == "پرخطر" & ur_target == "لکھیں"))

# check for NA
sum(is.na(ur_final$ur_cue))
sum(is.na(ur_final$ur_target))
sum(grepl("^NA", ur_final$ur_cue))
sum(grepl("^NA", ur_final$ur_target))

# check rows
nrow(ur_final)
table(ur_final$type, ur_final$cue_type, ur_final$target_type)

ur_final$ok <- NULL

export(ur_final, "ur/ur_trials_final.csv")
```



