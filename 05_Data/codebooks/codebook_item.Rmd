---
title: "SPAML Item Data Codebook"
output:
  html_document:
    toc: true
    toc_depth: 4
    toc_float: true
    code_folding: 'hide'
    self_contained: true
  pdf_document:
    toc: yes
    toc_depth: 4
    latex_engine: xelatex
---

# Set Options

```{r setup}
knitr::opts_chunk$set(
  warning = TRUE, # show warnings during codebook generation
  message = TRUE, # show messages during codebook generation
  error = TRUE, # do not interrupt codebook generation in case of errors,
    # usually better for debugging
  echo = TRUE  # show R code
)
ggplot2::theme_set(ggplot2::theme_bw())

library(rio)
library(labelled)
```

# Prep Data

```{r prepare_codebook}
library(codebook)
codebook_data <- import("../data_processing/output_data/item_data/sr_item_data.csv")

var_label(codebook_data) <- list(
  word = "Original stimulus showed to the participant in the language of the study.",
  class = "Word/nonword trial type indicator, which tells you what the correct answer is for the trial.",
  avgRT = "Average response latency for the stimulus item across all participants.",
  avgZ_RT = "Average z-scored response latency for the stimulus item - z-scored by participant session, then averaged across the item, regardless of condition.",
  samplesize = "The number of participants who were shown that item.",
  n_answered = "The number of participants who answered that item (i.e., it did not time out.",
  seRT = "The standard error of the raw response latency.",
  seZ_RT = "The standard error of the z-scored response latency.",
  accuracy = "The proportion of correct answers out of total answered for that item.",
  Z2.5_avgRT = "The average raw response latency excluding outliers of 2.5 Z or higher.",
  Z2.5_avgZ_RT = "The average Z-scored response latency excluding outliers of 2.5 Z or higher.",
  Z2.5_samplesize = "The number of data points viewed that were not Z equal 2.5 or higher", 
  Z2.5_n_answered = "The number of data points viewed that were not Z equal 2.5 or higher. Note that viewed and answered are the same because you had to answer the item (correctly) for it be to included in the Z-score calculation.",
  Z2.5_seRT = "Standard error of the raw response latency after removing Z equal 2.5 or higher.",
  Z2.5_seZ_RT = "Standard error of the Z-scored response latency after removing Z equal 2.5 or higher.",
  Z2.5_accuracy = "The accuracy for Z scored response latencies after excluding Z greater than 2.5 and higher. Note that you had to get the item right for it to be included in the Z-score calculation, so this value is always 1.", 
  Z3.0_avgRT = "The average raw response latency excluding outliers of 3.0 Z or higher.",
  Z3.0_avgZ_RT = "The average Z-scored response latency excluding outliers of 3.0 Z or higher.",
  Z3.0_samplesize = "The number of data points viewed that were not Z equal 3.0 or higher", 
  Z3.0_n_answered = "The number of data points viewed that were not Z equal 3.0 or higher. Note that viewed and answered are the same because you had to answer the item (correctly) for it be to included in the Z-score calculation.",
  Z3.0_seRT = "Standard error of the raw response latency after removing Z equal 3.0 or higher.",
  Z3.0_seZ_RT = "Standard error of the Z-scored response latency after removing Z equal 3.0 or higher.",
  Z3.0_accuracy = "The accuracy for Z scored response latencies after excluding Z greater than 3.0 and higher. Note that you had to get the item right for it to be included in the Z-score calculation, so this value is always 1.")

metadata(codebook_data)$name <- "Semantic Priming Across Many Languages (Example using Serbian data)"
metadata(codebook_data)$description <- "This dataset includes the summarized item data from the SPAML project (example is specifically Serbian, but all files are structured the same way). The data is averaged over items, regardless of condition for words (i.e., related or unrelated trial). 

Semantic priming has been studied for nearly 50 years across various experimental manipulations and theoretical frameworks. These studies provide insight into the cognitive underpinnings of semantic representations in both healthy and clinical populations; however, they have suffered from several issues including generally low sample sizes and a lack of diversity in linguistic implementations. Here, we will test the size and the variability of the semantic priming effect across ten languages by creating a large database of semantic priming values, based on an adaptive sampling procedure. Differences in response latencies between related word-pair conditions and unrelated word-pair conditions (i.e., difference score confidence interval is greater than zero) will allow quantifying evidence for semantic priming, whereas improvements in model fit with the addition of a random intercept for language will provide support for variability in semantic priming across languages."
metadata(codebook_data)$identifier <- "https://doi.org/10.5281/zenodo.10888833"
metadata(codebook_data)$creator <- "Erin M. Buchanan"
metadata(codebook_data)$citation <- "Buchanan, E., Cuccolo, K., Heyman, T., Iyer, A., Coles, N., Lewis Jr, N., Peters, K., van Berkel, N., Taylor, J., Van't Veer, A. E., Montefinese, M., Valentine, K. D., Maxwell, N., Türkan, B. N., Williams, G., Oliveros-Chacana, J. C., Röer, J., Fini, C., Acar, O., … Lewis, S. C. (2024). SemanticPriming/SPAML: SPAML v1 Data Release (v1.0.0) [Data set]. Zenodo. https://doi.org/10.5281/zenodo.10888833"
metadata(codebook_data)$url <- "https://github.com/SemanticPriming/SPAML/releases/"
metadata(codebook_data)$datePublished <- "2024-05-01"
metadata(codebook_data)$temporalCoverage <- "2022-2024" 
metadata(codebook_data)$spatialCoverage <- "Online" 
```

# Create codebook

```{r codebook}
codebook(codebook_data)
```
